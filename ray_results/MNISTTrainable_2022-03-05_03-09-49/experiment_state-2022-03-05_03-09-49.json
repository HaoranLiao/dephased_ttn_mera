{
  "checkpoints": [
    "{\n  \"trainable_name\": \"MNISTTrainable\",\n  \"trial_id\": \"a0b55_00002\",\n  \"config\": {\n    \"batch_size\": 100\n  },\n  \"local_dir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-09-49\",\n  \"evaluated_params\": {\n    \"batch_size\": 100\n  },\n  \"experiment_tag\": \"2_batch_size=100\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b018c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 99,\n    \"train_accuracy\": 92.67999999999999,\n    \"test_accuracy\": 92.63932702418506,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 100,\n    \"experiment_id\": \"3eddb66a17f04ee49c94de2dae3df4cb\",\n    \"date\": \"2022-03-05_03-12-20\",\n    \"timestamp\": 1646467940,\n    \"time_this_iter_s\": 1.3276817798614502,\n    \"time_total_s\": 147.59335780143738,\n    \"pid\": 3519,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"batch_size\": 100\n    },\n    \"time_since_restore\": 147.59335780143738,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 100,\n    \"trial_id\": \"a0b55_00002\",\n    \"experiment_tag\": \"2_batch_size=100\"\n  },\n  \"last_update_time\": 1646467940.990765,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 99,\n      \"min\": 0,\n      \"avg\": 49.50000000000002,\n      \"last\": 99,\n      \"last-5-avg\": 97.0,\n      \"last-10-avg\": 94.5\n    },\n    \"train_accuracy\": {\n      \"max\": 92.9,\n      \"min\": 54.92,\n      \"avg\": 91.55999999999999,\n      \"last\": 92.67999999999999,\n      \"last-5-avg\": 92.80000000000001,\n      \"last-10-avg\": 92.724\n    },\n    \"test_accuracy\": {\n      \"max\": 92.90220820189275,\n      \"min\": 54.15352260778128,\n      \"avg\": 91.74710830704522,\n      \"last\": 92.63932702418506,\n      \"last-5-avg\": 92.63932702418506,\n      \"last-10-avg\": 92.53943217665615\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.01,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"timestamp\": {\n      \"max\": 1646467940,\n      \"min\": 1646467797,\n      \"avg\": 1646467871.17,\n      \"last\": 1646467940,\n      \"last-5-avg\": 1646467937.8,\n      \"last-10-avg\": 1646467934.6\n    },\n    \"time_this_iter_s\": {\n      \"max\": 4.910693407058716,\n      \"min\": 1.2857046127319336,\n      \"avg\": 1.4759335780143732,\n      \"last\": 1.3276817798614502,\n      \"last-5-avg\": 1.321563196182251,\n      \"last-10-avg\": 1.3168073415756225\n    },\n    \"time_total_s\": {\n      \"max\": 147.59335780143738,\n      \"min\": 4.910693407058716,\n      \"avg\": 78.48380913972856,\n      \"last\": 147.59335780143738,\n      \"last-5-avg\": 144.95258131027222,\n      \"last-10-avg\": 141.65697233676912\n    },\n    \"pid\": {\n      \"max\": 3519,\n      \"min\": 3519,\n      \"avg\": 3518.9999999999977,\n      \"last\": 3519,\n      \"last-5-avg\": 3519.0,\n      \"last-10-avg\": 3519.0\n    },\n    \"time_since_restore\": {\n      \"max\": 147.59335780143738,\n      \"min\": 4.910693407058716,\n      \"avg\": 78.48380913972856,\n      \"last\": 147.59335780143738,\n      \"last-5-avg\": 144.95258131027222,\n      \"last-10-avg\": 141.65697233676912\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"config/batch_size\": {\n      \"max\": 100,\n      \"min\": 100,\n      \"avg\": 99.99999999999997,\n      \"last\": 100,\n      \"last-5-avg\": 100.0,\n      \"last-10-avg\": 100.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5f4b604b614b624b63652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5a4b5b4b5c4b5d4b5e4b5f4b604b614b624b63652e\"\n      }\n    },\n    \"train_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847405735c28f5c28f647405733333333333447405739999999999a47405731eb851eb8524740572b851eb851eb652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405731eb851eb85247405719999999999a47405735c28f5c28f6474057347ae147ae1547405719999999999a47405735c28f5c28f647405733333333333447405739999999999a47405731eb851eb8524740572b851eb851eb652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474057222fea76fb6d47405728eabbe514ba4740572c48249c21614740572c48249c216147405728eabbe514ba652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474057222fea76fb6d47405714ba479ac8d1474057222fea76fb6d474057222fea76fb6d474057115cdee3bc2a474057222fea76fb6d47405728eabbe514ba4740572c48249c21614740572c48249c216147405728eabbe514ba652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a5f1b23624a611b23624a621b23624a631b23624a641b2362652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a591b23624a5a1b23624a5b1b23624a5d1b23624a5e1b23624a5f1b23624a611b23624a621b23624a631b23624a641b2362652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ff501f780000000473ff5819080000000473ff51ee540000000473ff4d900c0000000473ff53e2f40000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff4e48380000000473ff4dab900000000473ff5389b00000000473ff558a640000000473ff4a652c0000000473ff501f780000000473ff5819080000000473ff51ee540000000473ff4d900c0000000473ff53e2f40000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474061c98d7e000000474061f4909f0000004740621ece6980000047406248806b00000047406272fcc9800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474060f764f5000000474061211a670000004740614b8b9d000000474061763ce98000004740619f898f000000474061c98d7e000000474061f4909f0000004740621ece6980000047406248806b00000047406272fcc9800000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284dbf0d4dbf0d4dbf0d4dbf0d4dbf0d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284dbf0d4dbf0d4dbf0d4dbf0d4dbf0d4dbf0d4dbf0d4dbf0d4dbf0d4dbf0d652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474061c98d7e000000474061f4909f0000004740621ece6980000047406248806b00000047406272fcc9800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474060f764f5000000474061211a670000004740614b8b9d000000474061763ce98000004740619f898f000000474061c98d7e000000474061f4909f0000004740621ece6980000047406248806b00000047406272fcc9800000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"config/batch_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b644b644b644b644b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b644b644b644b644b644b644b644b644b644b64652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646467790.0651708,\n  \"logdir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-09-49/MNISTTrainable_a0b55_00002_2_batch_size=100_2022-03-05_03-09-50\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"MNISTTrainable\",\n  \"trial_id\": \"a0b55_00000\",\n  \"config\": {\n    \"batch_size\": 25\n  },\n  \"local_dir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-09-49\",\n  \"evaluated_params\": {\n    \"batch_size\": 25\n  },\n  \"experiment_tag\": \"0_batch_size=25\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b018c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 99,\n    \"train_accuracy\": 92.72,\n    \"test_accuracy\": 92.42902208201893,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 100,\n    \"experiment_id\": \"bec0ea41924842e5a40a28b1facb85fe\",\n    \"date\": \"2022-03-05_03-14-22\",\n    \"timestamp\": 1646468062,\n    \"time_this_iter_s\": 2.207218885421753,\n    \"time_total_s\": 267.8592598438263,\n    \"pid\": 3524,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"batch_size\": 25\n    },\n    \"time_since_restore\": 267.8592598438263,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 100,\n    \"trial_id\": \"a0b55_00000\",\n    \"experiment_tag\": \"0_batch_size=25\"\n  },\n  \"last_update_time\": 1646468062.139617,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 99,\n      \"min\": 0,\n      \"avg\": 49.50000000000002,\n      \"last\": 99,\n      \"last-5-avg\": 97.0,\n      \"last-10-avg\": 94.5\n    },\n    \"train_accuracy\": {\n      \"max\": 93.16,\n      \"min\": 81.32000000000001,\n      \"avg\": 92.18320000000001,\n      \"last\": 92.72,\n      \"last-5-avg\": 92.76400000000001,\n      \"last-10-avg\": 92.652\n    },\n    \"test_accuracy\": {\n      \"max\": 92.74447949526814,\n      \"min\": 80.07360672975815,\n      \"avg\": 92.0967402733964,\n      \"last\": 92.42902208201893,\n      \"last-5-avg\": 92.56572029442694,\n      \"last-10-avg\": 92.43427970557308\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.01,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"timestamp\": {\n      \"max\": 1646468062,\n      \"min\": 1646467800,\n      \"avg\": 1646467941.67,\n      \"last\": 1646468062,\n      \"last-5-avg\": 1646468057.2,\n      \"last-10-avg\": 1646468051.7\n    },\n    \"time_this_iter_s\": {\n      \"max\": 6.378263473510742,\n      \"min\": 2.1721439361572266,\n      \"avg\": 2.6785925984382617,\n      \"last\": 2.207218885421753,\n      \"last-5-avg\": 2.2040664672851564,\n      \"last-10-avg\": 2.2063233137130736\n    },\n    \"time_total_s\": {\n      \"max\": 267.8592598438263,\n      \"min\": 6.378263473510742,\n      \"avg\": 148.1164408755302,\n      \"last\": 267.8592598438263,\n      \"last-5-avg\": 263.4407336235046,\n      \"last-10-avg\": 257.93007535934447\n    },\n    \"pid\": {\n      \"max\": 3524,\n      \"min\": 3524,\n      \"avg\": 3523.9999999999977,\n      \"last\": 3524,\n      \"last-5-avg\": 3524.0,\n      \"last-10-avg\": 3524.0\n    },\n    \"time_since_restore\": {\n      \"max\": 267.8592598438263,\n      \"min\": 6.378263473510742,\n      \"avg\": 148.1164408755302,\n      \"last\": 267.8592598438263,\n      \"last-5-avg\": 263.4407336235046,\n      \"last-10-avg\": 257.93007535934447\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"config/batch_size\": {\n      \"max\": 25,\n      \"min\": 25,\n      \"avg\": 24.999999999999993,\n      \"last\": 25,\n      \"last-5-avg\": 25.0,\n      \"last-10-avg\": 25.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5f4b604b614b624b63652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5a4b5b4b5c4b5d4b5e4b5f4b604b614b624b63652e\"\n      }\n    },\n    \"train_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847405730a3d70a3d7047405730a3d70a3d704740573ae147ae147b4740572a3d70a3d70a4740572e147ae147ae652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474057370a3d70a3d7474057333333333334474056f1eb851eb85247405731eb851eb8524740571eb851eb851e47405730a3d70a3d7047405730a3d70a3d704740573ae147ae147b4740572a3d70a3d70a4740572e147ae147ae652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474057258d532e0814474057258d532e0814474057258d532e081447405728eabbe514ba4740571b751908e21f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405728eabbe514ba474057115cdee3bc2a474056ec595f0630fe4740571b751908e21f4740571ed281bfeec6474057258d532e0814474057258d532e0814474057258d532e081447405728eabbe514ba4740571b751908e21f652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ad51b23624ad71b23624ad91b23624adb1b23624ade1b2362652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284aca1b23624acc1b23624ace1b23624ad01b23624ad31b23624ad51b23624ad71b23624ad91b23624adb1b23624ade1b2362652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740017425800000004740018bd120000000474001f386400000004740018dc4c0000000474001a86260000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474001d2b440000000474001915c20000000474001694dc0000000474001c62740000000474001c457000000004740017425800000004740018bd120000000474001f386400000004740018dc4c0000000474001a86260000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407030548a400000474070536c2c8000004740707753390000004740709a6ec2800000474070bdbf87400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406f00c3de00000047406f47094e80000047406f8cae8580000047406fd3c7228000004740700d6c3f40000047407030548a400000474070536c2c8000004740707753390000004740709a6ec2800000474070bdbf87400000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284dc40d4dc40d4dc40d4dc40d4dc40d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284dc40d4dc40d4dc40d4dc40d4dc40d4dc40d4dc40d4dc40d4dc40d4dc40d652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407030548a400000474070536c2c8000004740707753390000004740709a6ec2800000474070bdbf87400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406f00c3de00000047406f47094e80000047406f8cae8580000047406fd3c7228000004740700d6c3f40000047407030548a400000474070536c2c8000004740707753390000004740709a6ec2800000474070bdbf87400000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"config/batch_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b194b194b194b194b19652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b194b194b194b194b194b194b194b194b194b19652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646467790.0514388,\n  \"logdir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-09-49/MNISTTrainable_a0b55_00000_0_batch_size=25_2022-03-05_03-09-50\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"MNISTTrainable\",\n  \"trial_id\": \"a0b55_00003\",\n  \"config\": {\n    \"batch_size\": 250\n  },\n  \"local_dir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-09-49\",\n  \"evaluated_params\": {\n    \"batch_size\": 250\n  },\n  \"experiment_tag\": \"3_batch_size=250\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b018c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 99,\n    \"train_accuracy\": 91.82000000000001,\n    \"test_accuracy\": 92.3764458464774,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 100,\n    \"experiment_id\": \"d61b010338df470e86f4c4bd61a4971c\",\n    \"date\": \"2022-03-05_03-11-34\",\n    \"timestamp\": 1646467894,\n    \"time_this_iter_s\": 0.9470300674438477,\n    \"time_total_s\": 100.80989718437195,\n    \"pid\": 3517,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"batch_size\": 250\n    },\n    \"time_since_restore\": 100.80989718437195,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 100,\n    \"trial_id\": \"a0b55_00003\",\n    \"experiment_tag\": \"3_batch_size=250\"\n  },\n  \"last_update_time\": 1646467894.608087,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 99,\n      \"min\": 0,\n      \"avg\": 49.50000000000002,\n      \"last\": 99,\n      \"last-5-avg\": 97.0,\n      \"last-10-avg\": 94.5\n    },\n    \"train_accuracy\": {\n      \"max\": 92.36,\n      \"min\": 53.7,\n      \"avg\": 90.15499999999993,\n      \"last\": 91.82000000000001,\n      \"last-5-avg\": 92.028,\n      \"last-10-avg\": 91.976\n    },\n    \"test_accuracy\": {\n      \"max\": 92.6919032597266,\n      \"min\": 53.10199789695058,\n      \"avg\": 90.5005257623554,\n      \"last\": 92.3764458464774,\n      \"last-5-avg\": 92.51314405888539,\n      \"last-10-avg\": 92.47108307045215\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.01,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"timestamp\": {\n      \"max\": 1646467894,\n      \"min\": 1646467797,\n      \"avg\": 1646467845.78,\n      \"last\": 1646467894,\n      \"last-5-avg\": 1646467892.0,\n      \"last-10-avg\": 1646467889.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 4.596888542175293,\n      \"min\": 0.9175505638122559,\n      \"avg\": 1.008098971843719,\n      \"last\": 0.9470300674438477,\n      \"last-5-avg\": 0.965604829788208,\n      \"last-10-avg\": 0.9657762050628662\n    },\n    \"time_total_s\": {\n      \"max\": 100.80989718437195,\n      \"min\": 4.596888542175293,\n      \"avg\": 52.75795664072038,\n      \"last\": 100.80989718437195,\n      \"last-5-avg\": 98.8814591884613,\n      \"last-10-avg\": 96.46293847560882\n    },\n    \"pid\": {\n      \"max\": 3517,\n      \"min\": 3517,\n      \"avg\": 3516.9999999999977,\n      \"last\": 3517,\n      \"last-5-avg\": 3517.0,\n      \"last-10-avg\": 3517.0\n    },\n    \"time_since_restore\": {\n      \"max\": 100.80989718437195,\n      \"min\": 4.596888542175293,\n      \"avg\": 52.75795664072038,\n      \"last\": 100.80989718437195,\n      \"last-5-avg\": 98.8814591884613,\n      \"last-10-avg\": 96.46293847560882\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"config/batch_size\": {\n      \"max\": 250,\n      \"min\": 250,\n      \"avg\": 249.99999999999994,\n      \"last\": 250,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5f4b604b614b624b63652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5a4b5b4b5c4b5d4b5e4b5f4b604b614b624b63652e\"\n      }\n    },\n    \"train_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474056fd70a3d70a3d474057066666666667474057170a3d70a3d7474056f9999999999a474056f47ae147ae15652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474056ef5c28f5c28f474056f1eb851eb8524740570000000000004740570147ae147ae1474057051eb851eb85474056fd70a3d70a3d474057066666666667474057170a3d70a3d7474056f9999999999a474056f47ae147ae15652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474057258d532e08144740572c48249c2161474057258d532e081447405714ba479ac8d14740571817b051d578652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474057115cdee3bc2a4740570dff762caf83474057258d532e08144740571ed281bfeec6474057258d532e0814474057258d532e08144740572c48249c2161474057258d532e081447405714ba479ac8d14740571817b051d578652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a321b23624a331b23624a341b23624a351b23624a361b2362652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a2d1b23624a2e1b23624a2f1b23624a301b23624a311b23624a321b23624a331b23624a341b23624a351b23624a361b2362652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473feed98b00000000473fef3b5900000000473fee3b7280000000473fefe0c400000000473fee4e1200000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fef104980000000473fee658e80000000473feee9c280000000473feef15880000000473fef3c4380000000473feed98b00000000473fef3b5900000000473fee3b7280000000473fefe0c400000000473fee4e1200000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740583c8a180000004740587b00ca000000474058b777af000000474058f7393700000047405933d55b000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405707dd2800000047405744a845000000474057827bca000000474057c05e7b000000474057fed7020000004740583c8a180000004740587b00ca000000474058b777af000000474058f7393700000047405933d55b000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284dbd0d4dbd0d4dbd0d4dbd0d4dbd0d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284dbd0d4dbd0d4dbd0d4dbd0d4dbd0d4dbd0d4dbd0d4dbd0d4dbd0d4dbd0d652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740583c8a180000004740587b00ca000000474058b777af000000474058f7393700000047405933d55b000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405707dd2800000047405744a845000000474057827bca000000474057c05e7b000000474057fed7020000004740583c8a180000004740587b00ca000000474058b777af000000474058f7393700000047405933d55b000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"config/batch_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284bfa4bfa4bfa4bfa4bfa652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284bfa4bfa4bfa4bfa4bfa4bfa4bfa4bfa4bfa4bfa652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646467790.0714374,\n  \"logdir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-09-49/MNISTTrainable_a0b55_00003_3_batch_size=250_2022-03-05_03-09-50\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"MNISTTrainable\",\n  \"trial_id\": \"a0b55_00001\",\n  \"config\": {\n    \"batch_size\": 50\n  },\n  \"local_dir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-09-49\",\n  \"evaluated_params\": {\n    \"batch_size\": 50\n  },\n  \"experiment_tag\": \"1_batch_size=50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b018c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 99,\n    \"train_accuracy\": 92.62,\n    \"test_accuracy\": 92.6919032597266,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 100,\n    \"experiment_id\": \"4b6bf0c6cedd451682f49dabc104128b\",\n    \"date\": \"2022-03-05_03-13-03\",\n    \"timestamp\": 1646467983,\n    \"time_this_iter_s\": 1.6039574146270752,\n    \"time_total_s\": 190.36456775665283,\n    \"pid\": 3518,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"batch_size\": 50\n    },\n    \"time_since_restore\": 190.36456775665283,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 100,\n    \"trial_id\": \"a0b55_00001\",\n    \"experiment_tag\": \"1_batch_size=50\"\n  },\n  \"last_update_time\": 1646467983.3422065,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 99,\n      \"min\": 0,\n      \"avg\": 49.50000000000002,\n      \"last\": 99,\n      \"last-5-avg\": 97.0,\n      \"last-10-avg\": 94.5\n    },\n    \"train_accuracy\": {\n      \"max\": 92.94,\n      \"min\": 78.82000000000001,\n      \"avg\": 92.04639999999999,\n      \"last\": 92.62,\n      \"last-5-avg\": 92.71600000000001,\n      \"last-10-avg\": 92.752\n    },\n    \"test_accuracy\": {\n      \"max\": 92.79705573080967,\n      \"min\": 77.44479495268138,\n      \"avg\": 92.08149316508931,\n      \"last\": 92.6919032597266,\n      \"last-5-avg\": 92.66035751840168,\n      \"last-10-avg\": 92.61303890641429\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.01,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"timestamp\": {\n      \"max\": 1646467983,\n      \"min\": 1646467797,\n      \"avg\": 1646467895.2700007,\n      \"last\": 1646467983,\n      \"last-5-avg\": 1646467979.6,\n      \"last-10-avg\": 1646467975.6\n    },\n    \"time_this_iter_s\": {\n      \"max\": 5.256239652633667,\n      \"min\": 1.573760986328125,\n      \"avg\": 1.9036456775665276,\n      \"last\": 1.6039574146270752,\n      \"last-5-avg\": 1.601513147354126,\n      \"last-10-avg\": 1.60421462059021\n    },\n    \"time_total_s\": {\n      \"max\": 190.36456775665283,\n      \"min\": 5.256239652633667,\n      \"avg\": 103.00469142913815,\n      \"last\": 190.36456775665283,\n      \"last-5-avg\": 187.1610776901245,\n      \"last-10-avg\": 183.15999939441681\n    },\n    \"pid\": {\n      \"max\": 3518,\n      \"min\": 3518,\n      \"avg\": 3517.9999999999977,\n      \"last\": 3518,\n      \"last-5-avg\": 3518.0,\n      \"last-10-avg\": 3518.0\n    },\n    \"time_since_restore\": {\n      \"max\": 190.36456775665283,\n      \"min\": 5.256239652633667,\n      \"avg\": 103.00469142913815,\n      \"last\": 190.36456775665283,\n      \"last-5-avg\": 187.1610776901245,\n      \"last-10-avg\": 183.15999939441681\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"config/batch_size\": {\n      \"max\": 50,\n      \"min\": 50,\n      \"avg\": 49.999999999999986,\n      \"last\": 50,\n      \"last-5-avg\": 50.0,\n      \"last-10-avg\": 50.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5f4b604b614b624b63652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5a4b5b4b5c4b5d4b5e4b5f4b604b614b624b63652e\"\n      }\n    },\n    \"train_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740573333333333344740572000000000004740573851eb851eb847405731eb851eb85247405727ae147ae148652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740573333333333344740573851eb851eb8474057228f5c28f5c34740573851eb851eb847405735c28f5c28f64740573333333333344740572000000000004740573851eb851eb847405731eb851eb85247405727ae147ae148652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474057258d532e0814474057258d532e08144740573302f60a3aaf47405728eabbe514ba4740572c48249c2161652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405728eabbe514ba4740571b751908e21f47405728eabbe514ba474057222fea76fb6d474057258d532e0814474057258d532e0814474057258d532e08144740573302f60a3aaf47405728eabbe514ba4740572c48249c2161652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a881b23624a8a1b23624a8c1b23624a8d1b23624a8f1b2362652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a801b23624a821b23624a841b23624a851b23624a871b23624a881b23624a8a1b23624a8c1b23624a8d1b23624a8f1b2362652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ff98c3c00000000473ff99d4740000000473ff9e00a80000000473ff96ba040000000473ff9a9cf40000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ffa09d7c0000000473ffa104880000000473ff92e2000000000473ff9a96600000000473ff99bfe00000000473ff98c3c00000000473ff99d4740000000473ff9e00a80000000473ff96ba040000000473ff9a9cf40000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474066fe850780000047406731bf96000000474067657fab0000004740679856eb800000474067cbaa8a000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474065fe64f680000047406632858780000047406664e1c7800000474066983493800000474066cb6c8f800000474066fe850780000047406731bf96000000474067657fab0000004740679856eb800000474067cbaa8a000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284dbe0d4dbe0d4dbe0d4dbe0d4dbe0d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284dbe0d4dbe0d4dbe0d4dbe0d4dbe0d4dbe0d4dbe0d4dbe0d4dbe0d4dbe0d652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474066fe850780000047406731bf96000000474067657fab0000004740679856eb800000474067cbaa8a000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474065fe64f680000047406632858780000047406664e1c7800000474066983493800000474066cb6c8f800000474066fe850780000047406731bf96000000474067657fab0000004740679856eb800000474067cbaa8a000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"config/batch_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b324b324b324b324b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b324b324b324b324b324b324b324b324b324b32652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646467790.0584936,\n  \"logdir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-09-49/MNISTTrainable_a0b55_00001_1_batch_size=50_2022-03-05_03-09-50\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_max_pending_trials": 17,
    "_metric": "test_accuracy",
    "_total_time": 706.6270825862885,
    "_iteration": 421,
    "_has_errored": false,
    "_fail_fast": false,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_updated_queue": true,
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-09-49",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059527000000000000008c107261792e74756e652e73746f70706572948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1646467789.859116,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2022-03-05_03-09-49",
    "checkpoint_file": "/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-09-49/experiment_state-2022-03-05_03-09-49.json",
    "_checkpoint_period": "auto",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1646467789.859116,
    "timestamp": 1646468055.483232
  }
}