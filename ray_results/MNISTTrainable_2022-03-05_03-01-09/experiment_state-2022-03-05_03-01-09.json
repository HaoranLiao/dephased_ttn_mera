{
  "checkpoints": [
    "{\n  \"trainable_name\": \"MNISTTrainable\",\n  \"trial_id\": \"6ab9a_00001\",\n  \"config\": {\n    \"batch_size\": 250\n  },\n  \"local_dir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-01-09\",\n  \"evaluated_params\": {\n    \"batch_size\": 250\n  },\n  \"experiment_tag\": \"1_batch_size=250\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b018c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 50\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 49,\n    \"train_accuracy\": 89.3,\n    \"test_accuracy\": 87.7,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 50,\n    \"experiment_id\": \"8626e60dd4194635b21eed6804d412b8\",\n    \"date\": \"2022-03-05_03-01-24\",\n    \"timestamp\": 1646467284,\n    \"time_this_iter_s\": 0.19327807426452637,\n    \"time_total_s\": 11.617480039596558,\n    \"pid\": 243356,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"batch_size\": 250\n    },\n    \"time_since_restore\": 11.617480039596558,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 50,\n    \"trial_id\": \"6ab9a_00001\",\n    \"experiment_tag\": \"1_batch_size=250\"\n  },\n  \"last_update_time\": 1646467284.2553825,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 49,\n      \"min\": 0,\n      \"avg\": 24.499999999999996,\n      \"last\": 49,\n      \"last-5-avg\": 47.0,\n      \"last-10-avg\": 44.5\n    },\n    \"train_accuracy\": {\n      \"max\": 89.3,\n      \"min\": 53.900000000000006,\n      \"avg\": 75.29599999999996,\n      \"last\": 89.3,\n      \"last-5-avg\": 88.62000000000002,\n      \"last-10-avg\": 88.19\n    },\n    \"test_accuracy\": {\n      \"max\": 87.7,\n      \"min\": 52.300000000000004,\n      \"avg\": 71.18199999999996,\n      \"last\": 87.7,\n      \"last-5-avg\": 86.96000000000001,\n      \"last-10-avg\": 86.26\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.02,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"timestamp\": {\n      \"max\": 1646467284,\n      \"min\": 1646467275,\n      \"avg\": 1646467279.1599994,\n      \"last\": 1646467284,\n      \"last-5-avg\": 1646467283.4,\n      \"last-10-avg\": 1646467282.9\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2.5878844261169434,\n      \"min\": 0.17473196983337402,\n      \"avg\": 0.2323496007919311,\n      \"last\": 0.19327807426452637,\n      \"last-5-avg\": 0.18394994735717773,\n      \"last-10-avg\": 0.18531332015991211\n    },\n    \"time_total_s\": {\n      \"max\": 11.617480039596558,\n      \"min\": 2.5878844261169434,\n      \"avg\": 7.1043288898468,\n      \"last\": 11.617480039596558,\n      \"last-5-avg\": 11.246994972229004,\n      \"last-10-avg\": 10.788258457183838\n    },\n    \"pid\": {\n      \"max\": 243356,\n      \"min\": 243356,\n      \"avg\": 243355.99999999997,\n      \"last\": 243356,\n      \"last-5-avg\": 243356.0,\n      \"last-10-avg\": 243356.0\n    },\n    \"time_since_restore\": {\n      \"max\": 11.617480039596558,\n      \"min\": 2.5878844261169434,\n      \"avg\": 7.1043288898468,\n      \"last\": 11.617480039596558,\n      \"last-5-avg\": 11.246994972229004,\n      \"last-10-avg\": 10.788258457183838\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"config/batch_size\": {\n      \"max\": 250,\n      \"min\": 250,\n      \"avg\": 249.99999999999997,\n      \"last\": 250,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2d4b2e4b2f4b304b31652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b31652e\"\n      }\n    },\n    \"train_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740562666666666664740560ccccccccccd47405619999999999a474056266666666666474056533333333333652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474055e00000000000474055e66666666666474055f33333333333474055f9999999999a4740560000000000004740562666666666664740560ccccccccccd47405619999999999a474056266666666666474056533333333333652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474055b33333333333474055a66666666666474055b33333333333474055b9999999999a474055eccccccccccd652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740554000000000004740554666666666664740556ccccccccccd47405579999999999a474055866666666666474055b33333333333474055a66666666666474055b33333333333474055b9999999999a474055eccccccccccd652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ad31823624ad31823624ad31823624ad41823624ad4182362652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ad21823624ad21823624ad21823624ad31823624ad31823624ad31823624ad31823624ad31823624ad41823624ad4182362652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc7cf5e00000000473fc7823600000000473fc65d9e00000000473fc74dd400000000473fc8bd5600000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc8ae7800000000473fc7c6e400000000473fc80b7e00000000473fc817a600000000473fc6e09c00000000473fc7cf5e00000000473fc7823600000000473fc65d9e00000000473fc74dd400000000473fc8bd5600000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474025c47a600000004740262283380000004740267bf9b0000000474026d931000000004740273c2658000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474023ea1258000000474024492de8000000474024a95be000000047402509ba78000000474025653ce8000000474025c47a600000004740262283380000004740267bf9b0000000474026d931000000004740273c2658000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a9cb603004a9cb603004a9cb603004a9cb603004a9cb60300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a9cb603004a9cb603004a9cb603004a9cb603004a9cb603004a9cb603004a9cb603004a9cb603004a9cb603004a9cb60300652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474025c47a600000004740262283380000004740267bf9b0000000474026d931000000004740273c2658000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474023ea1258000000474024492de8000000474024a95be000000047402509ba78000000474025653ce8000000474025c47a600000004740262283380000004740267bf9b0000000474026d931000000004740273c2658000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"config/batch_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284bfa4bfa4bfa4bfa4bfa652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284bfa4bfa4bfa4bfa4bfa4bfa4bfa4bfa4bfa4bfa652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646467270.0147727,\n  \"logdir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-01-09/MNISTTrainable_6ab9a_00001_1_batch_size=250_2022-03-05_03-01-10\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"MNISTTrainable\",\n  \"trial_id\": \"6ab9a_00000\",\n  \"config\": {\n    \"batch_size\": 100\n  },\n  \"local_dir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-01-09\",\n  \"evaluated_params\": {\n    \"batch_size\": 100\n  },\n  \"experiment_tag\": \"0_batch_size=100\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b018c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 50\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 49,\n    \"train_accuracy\": 90.4,\n    \"test_accuracy\": 88.9,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 50,\n    \"experiment_id\": \"3a780a0844584398aa8af44e06f580c8\",\n    \"date\": \"2022-03-05_03-01-28\",\n    \"timestamp\": 1646467288,\n    \"time_this_iter_s\": 0.24323511123657227,\n    \"time_total_s\": 15.493686199188232,\n    \"pid\": 243357,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"batch_size\": 100\n    },\n    \"time_since_restore\": 15.493686199188232,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 50,\n    \"trial_id\": \"6ab9a_00000\",\n    \"experiment_tag\": \"0_batch_size=100\"\n  },\n  \"last_update_time\": 1646467288.1718404,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 49,\n      \"min\": 0,\n      \"avg\": 24.499999999999996,\n      \"last\": 49,\n      \"last-5-avg\": 47.0,\n      \"last-10-avg\": 44.5\n    },\n    \"train_accuracy\": {\n      \"max\": 90.5,\n      \"min\": 53.900000000000006,\n      \"avg\": 83.60999999999999,\n      \"last\": 90.4,\n      \"last-5-avg\": 90.26000000000002,\n      \"last-10-avg\": 90.15\n    },\n    \"test_accuracy\": {\n      \"max\": 89.0,\n      \"min\": 52.300000000000004,\n      \"avg\": 80.76599999999996,\n      \"last\": 88.9,\n      \"last-5-avg\": 88.84,\n      \"last-10-avg\": 88.66\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.02,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"timestamp\": {\n      \"max\": 1646467288,\n      \"min\": 1646467275,\n      \"avg\": 1646467281.2999992,\n      \"last\": 1646467288,\n      \"last-5-avg\": 1646467287.2,\n      \"last-10-avg\": 1646467286.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2.612550735473633,\n      \"min\": 0.23720097541809082,\n      \"avg\": 0.30987372398376456,\n      \"last\": 0.24323511123657227,\n      \"last-5-avg\": 0.24009418487548828,\n      \"last-10-avg\": 0.24308903217315675\n    },\n    \"time_total_s\": {\n      \"max\": 15.493686199188232,\n      \"min\": 2.612550735473633,\n      \"avg\": 9.213105316162107,\n      \"last\": 15.493686199188232,\n      \"last-5-avg\": 15.011469173431397,\n      \"last-10-avg\": 14.404982995986938\n    },\n    \"pid\": {\n      \"max\": 243357,\n      \"min\": 243357,\n      \"avg\": 243356.99999999997,\n      \"last\": 243357,\n      \"last-5-avg\": 243357.0,\n      \"last-10-avg\": 243357.0\n    },\n    \"time_since_restore\": {\n      \"max\": 15.493686199188232,\n      \"min\": 2.612550735473633,\n      \"avg\": 9.213105316162107,\n      \"last\": 15.493686199188232,\n      \"last-5-avg\": 15.011469173431397,\n      \"last-10-avg\": 14.404982995986938\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"config/batch_size\": {\n      \"max\": 100,\n      \"min\": 100,\n      \"avg\": 99.99999999999999,\n      \"last\": 100,\n      \"last-5-avg\": 100.0,\n      \"last-10-avg\": 100.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2d4b2e4b2f4b304b31652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b31652e\"\n      }\n    },\n    \"train_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740568ccccccccccd474056866666666667474056866666666667474056a0000000000047405699999999999a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740569333333333334740567333333333334740568ccccccccccd4740566ccccccccccd4740568ccccccccccd4740568ccccccccccd474056866666666667474056866666666667474056a0000000000047405699999999999a652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740563333333333334740563333333333334740562ccccccccccd47405640000000000047405639999999999a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474056400000000000474055f9999999999a474056400000000000474055e6666666666647405639999999999a4740563333333333334740563333333333334740562ccccccccccd47405640000000000047405639999999999a652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ad71823624ad71823624ad71823624ad71823624ad8182362652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ad51823624ad61823624ad61823624ad61823624ad61823624ad71823624ad71823624ad71823624ad71823624ad8182362652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fcebf6a00000000473fce5c9a00000000473fce878a00000000473fcee32600000000473fcf225400000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd0097200000000473fce721200000000473fcf70ae00000000473fced7ba00000000473fd0588200000000473fcebf6a00000000473fce5c9a00000000473fce878a00000000473fcee32600000000473fcf225400000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847402d111df800000047402d8a906000000047402e04ae8800000047402e803b2000000047402efcc470000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847402aa0725800000047402b1a3aa000000047402b97fd5800000047402c135c4000000047402c96205000000047402d111df800000047402d8a906000000047402e04ae8800000047402e803b2000000047402efcc470000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a9db603004a9db603004a9db603004a9db603004a9db60300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a9db603004a9db603004a9db603004a9db603004a9db603004a9db603004a9db603004a9db603004a9db603004a9db60300652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847402d111df800000047402d8a906000000047402e04ae8800000047402e803b2000000047402efcc470000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847402aa0725800000047402b1a3aa000000047402b97fd5800000047402c135c4000000047402c96205000000047402d111df800000047402d8a906000000047402e04ae8800000047402e803b2000000047402efcc470000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"config/batch_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b644b644b644b644b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b644b644b644b644b644b644b644b644b644b64652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646467270.0069811,\n  \"logdir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-01-09/MNISTTrainable_6ab9a_00000_0_batch_size=100_2022-03-05_03-01-09\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_max_pending_trials": 17,
    "_metric": "test_accuracy",
    "_total_time": 27.11116623878479,
    "_iteration": 127,
    "_has_errored": false,
    "_fail_fast": false,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_updated_queue": true,
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-01-09",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059527000000000000008c107261792e74756e652e73746f70706572948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1646467269.8143797,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2022-03-05_03-01-09",
    "checkpoint_file": "/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-01-09/experiment_state-2022-03-05_03-01-09.json",
    "_checkpoint_period": "auto",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1646467269.8143797,
    "timestamp": 1646467280.1114998
  }
}