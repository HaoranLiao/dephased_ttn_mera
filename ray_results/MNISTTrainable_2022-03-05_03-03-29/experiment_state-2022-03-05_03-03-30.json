{
  "checkpoints": [
    "{\n  \"trainable_name\": \"MNISTTrainable\",\n  \"trial_id\": \"be8ad_00001\",\n  \"config\": {\n    \"batch_size\": 50\n  },\n  \"local_dir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-03-29\",\n  \"evaluated_params\": {\n    \"batch_size\": 50\n  },\n  \"experiment_tag\": \"1_batch_size=50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b018c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 99,\n    \"train_accuracy\": 92.4,\n    \"test_accuracy\": 90.3,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 100,\n    \"experiment_id\": \"13fb6daec5644daab798d599669325c3\",\n    \"date\": \"2022-03-05_03-04-16\",\n    \"timestamp\": 1646467456,\n    \"time_this_iter_s\": 0.3512699604034424,\n    \"time_total_s\": 42.7109112739563,\n    \"pid\": 244930,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"batch_size\": 50\n    },\n    \"time_since_restore\": 42.7109112739563,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 100,\n    \"trial_id\": \"be8ad_00001\",\n    \"experiment_tag\": \"1_batch_size=50\"\n  },\n  \"last_update_time\": 1646467456.2674086,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 99,\n      \"min\": 0,\n      \"avg\": 49.50000000000002,\n      \"last\": 99,\n      \"last-5-avg\": 97.0,\n      \"last-10-avg\": 94.5\n    },\n    \"train_accuracy\": {\n      \"max\": 92.80000000000001,\n      \"min\": 53.900000000000006,\n      \"avg\": 90.01600000000002,\n      \"last\": 92.4,\n      \"last-5-avg\": 92.34,\n      \"last-10-avg\": 92.33000000000001\n    },\n    \"test_accuracy\": {\n      \"max\": 91.0,\n      \"min\": 52.300000000000004,\n      \"avg\": 87.57700000000001,\n      \"last\": 90.3,\n      \"last-5-avg\": 90.4,\n      \"last-10-avg\": 90.41999999999999\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.01,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"timestamp\": {\n      \"max\": 1646467456,\n      \"min\": 1646467415,\n      \"avg\": 1646467436.6699994,\n      \"last\": 1646467456,\n      \"last-5-avg\": 1646467455.0,\n      \"last-10-avg\": 1646467454.2\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2.8355324268341064,\n      \"min\": 0.33614563941955566,\n      \"avg\": 0.4271091127395629,\n      \"last\": 0.3512699604034424,\n      \"last-5-avg\": 0.3473149299621582,\n      \"last-10-avg\": 0.346850848197937\n    },\n    \"time_total_s\": {\n      \"max\": 42.7109112739563,\n      \"min\": 2.8355324268341064,\n      \"avg\": 23.82533757448196,\n      \"last\": 42.7109112739563,\n      \"last-5-avg\": 42.01632919311523,\n      \"last-10-avg\": 41.15181250572205\n    },\n    \"pid\": {\n      \"max\": 244930,\n      \"min\": 244930,\n      \"avg\": 244929.99999999994,\n      \"last\": 244930,\n      \"last-5-avg\": 244930.0,\n      \"last-10-avg\": 244930.0\n    },\n    \"time_since_restore\": {\n      \"max\": 42.7109112739563,\n      \"min\": 2.8355324268341064,\n      \"avg\": 23.82533757448196,\n      \"last\": 42.7109112739563,\n      \"last-5-avg\": 42.01632919311523,\n      \"last-10-avg\": 41.15181250572205\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"config/batch_size\": {\n      \"max\": 50,\n      \"min\": 50,\n      \"avg\": 49.999999999999986,\n      \"last\": 50,\n      \"last-5-avg\": 50.0,\n      \"last-10-avg\": 50.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5f4b604b614b624b63652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5a4b5b4b5c4b5d4b5e4b5f4b604b614b624b63652e\"\n      }\n    },\n    \"train_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740570ccccccccccd47405720000000000047405719999999999a4740570ccccccccccd47405719999999999a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740570ccccccccccd47405719999999999a4740572666666666674740570ccccccccccd4740570ccccccccccd4740570ccccccccccd47405720000000000047405719999999999a4740570ccccccccccd47405719999999999a652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474056accccccccccd47405680000000000047405699999999999a474056a66666666667474056933333333333652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474056a0000000000047405699999999999a474056800000000000474056accccccccccd474056a66666666667474056accccccccccd47405680000000000047405699999999999a474056a66666666667474056933333333333652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a7e1923624a7f1923624a7f1923624a7f1923624a80192362652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a7d1923624a7d1923624a7d1923624a7e1923624a7e1923624a7e1923624a7f1923624a7f1923624a7f1923624a80192362652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd6449700000000473fd6907300000000473fd5b47e00000000473fd61f4d00000000473fd67b3500000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd6a2c900000000473fd6500e00000000473fd5ff6c00000000473fd60b7c00000000473fd5da4200000000473fd6449700000000473fd6907300000000473fd5b47e00000000473fd61f4d00000000473fd67b3500000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474044a9403e000000474044d6612400000047404501ca200000004740452e08ba0000004740455aff24000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474043cc4ca0000000474043f8ecbc00000047404424eb9400000047404451028c0000004740447cb710000000474044a9403e000000474044d6612400000047404501ca200000004740452e08ba0000004740455aff24000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ac2bc03004ac2bc03004ac2bc03004ac2bc03004ac2bc0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ac2bc03004ac2bc03004ac2bc03004ac2bc03004ac2bc03004ac2bc03004ac2bc03004ac2bc03004ac2bc03004ac2bc0300652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474044a9403e000000474044d6612400000047404501ca200000004740452e08ba0000004740455aff24000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474043cc4ca0000000474043f8ecbc00000047404424eb9400000047404451028c0000004740447cb710000000474044a9403e000000474044d6612400000047404501ca200000004740452e08ba0000004740455aff24000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"config/batch_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b324b324b324b324b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b324b324b324b324b324b324b324b324b324b32652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646467410.6402807,\n  \"logdir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-03-29/MNISTTrainable_be8ad_00001_1_batch_size=50_2022-03-05_03-03-30\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"MNISTTrainable\",\n  \"trial_id\": \"be8ad_00000\",\n  \"config\": {\n    \"batch_size\": 25\n  },\n  \"local_dir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-03-29\",\n  \"evaluated_params\": {\n    \"batch_size\": 25\n  },\n  \"experiment_tag\": \"0_batch_size=25\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b018c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 99,\n    \"train_accuracy\": 92.5,\n    \"test_accuracy\": 91.3,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 100,\n    \"experiment_id\": \"81f461e935a5480eb9c103066fc1b911\",\n    \"date\": \"2022-03-05_03-04-31\",\n    \"timestamp\": 1646467471,\n    \"time_this_iter_s\": 0.45000147819519043,\n    \"time_total_s\": 57.690457344055176,\n    \"pid\": 244928,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"batch_size\": 25\n    },\n    \"time_since_restore\": 57.690457344055176,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 100,\n    \"trial_id\": \"be8ad_00000\",\n    \"experiment_tag\": \"0_batch_size=25\"\n  },\n  \"last_update_time\": 1646467471.2909658,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 99,\n      \"min\": 0,\n      \"avg\": 49.50000000000002,\n      \"last\": 99,\n      \"last-5-avg\": 97.0,\n      \"last-10-avg\": 94.5\n    },\n    \"train_accuracy\": {\n      \"max\": 92.80000000000001,\n      \"min\": 54.1,\n      \"avg\": 91.08599999999996,\n      \"last\": 92.5,\n      \"last-5-avg\": 92.60000000000001,\n      \"last-10-avg\": 92.58\n    },\n    \"test_accuracy\": {\n      \"max\": 91.7,\n      \"min\": 53.400000000000006,\n      \"avg\": 89.25299999999994,\n      \"last\": 91.3,\n      \"last-5-avg\": 91.12,\n      \"last-10-avg\": 90.99999999999999\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.01,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"timestamp\": {\n      \"max\": 1646467471,\n      \"min\": 1646467416,\n      \"avg\": 1646467445.6099997,\n      \"last\": 1646467471,\n      \"last-5-avg\": 1646467469.8,\n      \"last-10-avg\": 1646467468.8\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3.059183359146118,\n      \"min\": 0.44574594497680664,\n      \"avg\": 0.5769045734405515,\n      \"last\": 0.45000147819519043,\n      \"last-5-avg\": 0.4519644737243652,\n      \"last-10-avg\": 0.45589594841003417\n    },\n    \"time_total_s\": {\n      \"max\": 57.690457344055176,\n      \"min\": 3.059183359146118,\n      \"avg\": 32.67714421033858,\n      \"last\": 57.690457344055176,\n      \"last-5-avg\": 56.78919081687927,\n      \"last-10-avg\": 55.65050580501556\n    },\n    \"pid\": {\n      \"max\": 244928,\n      \"min\": 244928,\n      \"avg\": 244927.99999999994,\n      \"last\": 244928,\n      \"last-5-avg\": 244928.0,\n      \"last-10-avg\": 244928.0\n    },\n    \"time_since_restore\": {\n      \"max\": 57.690457344055176,\n      \"min\": 3.059183359146118,\n      \"avg\": 32.67714421033858,\n      \"last\": 57.690457344055176,\n      \"last-5-avg\": 56.78919081687927,\n      \"last-10-avg\": 55.65050580501556\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"config/batch_size\": {\n      \"max\": 25,\n      \"min\": 25,\n      \"avg\": 24.999999999999993,\n      \"last\": 25,\n      \"last-5-avg\": 25.0,\n      \"last-10-avg\": 25.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5f4b604b614b624b63652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5a4b5b4b5c4b5d4b5e4b5f4b604b614b624b63652e\"\n      }\n    },\n    \"train_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474057133333333334474057266666666667474057333333333334474057333333333334474057200000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405720000000000047405719999999999a47405733333333333447405719999999999a4740572ccccccccccd474057133333333334474057266666666667474057333333333334474057333333333334474057200000000000652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474056eccccccccccd474056d33333333333474056b33333333333474056a00000000000474056d33333333333652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474056a66666666667474056d33333333333474056a66666666667474056d33333333333474056a66666666667474056eccccccccccd474056d33333333333474056b33333333333474056a00000000000474056d33333333333652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a8d1923624a8d1923624a8e1923624a8e1923624a8f192362652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a8b1923624a8b1923624a8c1923624a8c1923624a8d1923624a8d1923624a8d1923624a8e1923624a8e1923624a8f192362652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fdcef0b00000000473fdd4ebd00000000473fdcdd4100000000473fdcb91200000000473fdcccd300000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fdcf92500000000473fddb42700000000473fdde08700000000473fddcce700000000473fdcca5600000000473fdcef0b00000000473fdd4ebd00000000473fdcdd4100000000473fdcb91200000000473fdcccd300000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404bf0fd2200000047404c2b9a9c00000047404c65551e00000047404c9ec74200000047404cd860e8000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404acac73600000047404b062f8400000047404b41f09200000047404b7d8a6000000047404bb71f0c00000047404bf0fd2200000047404c2b9a9c00000047404c65551e00000047404c9ec74200000047404cd860e8000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ac0bc03004ac0bc03004ac0bc03004ac0bc03004ac0bc0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ac0bc03004ac0bc03004ac0bc03004ac0bc03004ac0bc03004ac0bc03004ac0bc03004ac0bc03004ac0bc03004ac0bc0300652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404bf0fd2200000047404c2b9a9c00000047404c65551e00000047404c9ec74200000047404cd860e8000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404acac73600000047404b062f8400000047404b41f09200000047404b7d8a6000000047404bb71f0c00000047404bf0fd2200000047404c2b9a9c00000047404c65551e00000047404c9ec74200000047404cd860e8000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"config/batch_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b194b194b194b194b19652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b194b194b194b194b194b194b194b194b194b19652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646467410.6321845,\n  \"logdir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-03-29/MNISTTrainable_be8ad_00000_0_batch_size=25_2022-03-05_03-03-30\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"MNISTTrainable\",\n  \"trial_id\": \"be8ad_00003\",\n  \"config\": {\n    \"batch_size\": 250\n  },\n  \"local_dir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-03-29\",\n  \"evaluated_params\": {\n    \"batch_size\": 250\n  },\n  \"experiment_tag\": \"3_batch_size=250\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b018c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 99,\n    \"train_accuracy\": 92.30000000000001,\n    \"test_accuracy\": 90.4,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 100,\n    \"experiment_id\": \"94a31cdb4ab74c59997040e20e46c616\",\n    \"date\": \"2022-03-05_03-03-58\",\n    \"timestamp\": 1646467438,\n    \"time_this_iter_s\": 0.2197263240814209,\n    \"time_total_s\": 25.3181312084198,\n    \"pid\": 244927,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"batch_size\": 250\n    },\n    \"time_since_restore\": 25.3181312084198,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 100,\n    \"trial_id\": \"be8ad_00003\",\n    \"experiment_tag\": \"3_batch_size=250\"\n  },\n  \"last_update_time\": 1646467438.9075348,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 99,\n      \"min\": 0,\n      \"avg\": 49.50000000000002,\n      \"last\": 99,\n      \"last-5-avg\": 97.0,\n      \"last-10-avg\": 94.5\n    },\n    \"train_accuracy\": {\n      \"max\": 92.4,\n      \"min\": 53.6,\n      \"avg\": 83.88699999999999,\n      \"last\": 92.30000000000001,\n      \"last-5-avg\": 92.26000000000002,\n      \"last-10-avg\": 92.25\n    },\n    \"test_accuracy\": {\n      \"max\": 90.8,\n      \"min\": 52.300000000000004,\n      \"avg\": 80.70999999999997,\n      \"last\": 90.4,\n      \"last-5-avg\": 90.52000000000001,\n      \"last-10-avg\": 90.47\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.01,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"timestamp\": {\n      \"max\": 1646467438,\n      \"min\": 1646467415,\n      \"avg\": 1646467426.9700003,\n      \"last\": 1646467438,\n      \"last-5-avg\": 1646467437.8,\n      \"last-10-avg\": 1646467437.3\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2.790398597717285,\n      \"min\": 0.2091681957244873,\n      \"avg\": 0.25318131208419803,\n      \"last\": 0.2197263240814209,\n      \"last-5-avg\": 0.22948312759399414,\n      \"last-10-avg\": 0.22644951343536376\n    },\n    \"time_total_s\": {\n      \"max\": 25.3181312084198,\n      \"min\": 2.790398597717285,\n      \"avg\": 14.09718174695969,\n      \"last\": 25.3181312084198,\n      \"last-5-avg\": 24.867592000961302,\n      \"last-10-avg\": 24.29613003730774\n    },\n    \"pid\": {\n      \"max\": 244927,\n      \"min\": 244927,\n      \"avg\": 244926.99999999994,\n      \"last\": 244927,\n      \"last-5-avg\": 244927.0,\n      \"last-10-avg\": 244927.0\n    },\n    \"time_since_restore\": {\n      \"max\": 25.3181312084198,\n      \"min\": 2.790398597717285,\n      \"avg\": 14.09718174695969,\n      \"last\": 25.3181312084198,\n      \"last-5-avg\": 24.867592000961302,\n      \"last-10-avg\": 24.29613003730774\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"config/batch_size\": {\n      \"max\": 250,\n      \"min\": 250,\n      \"avg\": 249.99999999999994,\n      \"last\": 250,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5f4b604b614b624b63652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5a4b5b4b5c4b5d4b5e4b5f4b604b614b624b63652e\"\n      }\n    },\n    \"train_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847405719999999999a474057000000000000474057133333333334474057133333333334474057133333333334652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740571333333333344740571333333333344740570ccccccccccd47405706666666666747405713333333333447405719999999999a474057000000000000474057133333333334474057133333333334474057133333333334652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474056a00000000000474056a6666666666747405699999999999a474056accccccccccd47405699999999999a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474056933333333333474056a00000000000474056a0000000000047405699999999999a47405699999999999a474056a00000000000474056a6666666666747405699999999999a474056accccccccccd47405699999999999a652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a6d1923624a6e1923624a6e1923624a6e1923624a6e192362652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a6c1923624a6d1923624a6d1923624a6d1923624a6d1923624a6d1923624a6e1923624a6e1923624a6e1923624a6e192362652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fcdbd6400000000473fce8a0c00000000473fce16ee00000000473fcc602800000000473fcc1ffe00000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fcd2f7000000000473fcc981000000000473fcafeea00000000473fcdf5a800000000473fcc406400000000473fcdbd6400000000473fce8a0c00000000473fce16ee00000000473fcc602800000000473fcc1ffe00000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474038672ecc000000474038a442e4000000474038e070c000000047403919311000000047403951710c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740374819f8000000474037814a18000000474037b747ec000000474037f3333c0000004740382bb404000000474038672ecc000000474038a442e4000000474038e070c000000047403919311000000047403951710c000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284abfbc03004abfbc03004abfbc03004abfbc03004abfbc0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284abfbc03004abfbc03004abfbc03004abfbc03004abfbc03004abfbc03004abfbc03004abfbc03004abfbc03004abfbc0300652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474038672ecc000000474038a442e4000000474038e070c000000047403919311000000047403951710c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740374819f8000000474037814a18000000474037b747ec000000474037f3333c0000004740382bb404000000474038672ecc000000474038a442e4000000474038e070c000000047403919311000000047403951710c000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"config/batch_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284bfa4bfa4bfa4bfa4bfa652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284bfa4bfa4bfa4bfa4bfa4bfa4bfa4bfa4bfa4bfa652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646467410.6519392,\n  \"logdir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-03-29/MNISTTrainable_be8ad_00003_3_batch_size=250_2022-03-05_03-03-30\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"MNISTTrainable\",\n  \"trial_id\": \"be8ad_00002\",\n  \"config\": {\n    \"batch_size\": 100\n  },\n  \"local_dir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-03-29\",\n  \"evaluated_params\": {\n    \"batch_size\": 100\n  },\n  \"experiment_tag\": \"2_batch_size=100\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b018c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 99,\n    \"train_accuracy\": 92.10000000000001,\n    \"test_accuracy\": 90.3,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 100,\n    \"experiment_id\": \"59b38b7108804ebdbbd8525cf3542e98\",\n    \"date\": \"2022-03-05_03-04-07\",\n    \"timestamp\": 1646467447,\n    \"time_this_iter_s\": 0.2924673557281494,\n    \"time_total_s\": 34.2637414932251,\n    \"pid\": 244923,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"batch_size\": 100\n    },\n    \"time_since_restore\": 34.2637414932251,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 100,\n    \"trial_id\": \"be8ad_00002\",\n    \"experiment_tag\": \"2_batch_size=100\"\n  },\n  \"last_update_time\": 1646467447.9174242,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 99,\n      \"min\": 0,\n      \"avg\": 49.50000000000002,\n      \"last\": 99,\n      \"last-5-avg\": 97.0,\n      \"last-10-avg\": 94.5\n    },\n    \"train_accuracy\": {\n      \"max\": 92.30000000000001,\n      \"min\": 53.900000000000006,\n      \"avg\": 88.56400000000002,\n      \"last\": 92.10000000000001,\n      \"last-5-avg\": 92.02000000000001,\n      \"last-10-avg\": 92.10000000000001\n    },\n    \"test_accuracy\": {\n      \"max\": 90.5,\n      \"min\": 52.300000000000004,\n      \"avg\": 85.91999999999994,\n      \"last\": 90.3,\n      \"last-5-avg\": 90.22,\n      \"last-10-avg\": 90.2\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.01,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"timestamp\": {\n      \"max\": 1646467447,\n      \"min\": 1646467416,\n      \"avg\": 1646467431.959999,\n      \"last\": 1646467447,\n      \"last-5-avg\": 1646467446.8,\n      \"last-10-avg\": 1646467446.1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2.79551100730896,\n      \"min\": 0.28255295753479004,\n      \"avg\": 0.342637414932251,\n      \"last\": 0.2924673557281494,\n      \"last-5-avg\": 0.2892711639404297,\n      \"last-10-avg\": 0.2891674518585205\n    },\n    \"time_total_s\": {\n      \"max\": 34.2637414932251,\n      \"min\": 2.79551100730896,\n      \"avg\": 18.959761884212494,\n      \"last\": 34.2637414932251,\n      \"last-5-avg\": 33.681889295578,\n      \"last-10-avg\": 32.96091277599335\n    },\n    \"pid\": {\n      \"max\": 244923,\n      \"min\": 244923,\n      \"avg\": 244922.99999999994,\n      \"last\": 244923,\n      \"last-5-avg\": 244923.0,\n      \"last-10-avg\": 244923.0\n    },\n    \"time_since_restore\": {\n      \"max\": 34.2637414932251,\n      \"min\": 2.79551100730896,\n      \"avg\": 18.959761884212494,\n      \"last\": 34.2637414932251,\n      \"last-5-avg\": 33.681889295578,\n      \"last-10-avg\": 32.96091277599335\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"config/batch_size\": {\n      \"max\": 100,\n      \"min\": 100,\n      \"avg\": 99.99999999999997,\n      \"last\": 100,\n      \"last-5-avg\": 100.0,\n      \"last-10-avg\": 100.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5f4b604b614b624b63652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5a4b5b4b5c4b5d4b5e4b5f4b604b614b624b63652e\"\n      }\n    },\n    \"train_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740570ccccccccccd474057000000000000474056eccccccccccd474057066666666667474057066666666667652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740570ccccccccccd4740571333333333344740571333333333344740570ccccccccccd474056f9999999999a4740570ccccccccccd474057000000000000474056eccccccccccd474057066666666667474057066666666667652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847405699999999999a4740566ccccccccccd474056a000000000004740568ccccccccccd474056933333333333652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740568666666666674740568ccccccccccd47405693333333333347405679999999999a47405699999999999a47405699999999999a4740566ccccccccccd474056a000000000004740568ccccccccccd474056933333333333652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a761923624a771923624a771923624a771923624a77192362652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a751923624a751923624a751923624a761923624a761923624a761923624a771923624a771923624a771923624a77192362652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd24b7700000000473fd276f700000000473fd2696900000000473fd2ad7800000000473fd2b7c900000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd2c54c00000000473fd269c700000000473fd21dca00000000473fd2a9a700000000473fd2899600000000473fd24b7700000000473fd276f700000000473fd2696900000000473fd2ad7800000000473fd2b7c900000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740408d3706000000474040b224f4000000474040d6f7c6000000474040fc52b600000047404121c248000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403faa54f800000047403ff3fc140000004740401e399e000000474040438cec00000047404068a0180000004740408d3706000000474040b224f4000000474040d6f7c6000000474040fc52b600000047404121c248000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284abbbc03004abbbc03004abbbc03004abbbc03004abbbc0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284abbbc03004abbbc03004abbbc03004abbbc03004abbbc03004abbbc03004abbbc03004abbbc03004abbbc03004abbbc0300652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740408d3706000000474040b224f4000000474040d6f7c6000000474040fc52b600000047404121c248000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403faa54f800000047403ff3fc140000004740401e399e000000474040438cec00000047404068a0180000004740408d3706000000474040b224f4000000474040d6f7c6000000474040fc52b600000047404121c248000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"config/batch_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b644b644b644b644b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b644b644b644b644b644b644b644b644b644b64652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646467410.6457183,\n  \"logdir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-03-29/MNISTTrainable_be8ad_00002_2_batch_size=100_2022-03-05_03-03-30\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_max_pending_trials": 17,
    "_metric": "test_accuracy",
    "_total_time": 159.98324131965637,
    "_iteration": 418,
    "_has_errored": false,
    "_fail_fast": false,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_updated_queue": true,
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-03-29",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059527000000000000008c107261792e74756e652e73746f70706572948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1646467410.437785,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2022-03-05_03-03-30",
    "checkpoint_file": "/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-03-29/experiment_state-2022-03-05_03-03-30.json",
    "_checkpoint_period": "auto",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1646467410.437785,
    "timestamp": 1646467471.2969718
  }
}