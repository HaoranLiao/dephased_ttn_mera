{
  "checkpoints": [
    "{\n  \"trainable_name\": \"MNISTTrainable\",\n  \"trial_id\": \"07589_00000\",\n  \"config\": {\n    \"batch_size\": 25\n  },\n  \"local_dir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-05-32\",\n  \"evaluated_params\": {\n    \"batch_size\": 25\n  },\n  \"experiment_tag\": \"0_batch_size=25\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b018c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 99,\n    \"train_accuracy\": 92.0,\n    \"test_accuracy\": 91.5,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 100,\n    \"experiment_id\": \"9425a879550e4f3489ef04498a173dcc\",\n    \"date\": \"2022-03-05_03-06-33\",\n    \"timestamp\": 1646467593,\n    \"time_this_iter_s\": 0.45261406898498535,\n    \"time_total_s\": 57.43484687805176,\n    \"pid\": 1069,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"batch_size\": 25\n    },\n    \"time_since_restore\": 57.43484687805176,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 100,\n    \"trial_id\": \"07589_00000\",\n    \"experiment_tag\": \"0_batch_size=25\"\n  },\n  \"last_update_time\": 1646467593.2047558,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 99,\n      \"min\": 0,\n      \"avg\": 49.50000000000002,\n      \"last\": 99,\n      \"last-5-avg\": 97.0,\n      \"last-10-avg\": 94.5\n    },\n    \"train_accuracy\": {\n      \"max\": 92.5,\n      \"min\": 64.60000000000001,\n      \"avg\": 90.73,\n      \"last\": 92.0,\n      \"last-5-avg\": 92.26,\n      \"last-10-avg\": 92.25\n    },\n    \"test_accuracy\": {\n      \"max\": 91.5,\n      \"min\": 52.5,\n      \"avg\": 88.5569999999999,\n      \"last\": 91.5,\n      \"last-5-avg\": 90.82000000000001,\n      \"last-10-avg\": 90.88999999999999\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.01,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"timestamp\": {\n      \"max\": 1646467593,\n      \"min\": 1646467538,\n      \"avg\": 1646467567.4699998,\n      \"last\": 1646467593,\n      \"last-5-avg\": 1646467591.8,\n      \"last-10-avg\": 1646467590.6\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3.063185214996338,\n      \"min\": 0.4476194381713867,\n      \"avg\": 0.5743484687805173,\n      \"last\": 0.45261406898498535,\n      \"last-5-avg\": 0.45543713569641114,\n      \"last-10-avg\": 0.4564528465270996\n    },\n    \"time_total_s\": {\n      \"max\": 57.43484687805176,\n      \"min\": 3.063185214996338,\n      \"avg\": 32.41645922183992,\n      \"last\": 57.43484687805176,\n      \"last-5-avg\": 56.5283296585083,\n      \"last-10-avg\": 55.38472065925598\n    },\n    \"pid\": {\n      \"max\": 1069,\n      \"min\": 1069,\n      \"avg\": 1069.0,\n      \"last\": 1069,\n      \"last-5-avg\": 1069.0,\n      \"last-10-avg\": 1069.0\n    },\n    \"time_since_restore\": {\n      \"max\": 57.43484687805176,\n      \"min\": 3.063185214996338,\n      \"avg\": 32.41645922183992,\n      \"last\": 57.43484687805176,\n      \"last-5-avg\": 56.5283296585083,\n      \"last-10-avg\": 55.38472065925598\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"config/batch_size\": {\n      \"max\": 25,\n      \"min\": 25,\n      \"avg\": 24.999999999999993,\n      \"last\": 25,\n      \"last-5-avg\": 25.0,\n      \"last-10-avg\": 25.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5f4b604b614b624b63652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5a4b5b4b5c4b5d4b5e4b5f4b604b614b624b63652e\"\n      }\n    },\n    \"train_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847405713333333333447405713333333333447405719999999999a474057133333333334474057000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405700000000000047405720000000000047405700000000000047405719999999999a47405713333333333447405713333333333447405713333333333447405719999999999a474057133333333334474057000000000000652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474056c00000000000474056b3333333333347405679999999999a474056b9999999999a474056e00000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474056b33333333333474056b33333333333474056d9999999999a474056c00000000000474056b33333333333474056c00000000000474056b3333333333347405679999999999a474056b9999999999a474056e00000000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a071a23624a071a23624a081a23624a081a23624a091a2362652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a051a23624a051a23624a051a23624a061a23624a061a23624a071a23624a071a23624a081a23624a081a23624a091a2362652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fdd8a8200000000473fdd176400000000473fdd4baa00000000473fdcd83800000000473fdcf7a100000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fdd17fc00000000473fdd087c00000000473fdd9ca800000000473fdd90db00000000473fdd15d800000000473fdd8a8200000000473fdd176400000000473fdd4baa00000000473fdcd83800000000473fdcf7a100000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404bcf434200000047404c09720a00000047404c44095e00000047404c7db9ce00000047404cb7a910000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404aa9969000000047404ae3a78800000047404b1ee0d800000047404b5a028e00000047404b942e3e00000047404bcf434200000047404c09720a00000047404c44095e00000047404c7db9ce00000047404cb7a910000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d2d044d2d044d2d044d2d044d2d04652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d2d044d2d044d2d044d2d044d2d044d2d044d2d044d2d044d2d044d2d04652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404bcf434200000047404c09720a00000047404c44095e00000047404c7db9ce00000047404cb7a910000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404aa9969000000047404ae3a78800000047404b1ee0d800000047404b5a028e00000047404b942e3e00000047404bcf434200000047404c09720a00000047404c44095e00000047404c7db9ce00000047404cb7a910000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"config/batch_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b194b194b194b194b19652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b194b194b194b194b194b194b194b194b194b19652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646467532.788346,\n  \"logdir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-05-32/MNISTTrainable_07589_00000_0_batch_size=25_2022-03-05_03-05-32\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"MNISTTrainable\",\n  \"trial_id\": \"07589_00003\",\n  \"config\": {\n    \"batch_size\": 250\n  },\n  \"local_dir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-05-32\",\n  \"evaluated_params\": {\n    \"batch_size\": 250\n  },\n  \"experiment_tag\": \"3_batch_size=250\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b018c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 99,\n    \"train_accuracy\": 91.4,\n    \"test_accuracy\": 89.4,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 100,\n    \"experiment_id\": \"63bf05730427404282b5521c6516a1a1\",\n    \"date\": \"2022-03-05_03-06-01\",\n    \"timestamp\": 1646467561,\n    \"time_this_iter_s\": 0.2308645248413086,\n    \"time_total_s\": 25.38120746612549,\n    \"pid\": 1068,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"batch_size\": 250\n    },\n    \"time_since_restore\": 25.38120746612549,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 100,\n    \"trial_id\": \"07589_00003\",\n    \"experiment_tag\": \"3_batch_size=250\"\n  },\n  \"last_update_time\": 1646467561.2169623,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 99,\n      \"min\": 0,\n      \"avg\": 49.50000000000002,\n      \"last\": 99,\n      \"last-5-avg\": 97.0,\n      \"last-10-avg\": 94.5\n    },\n    \"train_accuracy\": {\n      \"max\": 91.7,\n      \"min\": 53.6,\n      \"avg\": 83.96299999999995,\n      \"last\": 91.4,\n      \"last-5-avg\": 91.47999999999999,\n      \"last-10-avg\": 91.5\n    },\n    \"test_accuracy\": {\n      \"max\": 90.0,\n      \"min\": 50.7,\n      \"avg\": 80.41300000000001,\n      \"last\": 89.4,\n      \"last-5-avg\": 89.67999999999999,\n      \"last-10-avg\": 89.61999999999999\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.01,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"timestamp\": {\n      \"max\": 1646467561,\n      \"min\": 1646467538,\n      \"avg\": 1646467549.21,\n      \"last\": 1646467561,\n      \"last-5-avg\": 1646467560.2,\n      \"last-10-avg\": 1646467559.7\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2.717592716217041,\n      \"min\": 0.2149355411529541,\n      \"avg\": 0.25381207466125477,\n      \"last\": 0.2308645248413086,\n      \"last-5-avg\": 0.22594566345214845,\n      \"last-10-avg\": 0.22749001979827882\n    },\n    \"time_total_s\": {\n      \"max\": 25.38120746612549,\n      \"min\": 2.717592716217041,\n      \"avg\": 14.095057194232943,\n      \"last\": 25.38120746612549,\n      \"last-5-avg\": 24.928636693954466,\n      \"last-10-avg\": 24.360986995697022\n    },\n    \"pid\": {\n      \"max\": 1068,\n      \"min\": 1068,\n      \"avg\": 1068.0,\n      \"last\": 1068,\n      \"last-5-avg\": 1068.0,\n      \"last-10-avg\": 1068.0\n    },\n    \"time_since_restore\": {\n      \"max\": 25.38120746612549,\n      \"min\": 2.717592716217041,\n      \"avg\": 14.095057194232943,\n      \"last\": 25.38120746612549,\n      \"last-5-avg\": 24.928636693954466,\n      \"last-10-avg\": 24.360986995697022\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"config/batch_size\": {\n      \"max\": 250,\n      \"min\": 250,\n      \"avg\": 249.99999999999994,\n      \"last\": 250,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5f4b604b614b624b63652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5a4b5b4b5c4b5d4b5e4b5f4b604b614b624b63652e\"\n      }\n    },\n    \"train_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474056e66666666667474056e66666666667474056d33333333333474056e00000000000474056d9999999999a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474056eccccccccccd474056eccccccccccd474056cccccccccccd474056d9999999999a474056e66666666667474056e66666666667474056e66666666667474056d33333333333474056e00000000000474056d9999999999a652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847405660000000000047405666666666666747405680000000000047405679999999999a47405659999999999a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405660000000000047405659999999999a4740567333333333334740566ccccccccccd47405659999999999a47405660000000000047405666666666666747405680000000000047405679999999999a47405659999999999a652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ae81923624ae81923624ae81923624ae81923624ae9192362652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ae71923624ae71923624ae71923624ae71923624ae81923624ae81923624ae81923624ae81923624ae81923624ae9192362652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fcda51c00000000473fcc29bc00000000473fcc75ca00000000473fccc95600000000473fcd8cf800000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fccfb8600000000473fcd9eac00000000473fcd763200000000473fcd678200000000473fcd1d1800000000473fcda51c00000000473fcc29bc00000000473fcc75ca00000000473fccc95600000000473fcd8cf800000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740387bab28000000474038b3fea0000000474038ecea34000000474039267ce00000004740396196d0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474037552e00000000474037906b58000000474037cb57bc0000004740380626c00000004740384060f00000004740387bab28000000474038b3fea0000000474038ecea34000000474039267ce00000004740396196d0000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d2c044d2c044d2c044d2c044d2c04652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d2c044d2c044d2c044d2c044d2c044d2c044d2c044d2c044d2c044d2c04652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740387bab28000000474038b3fea0000000474038ecea34000000474039267ce00000004740396196d0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474037552e00000000474037906b58000000474037cb57bc0000004740380626c00000004740384060f00000004740387bab28000000474038b3fea0000000474038ecea34000000474039267ce00000004740396196d0000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"config/batch_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284bfa4bfa4bfa4bfa4bfa652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284bfa4bfa4bfa4bfa4bfa4bfa4bfa4bfa4bfa4bfa652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646467532.808228,\n  \"logdir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-05-32/MNISTTrainable_07589_00003_3_batch_size=250_2022-03-05_03-05-32\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"MNISTTrainable\",\n  \"trial_id\": \"07589_00002\",\n  \"config\": {\n    \"batch_size\": 100\n  },\n  \"local_dir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-05-32\",\n  \"evaluated_params\": {\n    \"batch_size\": 100\n  },\n  \"experiment_tag\": \"2_batch_size=100\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b018c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 99,\n    \"train_accuracy\": 91.9,\n    \"test_accuracy\": 90.60000000000001,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 100,\n    \"experiment_id\": \"ea586ef6da4640da901e56b66cfd40b2\",\n    \"date\": \"2022-03-05_03-06-09\",\n    \"timestamp\": 1646467569,\n    \"time_this_iter_s\": 0.2936127185821533,\n    \"time_total_s\": 34.21665334701538,\n    \"pid\": 1075,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"batch_size\": 100\n    },\n    \"time_since_restore\": 34.21665334701538,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 100,\n    \"trial_id\": \"07589_00002\",\n    \"experiment_tag\": \"2_batch_size=100\"\n  },\n  \"last_update_time\": 1646467569.9530027,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 99,\n      \"min\": 0,\n      \"avg\": 49.50000000000002,\n      \"last\": 99,\n      \"last-5-avg\": 97.0,\n      \"last-10-avg\": 94.5\n    },\n    \"train_accuracy\": {\n      \"max\": 92.5,\n      \"min\": 53.900000000000006,\n      \"avg\": 88.39499999999998,\n      \"last\": 91.9,\n      \"last-5-avg\": 91.88,\n      \"last-10-avg\": 91.9\n    },\n    \"test_accuracy\": {\n      \"max\": 90.9,\n      \"min\": 52.300000000000004,\n      \"avg\": 85.83999999999999,\n      \"last\": 90.60000000000001,\n      \"last-5-avg\": 90.48,\n      \"last-10-avg\": 90.52000000000001\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.01,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"timestamp\": {\n      \"max\": 1646467569,\n      \"min\": 1646467538,\n      \"avg\": 1646467553.9800003,\n      \"last\": 1646467569,\n      \"last-5-avg\": 1646467568.8,\n      \"last-10-avg\": 1646467568.1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2.7773945331573486,\n      \"min\": 0.28048110008239746,\n      \"avg\": 0.3421665334701541,\n      \"last\": 0.2936127185821533,\n      \"last-5-avg\": 0.2892141819000244,\n      \"last-10-avg\": 0.2874821662902832\n    },\n    \"time_total_s\": {\n      \"max\": 34.21665334701538,\n      \"min\": 2.7773945331573486,\n      \"avg\": 18.95137016057968,\n      \"last\": 34.21665334701538,\n      \"last-5-avg\": 33.635766458511355,\n      \"last-10-avg\": 32.91740386486053\n    },\n    \"pid\": {\n      \"max\": 1075,\n      \"min\": 1075,\n      \"avg\": 1075.0,\n      \"last\": 1075,\n      \"last-5-avg\": 1075.0,\n      \"last-10-avg\": 1075.0\n    },\n    \"time_since_restore\": {\n      \"max\": 34.21665334701538,\n      \"min\": 2.7773945331573486,\n      \"avg\": 18.95137016057968,\n      \"last\": 34.21665334701538,\n      \"last-5-avg\": 33.635766458511355,\n      \"last-10-avg\": 32.91740386486053\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"config/batch_size\": {\n      \"max\": 100,\n      \"min\": 100,\n      \"avg\": 99.99999999999997,\n      \"last\": 100,\n      \"last-5-avg\": 100.0,\n      \"last-10-avg\": 100.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5f4b604b614b624b63652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5a4b5b4b5c4b5d4b5e4b5f4b604b614b624b63652e\"\n      }\n    },\n    \"train_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474057066666666667474056cccccccccccd474057133333333334474056f9999999999a474056f9999999999a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474056f33333333333474056f9999999999a474057066666666667474056f9999999999a474056f9999999999a474057066666666667474056cccccccccccd474057133333333334474056f9999999999a474056f9999999999a652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740568ccccccccccd474056b333333333334740568ccccccccccd474056a66666666667474056a66666666667652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474056a66666666667474056a00000000000474056a00000000000474056accccccccccd474056a000000000004740568ccccccccccd474056b333333333334740568ccccccccccd474056a66666666667474056a66666666667652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284af01923624af11923624af11923624af11923624af1192362652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284aef1923624aef1923624aef1923624af01923624af01923624af01923624af11923624af11923624af11923624af1192362652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd24ad600000000473fd2c14400000000473fd22a8900000000473fd28b3d00000000473fd2ca8d00000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd1fcfa00000000473fd288b700000000473fd2585900000000473fd29f3600000000473fd1f36700000000473fd24ad600000000473fd2c14400000000473fd22a8900000000473fd28b3d00000000473fd2ca8d00000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404087381e000000474040acbaa6000000474040d10fb8000000474040f626320000004740411bbb4c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403f9f763000000047403fe9990c000000474040197d380000004740403ebba400000047404062a27200000047404087381e000000474040acbaa6000000474040d10fb8000000474040f626320000004740411bbb4c000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d33044d33044d33044d33044d3304652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d33044d33044d33044d33044d33044d33044d33044d33044d33044d3304652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404087381e000000474040acbaa6000000474040d10fb8000000474040f626320000004740411bbb4c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403f9f763000000047403fe9990c000000474040197d380000004740403ebba400000047404062a27200000047404087381e000000474040acbaa6000000474040d10fb8000000474040f626320000004740411bbb4c000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"config/batch_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b644b644b644b644b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b644b644b644b644b644b644b644b644b644b64652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646467532.8009853,\n  \"logdir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-05-32/MNISTTrainable_07589_00002_2_batch_size=100_2022-03-05_03-05-32\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"MNISTTrainable\",\n  \"trial_id\": \"07589_00001\",\n  \"config\": {\n    \"batch_size\": 50\n  },\n  \"local_dir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-05-32\",\n  \"evaluated_params\": {\n    \"batch_size\": 50\n  },\n  \"experiment_tag\": \"1_batch_size=50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b018c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 99,\n    \"train_accuracy\": 91.5,\n    \"test_accuracy\": 91.10000000000001,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 100,\n    \"experiment_id\": \"0a721b5043e845ac8306059793f59afa\",\n    \"date\": \"2022-03-05_03-06-18\",\n    \"timestamp\": 1646467578,\n    \"time_this_iter_s\": 0.3475005626678467,\n    \"time_total_s\": 42.83975887298584,\n    \"pid\": 1064,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"batch_size\": 50\n    },\n    \"time_since_restore\": 42.83975887298584,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 100,\n    \"trial_id\": \"07589_00001\",\n    \"experiment_tag\": \"1_batch_size=50\"\n  },\n  \"last_update_time\": 1646467578.5442312,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 99,\n      \"min\": 0,\n      \"avg\": 49.50000000000002,\n      \"last\": 99,\n      \"last-5-avg\": 97.0,\n      \"last-10-avg\": 94.5\n    },\n    \"train_accuracy\": {\n      \"max\": 92.9,\n      \"min\": 53.900000000000006,\n      \"avg\": 90.42899999999993,\n      \"last\": 91.5,\n      \"last-5-avg\": 91.82000000000001,\n      \"last-10-avg\": 91.86000000000001\n    },\n    \"test_accuracy\": {\n      \"max\": 91.7,\n      \"min\": 52.300000000000004,\n      \"avg\": 88.70699999999995,\n      \"last\": 91.10000000000001,\n      \"last-5-avg\": 91.2,\n      \"last-10-avg\": 91.22\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.01,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"timestamp\": {\n      \"max\": 1646467578,\n      \"min\": 1646467538,\n      \"avg\": 1646467558.8999994,\n      \"last\": 1646467578,\n      \"last-5-avg\": 1646467577.4,\n      \"last-10-avg\": 1646467576.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2.820483922958374,\n      \"min\": 0.3343179225921631,\n      \"avg\": 0.42839758872985817,\n      \"last\": 0.3475005626678467,\n      \"last-5-avg\": 0.3456775665283203,\n      \"last-10-avg\": 0.3436148643493652\n    },\n    \"time_total_s\": {\n      \"max\": 42.83975887298584,\n      \"min\": 2.820483922958374,\n      \"avg\": 23.88837884187699,\n      \"last\": 42.83975887298584,\n      \"last-5-avg\": 42.14909548759461,\n      \"last-10-avg\": 41.29036996364594\n    },\n    \"pid\": {\n      \"max\": 1064,\n      \"min\": 1064,\n      \"avg\": 1064.0,\n      \"last\": 1064,\n      \"last-5-avg\": 1064.0,\n      \"last-10-avg\": 1064.0\n    },\n    \"time_since_restore\": {\n      \"max\": 42.83975887298584,\n      \"min\": 2.820483922958374,\n      \"avg\": 23.88837884187699,\n      \"last\": 42.83975887298584,\n      \"last-5-avg\": 42.14909548759461,\n      \"last-10-avg\": 41.29036996364594\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"config/batch_size\": {\n      \"max\": 50,\n      \"min\": 50,\n      \"avg\": 49.999999999999986,\n      \"last\": 50,\n      \"last-5-avg\": 50.0,\n      \"last-10-avg\": 50.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5f4b604b614b624b63652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5a4b5b4b5c4b5d4b5e4b5f4b604b614b624b63652e\"\n      }\n    },\n    \"train_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474056f9999999999a474056f9999999999a474056e666666666674740570ccccccccccd474056e00000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474056e66666666667474057000000000000474057000000000000474056f33333333333474057066666666667474056f9999999999a474056f9999999999a474056e666666666674740570ccccccccccd474056e00000000000652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474056d9999999999a474056d33333333333474056cccccccccccd474056c00000000000474056c66666666667652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474056d33333333333474056cccccccccccd474056d33333333333474056c66666666667474056d33333333333474056d9999999999a474056d33333333333474056cccccccccccd474056c00000000000474056c66666666667652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284af91923624af91923624af91923624afa1923624afa192362652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284af71923624af71923624af81923624af81923624af81923624af91923624af91923624af91923624afa1923624afa192362652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd6262100000000473fd67f5000000000473fd5a30300000000473fd6180100000000473fd63d7300000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd633aa00000000473fd5893d00000000473fd618a700000000473fd610ef00000000473fd5657700000000473fd6262100000000473fd67f5000000000473fd5a30300000000473fd6180100000000473fd63d7300000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474044ba8daa000000474044e78c4a00000047404512d2500000004740453f02520000004740456b7d38000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474043e010d40000004740440b234e00000047404437549c00000047404463767a0000004740448e4168000000474044ba8daa000000474044e78c4a00000047404512d2500000004740453f02520000004740456b7d38000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d28044d28044d28044d28044d2804652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d28044d28044d28044d28044d28044d28044d28044d28044d28044d2804652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474044ba8daa000000474044e78c4a00000047404512d2500000004740453f02520000004740456b7d38000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474043e010d40000004740440b234e00000047404437549c00000047404463767a0000004740448e4168000000474044ba8daa000000474044e78c4a00000047404512d2500000004740453f02520000004740456b7d38000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"config/batch_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b324b324b324b324b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b324b324b324b324b324b324b324b324b324b32652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646467532.7955778,\n  \"logdir\": \"/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-05-32/MNISTTrainable_07589_00001_1_batch_size=50_2022-03-05_03-05-32\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_max_pending_trials": 17,
    "_metric": "test_accuracy",
    "_total_time": 159.87246656417847,
    "_iteration": 420,
    "_has_errored": false,
    "_fail_fast": false,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_updated_queue": true,
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-05-32",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059527000000000000008c107261792e74756e652e73746f70706572948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1646467532.5849354,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2022-03-05_03-05-32",
    "checkpoint_file": "/home/haoranliao/ray_results/MNISTTrainable_2022-03-05_03-05-32/experiment_state-2022-03-05_03-05-32.json",
    "_checkpoint_period": "auto",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1646467532.5849354,
    "timestamp": 1646467593.2091665
  }
}