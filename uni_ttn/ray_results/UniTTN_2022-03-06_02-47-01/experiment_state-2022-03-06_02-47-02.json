{
  "checkpoints": [
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"9bfe8_00001\",\n  \"config\": {\n    \"tune_lr\": 0.001,\n    \"tune_init_std\": 0.1\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_02-47-01\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 0.1,\n    \"tune_lr\": 0.001\n  },\n  \"experiment_tag\": \"1_tune_init_std=0.1,tune_lr=0.001\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 2,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b028c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 49,\n    \"test_accuracy\": 92.06098843322819,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 50,\n    \"experiment_id\": \"46d9d5417a95486893c7db91419fe0a9\",\n    \"date\": \"2022-03-06_02-48-03\",\n    \"timestamp\": 1646552883,\n    \"time_this_iter_s\": 1.1210079193115234,\n    \"time_total_s\": 57.774704933166504,\n    \"pid\": 108221,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"tune_lr\": 0.001,\n      \"tune_init_std\": 0.1\n    },\n    \"time_since_restore\": 57.774704933166504,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 50,\n    \"trial_id\": \"9bfe8_00001\",\n    \"experiment_tag\": \"1_tune_init_std=0.1,tune_lr=0.001\"\n  },\n  \"last_update_time\": 1646552883.9521418,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 49,\n      \"min\": 0,\n      \"avg\": 24.499999999999996,\n      \"last\": 49,\n      \"last-5-avg\": 47.0,\n      \"last-10-avg\": 44.5\n    },\n    \"test_accuracy\": {\n      \"max\": 92.16614090431125,\n      \"min\": 54.73186119873817,\n      \"avg\": 88.87697160883273,\n      \"last\": 92.06098843322819,\n      \"last-5-avg\": 92.0820189274448,\n      \"last-10-avg\": 91.98212407991589\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.02,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"timestamp\": {\n      \"max\": 1646552883,\n      \"min\": 1646552829,\n      \"avg\": 1646552856.219999,\n      \"last\": 1646552883,\n      \"last-5-avg\": 1646552881.0,\n      \"last-10-avg\": 1646552878.4\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3.6878764629364014,\n      \"min\": 1.0305001735687256,\n      \"avg\": 1.1554940986633293,\n      \"last\": 1.1210079193115234,\n      \"last-5-avg\": 1.11641206741333,\n      \"last-10-avg\": 1.1097790718078613\n    },\n    \"time_total_s\": {\n      \"max\": 57.774704933166504,\n      \"min\": 3.6878764629364014,\n      \"avg\": 30.69557750701904,\n      \"last\": 57.774704933166504,\n      \"last-5-avg\": 55.52710409164429,\n      \"last-10-avg\": 52.76849622726441\n    },\n    \"pid\": {\n      \"max\": 108221,\n      \"min\": 108221,\n      \"avg\": 108220.99999999999,\n      \"last\": 108221,\n      \"last-5-avg\": 108221.0,\n      \"last-10-avg\": 108221.0\n    },\n    \"time_since_restore\": {\n      \"max\": 57.774704933166504,\n      \"min\": 3.6878764629364014,\n      \"avg\": 30.69557750701904,\n      \"last\": 57.774704933166504,\n      \"last-5-avg\": 55.52710409164429,\n      \"last-10-avg\": 52.76849622726441\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.001,\n      \"min\": 0.001,\n      \"avg\": 0.0010000000000000005,\n      \"last\": 0.001,\n      \"last-5-avg\": 0.001,\n      \"last-10-avg\": 0.0010000000000000002\n    },\n    \"config/tune_init_std\": {\n      \"max\": 0.1,\n      \"min\": 0.1,\n      \"avg\": 0.09999999999999996,\n      \"last\": 0.1,\n      \"last-5-avg\": 0.1,\n      \"last-10-avg\": 0.09999999999999999\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2d4b2e4b2f4b304b31652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b31652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474056fd2c6a9970404740570744a4be96364740570744a4be96364740570aa20d75a2dc47405703e73c07898f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474056e59e8d9817b0474056f671992b56f2474056f9cf01e263994740570089d3507ce847405703e73c07898f474056fd2c6a9970404740570744a4be96364740570744a4be96364740570aa20d75a2dc47405703e73c07898f652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a2f6724624a306724624a316724624a326724624a33672462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a296724624a2b6724624a2c6724624a2d6724624a2e6724624a2f6724624a306724624a316724624a326724624a33672462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ff16eccc0000000473ff1df2e80000000473ff20660c0000000473ff20c1c80000000473ff1efa600000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff20cf1c0000000473ff1cc8780000000473ff1b2a940000000473ff1643100000000473ff1501b00000000473ff16eccc0000000473ff1df2e80000000473ff20660c0000000473ff20c1c80000000473ff1efa600000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404aa41efa00000047404b33186e00000047404bc34b7400000047404c53ac5800000047404ce32988000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474047e70cae0000004740487570ea0000004740490306340000004740498e27bc00000047404a18a89400000047404aa41efa00000047404b33186e00000047404bc34b7400000047404c53ac5800000047404ce32988000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284abda601004abda601004abda601004abda601004abda60100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284abda601004abda601004abda601004abda601004abda601004abda601004abda601004abda601004abda601004abda60100652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404aa41efa00000047404b33186e00000047404bc34b7400000047404c53ac5800000047404ce32988000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474047e70cae0000004740487570ea0000004740490306340000004740498e27bc00000047404a18a89400000047404aa41efa00000047404b33186e00000047404bc34b7400000047404c53ac5800000047404ce32988000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646552822.5353174,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_02-47-01/UniTTN_9bfe8_00001_1_tune_init_std=0.1,tune_lr=0.001_2022-03-06_02-47-02\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"9bfe8_00000\",\n  \"config\": {\n    \"tune_lr\": 0.001,\n    \"tune_init_std\": 1\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_02-47-01\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 1,\n    \"tune_lr\": 0.001\n  },\n  \"experiment_tag\": \"0_tune_init_std=1,tune_lr=0.001\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 2,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b028c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 49,\n    \"test_accuracy\": 91.11461619348054,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 50,\n    \"experiment_id\": \"ceb0154f242f47d6983db646fc3cd07b\",\n    \"date\": \"2022-03-06_02-48-04\",\n    \"timestamp\": 1646552884,\n    \"time_this_iter_s\": 0.9625086784362793,\n    \"time_total_s\": 57.7818820476532,\n    \"pid\": 108219,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"tune_lr\": 0.001,\n      \"tune_init_std\": 1\n    },\n    \"time_since_restore\": 57.7818820476532,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 50,\n    \"trial_id\": \"9bfe8_00000\",\n    \"experiment_tag\": \"0_tune_init_std=1,tune_lr=0.001\"\n  },\n  \"last_update_time\": 1646552884.7901318,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 49,\n      \"min\": 0,\n      \"avg\": 24.499999999999996,\n      \"last\": 49,\n      \"last-5-avg\": 47.0,\n      \"last-10-avg\": 44.5\n    },\n    \"test_accuracy\": {\n      \"max\": 91.11461619348054,\n      \"min\": 68.98002103049421,\n      \"avg\": 87.74973711882227,\n      \"last\": 91.11461619348054,\n      \"last-5-avg\": 90.97791798107255,\n      \"last-10-avg\": 90.83070452155626\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.02,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"timestamp\": {\n      \"max\": 1646552884,\n      \"min\": 1646552830,\n      \"avg\": 1646552857.3799996,\n      \"last\": 1646552884,\n      \"last-5-avg\": 1646552882.0,\n      \"last-10-avg\": 1646552879.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 4.051512002944946,\n      \"min\": 0.9625086784362793,\n      \"avg\": 1.1556376409530635,\n      \"last\": 0.9625086784362793,\n      \"last-5-avg\": 1.0581353664398194,\n      \"last-10-avg\": 1.0839673042297364\n    },\n    \"time_total_s\": {\n      \"max\": 57.7818820476532,\n      \"min\": 4.051512002944946,\n      \"avg\": 31.011948313713066,\n      \"last\": 57.7818820476532,\n      \"last-5-avg\": 55.726006269454956,\n      \"last-10-avg\": 52.99989213943481\n    },\n    \"pid\": {\n      \"max\": 108219,\n      \"min\": 108219,\n      \"avg\": 108218.99999999999,\n      \"last\": 108219,\n      \"last-5-avg\": 108219.0,\n      \"last-10-avg\": 108219.0\n    },\n    \"time_since_restore\": {\n      \"max\": 57.7818820476532,\n      \"min\": 4.051512002944946,\n      \"avg\": 31.011948313713066,\n      \"last\": 57.7818820476532,\n      \"last-5-avg\": 55.726006269454956,\n      \"last-10-avg\": 52.99989213943481\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.001,\n      \"min\": 0.001,\n      \"avg\": 0.0010000000000000005,\n      \"last\": 0.001,\n      \"last-5-avg\": 0.001,\n      \"last-10-avg\": 0.0010000000000000002\n    },\n    \"config/tune_init_std\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2d4b2e4b2f4b304b31652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b31652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474056b9e03c4c7337474056b9e03c4c7337474056bd3da5037fde474056c09b0dba8c84474056c755df28a5d2652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474056a5afc802274d474056ac6a9970409b474056ac6a9970409b474056b3256ade59e9474056a90d30b933f4474056b9e03c4c7337474056b9e03c4c7337474056bd3da5037fde474056c09b0dba8c84474056c755df28a5d2652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a306724624a316724624a326724624a336724624a34672462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a2b6724624a2c6724624a2d6724624a2e6724624a2f6724624a306724624a316724624a326724624a336724624a34672462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ff1a6aa00000000473ff14bc6c0000000473ff1566440000000473ff0f75840000000473feeccdf00000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff1c259c0000000473ff2141b00000000473ff1a023c0000000473ff137d8c0000000473ff21a3f00000000473ff1a6aa00000000473ff14bc6c0000000473ff1566440000000473ff0f75840000000473feeccdf00000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404acc152000000047404b56735600000047404be1267800000047404c68e13a00000047404ce414b6000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404806ad1c000000474048974df4000000474049244f12000000474049ae0dd800000047404a3edfd000000047404acc152000000047404b56735600000047404be1267800000047404c68e13a00000047404ce414b6000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284abba601004abba601004abba601004abba601004abba60100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284abba601004abba601004abba601004abba601004abba601004abba601004abba601004abba601004abba601004abba60100652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404acc152000000047404b56735600000047404be1267800000047404c68e13a00000047404ce414b6000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404806ad1c000000474048974df4000000474049244f12000000474049ae0dd800000047404a3edfd000000047404acc152000000047404b56735600000047404be1267800000047404c68e13a00000047404ce414b6000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646552822.5264087,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_02-47-01/UniTTN_9bfe8_00000_0_tune_init_std=1,tune_lr=0.001_2022-03-06_02-47-02\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"9bfe8_00002\",\n  \"config\": {\n    \"tune_lr\": 0.001,\n    \"tune_init_std\": 0.01\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_02-47-01\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 0.01,\n    \"tune_lr\": 0.001\n  },\n  \"experiment_tag\": \"2_tune_init_std=0.01,tune_lr=0.001\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 2,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b028c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 99,\n    \"test_accuracy\": 92.63932702418506,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 100,\n    \"experiment_id\": \"f70950b0625f4cff908e1e637107a586\",\n    \"date\": \"2022-03-06_02-48-40\",\n    \"timestamp\": 1646552920,\n    \"time_this_iter_s\": 0.7533247470855713,\n    \"time_total_s\": 95.17151594161987,\n    \"pid\": 108209,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"tune_lr\": 0.001,\n      \"tune_init_std\": 0.01\n    },\n    \"time_since_restore\": 95.17151594161987,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 100,\n    \"trial_id\": \"9bfe8_00002\",\n    \"experiment_tag\": \"2_tune_init_std=0.01,tune_lr=0.001\"\n  },\n  \"last_update_time\": 1646552920.736562,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 99,\n      \"min\": 0,\n      \"avg\": 49.50000000000002,\n      \"last\": 99,\n      \"last-5-avg\": 97.0,\n      \"last-10-avg\": 94.5\n    },\n    \"test_accuracy\": {\n      \"max\": 92.90220820189275,\n      \"min\": 53.10199789695058,\n      \"avg\": 89.37697160883282,\n      \"last\": 92.63932702418506,\n      \"last-5-avg\": 92.52365930599369,\n      \"last-10-avg\": 92.55520504731861\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.01,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"timestamp\": {\n      \"max\": 1646552920,\n      \"min\": 1646552828,\n      \"avg\": 1646552878.0499995,\n      \"last\": 1646552920,\n      \"last-5-avg\": 1646552918.6,\n      \"last-10-avg\": 1646552916.7\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3.4885900020599365,\n      \"min\": 0.7409543991088867,\n      \"avg\": 0.9517151594161984,\n      \"last\": 0.7533247470855713,\n      \"last-5-avg\": 0.7581710338592529,\n      \"last-10-avg\": 0.7572487115859985\n    },\n    \"time_total_s\": {\n      \"max\": 95.17151594161987,\n      \"min\": 3.4885900020599365,\n      \"avg\": 53.238801760673525,\n      \"last\": 95.17151594161987,\n      \"last-5-avg\": 93.66379146575927,\n      \"last-10-avg\": 91.76289176940918\n    },\n    \"pid\": {\n      \"max\": 108209,\n      \"min\": 108209,\n      \"avg\": 108208.99999999993,\n      \"last\": 108209,\n      \"last-5-avg\": 108209.0,\n      \"last-10-avg\": 108209.0\n    },\n    \"time_since_restore\": {\n      \"max\": 95.17151594161987,\n      \"min\": 3.4885900020599365,\n      \"avg\": 53.238801760673525,\n      \"last\": 95.17151594161987,\n      \"last-5-avg\": 93.66379146575927,\n      \"last-10-avg\": 91.76289176940918\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.001,\n      \"min\": 0.001,\n      \"avg\": 0.0010000000000000009,\n      \"last\": 0.001,\n      \"last-5-avg\": 0.001,\n      \"last-10-avg\": 0.0010000000000000002\n    },\n    \"config/tune_init_std\": {\n      \"max\": 0.01,\n      \"min\": 0.01,\n      \"avg\": 0.010000000000000009,\n      \"last\": 0.01,\n      \"last-5-avg\": 0.01,\n      \"last-10-avg\": 0.009999999999999998\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5f4b604b614b624b63652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5a4b5b4b5c4b5d4b5e4b5f4b604b614b624b63652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740571ed281bfeec647405736605ec147564740571b751908e21f4740570dff762caf8347405728eabbe514ba652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740572fa58d532e084740572c48249c216147405739bdc77853fd4740570089d3507ce8474057258d532e08144740571ed281bfeec647405736605ec147564740571b751908e21f4740570dff762caf8347405728eabbe514ba652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a556724624a566724624a576724624a576724624a58672462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a516724624a526724624a536724624a546724624a546724624a556724624a566724624a576724624a576724624a58672462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe86f3800000000473fe8a05400000000473fe83c9600000000473fe7e75100000000473fe81b3c80000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe7d4e880000000473fe85aa100000000473fe869c280000000473fe7d8ce80000000473fe8910680000000473fe86f3800000000473fe8a05400000000473fe83c9600000000473fe7e75100000000473fe81b3c80000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474057093b2f0000004740573a7bd70000004740576af5030000004740579ac3a5000000474057cafa1e000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405616004e00000047405646b590000000474056778915000000474056a73ab2000000474056d85cbf000000474057093b2f0000004740573a7bd70000004740576af5030000004740579ac3a5000000474057cafa1e000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ab1a601004ab1a601004ab1a601004ab1a601004ab1a60100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ab1a601004ab1a601004ab1a601004ab1a601004ab1a601004ab1a601004ab1a601004ab1a601004ab1a601004ab1a60100652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474057093b2f0000004740573a7bd70000004740576af5030000004740579ac3a5000000474057cafa1e000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405616004e00000047405646b590000000474056778915000000474056a73ab2000000474056d85cbf000000474057093b2f0000004740573a7bd70000004740576af5030000004740579ac3a5000000474057cafa1e000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646552822.5408278,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_02-47-01/UniTTN_9bfe8_00002_2_tune_init_std=0.01,tune_lr=0.001_2022-03-06_02-47-02\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"9bfe8_00003\",\n  \"config\": {\n    \"tune_lr\": 0.003,\n    \"tune_init_std\": 1\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_02-47-01\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 1,\n    \"tune_lr\": 0.003\n  },\n  \"experiment_tag\": \"3_tune_init_std=1,tune_lr=0.003\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 2,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b028c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 99,\n    \"test_accuracy\": 93.4279705573081,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 100,\n    \"experiment_id\": \"09e4161c1da54fba89984f706c855292\",\n    \"date\": \"2022-03-06_02-48-41\",\n    \"timestamp\": 1646552921,\n    \"time_this_iter_s\": 0.687171220779419,\n    \"time_total_s\": 95.69412422180176,\n    \"pid\": 108213,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"tune_lr\": 0.003,\n      \"tune_init_std\": 1\n    },\n    \"time_since_restore\": 95.69412422180176,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 100,\n    \"trial_id\": \"9bfe8_00003\",\n    \"experiment_tag\": \"3_tune_init_std=1,tune_lr=0.003\"\n  },\n  \"last_update_time\": 1646552921.6375828,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 99,\n      \"min\": 0,\n      \"avg\": 49.50000000000002,\n      \"last\": 99,\n      \"last-5-avg\": 97.0,\n      \"last-10-avg\": 94.5\n    },\n    \"test_accuracy\": {\n      \"max\": 93.48054679284962,\n      \"min\": 66.29863301787591,\n      \"avg\": 92.1603575184017,\n      \"last\": 93.4279705573081,\n      \"last-5-avg\": 93.27024185068349,\n      \"last-10-avg\": 93.24395373291271\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.01,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"timestamp\": {\n      \"max\": 1646552921,\n      \"min\": 1646552829,\n      \"avg\": 1646552878.9399993,\n      \"last\": 1646552921,\n      \"last-5-avg\": 1646552919.6,\n      \"last-10-avg\": 1646552917.7\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3.5730433464050293,\n      \"min\": 0.687171220779419,\n      \"avg\": 0.956941242218018,\n      \"last\": 0.687171220779419,\n      \"last-5-avg\": 0.7436396598815918,\n      \"last-10-avg\": 0.7566099643707276\n    },\n    \"time_total_s\": {\n      \"max\": 95.69412422180176,\n      \"min\": 3.5730433464050293,\n      \"avg\": 53.70399089574813,\n      \"last\": 95.69412422180176,\n      \"last-5-avg\": 94.2401134967804,\n      \"last-10-avg\": 92.33922820091247\n    },\n    \"pid\": {\n      \"max\": 108213,\n      \"min\": 108213,\n      \"avg\": 108212.99999999993,\n      \"last\": 108213,\n      \"last-5-avg\": 108213.0,\n      \"last-10-avg\": 108213.0\n    },\n    \"time_since_restore\": {\n      \"max\": 95.69412422180176,\n      \"min\": 3.5730433464050293,\n      \"avg\": 53.70399089574813,\n      \"last\": 95.69412422180176,\n      \"last-5-avg\": 94.2401134967804,\n      \"last-10-avg\": 92.33922820091247\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.003,\n      \"min\": 0.003,\n      \"avg\": 0.003000000000000002,\n      \"last\": 0.003,\n      \"last-5-avg\": 0.003,\n      \"last-10-avg\": 0.0029999999999999996\n    },\n    \"config/tune_init_std\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999993,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5f4b604b614b624b63652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5a4b5b4b5c4b5d4b5e4b5f4b604b614b624b63652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847405754a90d30b93447405754a90d30b93447405747336a5486984740574a90d30b933f4740575b63de9ed282652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474057407898e66d4a474057580675e7c5db474057580675e7c5db4740574dee3bc29fe647405747336a54869847405754a90d30b93447405754a90d30b93447405747336a5486984740574a90d30b933f4740575b63de9ed282652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a566724624a576724624a586724624a586724624a59672462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a526724624a536724624a546724624a556724624a556724624a566724624a576724624a586724624a586724624a59672462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe8877b80000000473fe82f1100000000473fe856e380000000473fe7f0bc80000000473fe5fd4e80000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe8db0500000000473fe87fcd00000000473fe8a42000000000473fe850e680000000473fe8d22980000000473fe8877b80000000473fe82f1100000000473fe856e380000000473fe7f0bc80000000473fe5fd4e80000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740572f84890000004740575fe2ab000000474057909072000000474057c071eb000000474057ec6c88000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405639e7980000004740566ae7320000004740569c2f72000000474056ccd13f000000474056fe75920000004740572f84890000004740575fe2ab000000474057909072000000474057c071eb000000474057ec6c88000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ab5a601004ab5a601004ab5a601004ab5a601004ab5a60100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ab5a601004ab5a601004ab5a601004ab5a601004ab5a601004ab5a601004ab5a601004ab5a601004ab5a601004ab5a60100652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740572f84890000004740575fe2ab000000474057909072000000474057c071eb000000474057ec6c88000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405639e7980000004740566ae7320000004740569c2f72000000474056ccd13f000000474056fe75920000004740572f84890000004740575fe2ab000000474057909072000000474057c071eb000000474057ec6c88000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646552822.546683,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_02-47-01/UniTTN_9bfe8_00003_3_tune_init_std=1,tune_lr=0.003_2022-03-06_02-47-02\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"9bfe8_00005\",\n  \"config\": {\n    \"tune_lr\": 0.003,\n    \"tune_init_std\": 0.01\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_02-47-01\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 0.01,\n    \"tune_lr\": 0.003\n  },\n  \"experiment_tag\": \"5_tune_init_std=0.01,tune_lr=0.003\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 2,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b028c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 99,\n    \"test_accuracy\": 92.48159831756047,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 100,\n    \"experiment_id\": \"9d2f5c7d1e2e44b3baad951c8d1b4e00\",\n    \"date\": \"2022-03-06_02-48-42\",\n    \"timestamp\": 1646552922,\n    \"time_this_iter_s\": 0.5965702533721924,\n    \"time_total_s\": 95.24552917480469,\n    \"pid\": 108223,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"tune_lr\": 0.003,\n      \"tune_init_std\": 0.01\n    },\n    \"time_since_restore\": 95.24552917480469,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 100,\n    \"trial_id\": \"9bfe8_00005\",\n    \"experiment_tag\": \"5_tune_init_std=0.01,tune_lr=0.003\"\n  },\n  \"last_update_time\": 1646552922.8630345,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 99,\n      \"min\": 0,\n      \"avg\": 49.50000000000002,\n      \"last\": 99,\n      \"last-5-avg\": 97.0,\n      \"last-10-avg\": 94.5\n    },\n    \"test_accuracy\": {\n      \"max\": 92.90220820189275,\n      \"min\": 53.10199789695058,\n      \"avg\": 91.43270241850688,\n      \"last\": 92.48159831756047,\n      \"last-5-avg\": 92.48159831756047,\n      \"last-10-avg\": 92.5236593059937\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.01,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"timestamp\": {\n      \"max\": 1646552922,\n      \"min\": 1646552831,\n      \"avg\": 1646552880.9599993,\n      \"last\": 1646552922,\n      \"last-5-avg\": 1646552921.0,\n      \"last-10-avg\": 1646552919.2\n    },\n    \"time_this_iter_s\": {\n      \"max\": 4.221465826034546,\n      \"min\": 0.5965702533721924,\n      \"avg\": 0.9524552917480469,\n      \"last\": 0.5965702533721924,\n      \"last-5-avg\": 0.6732709407806396,\n      \"last-10-avg\": 0.7165908336639404\n    },\n    \"time_total_s\": {\n      \"max\": 95.24552917480469,\n      \"min\": 4.221465826034546,\n      \"avg\": 54.065004928112025,\n      \"last\": 95.24552917480469,\n      \"last-5-avg\": 93.99003920555114,\n      \"last-10-avg\": 92.17183408737182\n    },\n    \"pid\": {\n      \"max\": 108223,\n      \"min\": 108223,\n      \"avg\": 108222.99999999993,\n      \"last\": 108223,\n      \"last-5-avg\": 108223.0,\n      \"last-10-avg\": 108223.0\n    },\n    \"time_since_restore\": {\n      \"max\": 95.24552917480469,\n      \"min\": 4.221465826034546,\n      \"avg\": 54.065004928112025,\n      \"last\": 95.24552917480469,\n      \"last-5-avg\": 93.99003920555114,\n      \"last-10-avg\": 92.17183408737182\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.003,\n      \"min\": 0.003,\n      \"avg\": 0.003000000000000002,\n      \"last\": 0.003,\n      \"last-5-avg\": 0.003,\n      \"last-10-avg\": 0.0029999999999999996\n    },\n    \"config/tune_init_std\": {\n      \"max\": 0.01,\n      \"min\": 0.01,\n      \"avg\": 0.010000000000000009,\n      \"last\": 0.01,\n      \"last-5-avg\": 0.01,\n      \"last-10-avg\": 0.009999999999999998\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5f4b604b614b624b63652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5a4b5b4b5c4b5d4b5e4b5f4b604b614b624b63652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474057222fea76fb6d4740571817b051d578474057258d532e08144740571b751908e21f4740571ed281bfeec6652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405728eabbe514ba4740571ed281bfeec6474057258d532e08144740572c48249c21614740571b751908e21f474057222fea76fb6d4740571817b051d578474057258d532e08144740571b751908e21f4740571ed281bfeec6652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a586724624a586724624a596724624a5a6724624a5a672462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a546724624a556724624a556724624a566724624a576724624a586724624a586724624a596724624a5a6724624a5a672462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe860ea00000000473fe751cf80000000473fe59b6780000000473fe353f200000000473fe3171a80000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe7d2ee00000000473fe858f600000000473fe8db4800000000473fe8344400000000473fe85a8180000000473fe860ea00000000473fe751cf80000000473fe59b6780000000473fe353f200000000473fe3171a80000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847405729063900000047405757a9d800000047405782e0a7000000474057a9888b000000474057cfb6c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405634be5e00000047405665704a0000004740569726da000000474056c78f62000000474056f8446500000047405729063900000047405757a9d800000047405782e0a7000000474057a9888b000000474057cfb6c0000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284abfa601004abfa601004abfa601004abfa601004abfa60100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284abfa601004abfa601004abfa601004abfa601004abfa601004abfa601004abfa601004abfa601004abfa601004abfa60100652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847405729063900000047405757a9d800000047405782e0a7000000474057a9888b000000474057cfb6c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405634be5e00000047405665704a0000004740569726da000000474056c78f62000000474056f8446500000047405729063900000047405757a9d800000047405782e0a7000000474057a9888b000000474057cfb6c0000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646552822.5692816,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_02-47-01/UniTTN_9bfe8_00005_5_tune_init_std=0.01,tune_lr=0.003_2022-03-06_02-47-02\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"9bfe8_00004\",\n  \"config\": {\n    \"tune_lr\": 0.003,\n    \"tune_init_std\": 0.1\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_02-47-01\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 0.1,\n    \"tune_lr\": 0.003\n  },\n  \"experiment_tag\": \"4_tune_init_std=0.1,tune_lr=0.003\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 2,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b028c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 49,\n    \"test_accuracy\": 92.3764458464774,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 50,\n    \"experiment_id\": \"db5e300dfed3419dbc9e6fa7b6264607\",\n    \"date\": \"2022-03-06_02-48-04\",\n    \"timestamp\": 1646552884,\n    \"time_this_iter_s\": 1.0209987163543701,\n    \"time_total_s\": 57.875651121139526,\n    \"pid\": 108218,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"tune_lr\": 0.003,\n      \"tune_init_std\": 0.1\n    },\n    \"time_since_restore\": 57.875651121139526,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 50,\n    \"trial_id\": \"9bfe8_00004\",\n    \"experiment_tag\": \"4_tune_init_std=0.1,tune_lr=0.003\"\n  },\n  \"last_update_time\": 1646552884.4664938,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 49,\n      \"min\": 0,\n      \"avg\": 24.499999999999996,\n      \"last\": 49,\n      \"last-5-avg\": 47.0,\n      \"last-10-avg\": 44.5\n    },\n    \"test_accuracy\": {\n      \"max\": 92.6919032597266,\n      \"min\": 61.3564668769716,\n      \"avg\": 91.24710830704522,\n      \"last\": 92.3764458464774,\n      \"last-5-avg\": 92.42902208201895,\n      \"last-10-avg\": 92.43953732912725\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.02,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"timestamp\": {\n      \"max\": 1646552884,\n      \"min\": 1646552830,\n      \"avg\": 1646552856.9799998,\n      \"last\": 1646552884,\n      \"last-5-avg\": 1646552882.0,\n      \"last-10-avg\": 1646552879.1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 4.006795644760132,\n      \"min\": 1.0209987163543701,\n      \"avg\": 1.15751302242279,\n      \"last\": 1.0209987163543701,\n      \"last-5-avg\": 1.0850361824035644,\n      \"last-10-avg\": 1.0835692405700683\n    },\n    \"time_total_s\": {\n      \"max\": 57.875651121139526,\n      \"min\": 4.006795644760132,\n      \"avg\": 31.006497030258167,\n      \"last\": 57.875651121139526,\n      \"last-5-avg\": 55.72615008354187,\n      \"last-10-avg\": 53.011114430427554\n    },\n    \"pid\": {\n      \"max\": 108218,\n      \"min\": 108218,\n      \"avg\": 108217.99999999999,\n      \"last\": 108218,\n      \"last-5-avg\": 108218.0,\n      \"last-10-avg\": 108218.0\n    },\n    \"time_since_restore\": {\n      \"max\": 57.875651121139526,\n      \"min\": 4.006795644760132,\n      \"avg\": 31.006497030258167,\n      \"last\": 57.875651121139526,\n      \"last-5-avg\": 55.72615008354187,\n      \"last-10-avg\": 53.011114430427554\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.003,\n      \"min\": 0.003,\n      \"avg\": 0.003000000000000001,\n      \"last\": 0.003,\n      \"last-5-avg\": 0.003,\n      \"last-10-avg\": 0.0029999999999999996\n    },\n    \"config/tune_init_std\": {\n      \"max\": 0.1,\n      \"min\": 0.1,\n      \"avg\": 0.09999999999999996,\n      \"last\": 0.1,\n      \"last-5-avg\": 0.1,\n      \"last-10-avg\": 0.09999999999999999\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2d4b2e4b2f4b304b31652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b31652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740570dff762caf83474057258d532e08144740571ed281bfeec64740571ed281bfeec64740571817b051d578652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740571817b051d5784740571817b051d5784740572c48249c2161474057115cdee3bc2a474057222fea76fb6d4740570dff762caf83474057258d532e08144740571ed281bfeec64740571ed281bfeec64740571817b051d578652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a306724624a316724624a326724624a336724624a34672462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a2a6724624a2b6724624a2c6724624a2d6724624a2f6724624a306724624a316724624a326724624a336724624a34672462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ff16e7500000000473ff1695140000000473ff1aad8c0000000473ff1f4e8c0000000473ff05602c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff18a9b80000000473ff1516240000000473ff1473400000000473ff13ee580000000473ff12f5d40000000473ff16e7500000000473ff1695140000000473ff1aad8c0000000473ff1f4e8c0000000473ff05602c0000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404ac51caa00000047404b50673400000047404bddbdfa00000047404c6d654000000047404cf01556000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404811723a0000004740489bfd4c0000004740492636ec000000474049b02e1800000047404a39a90200000047404ac51caa00000047404b50673400000047404bddbdfa00000047404c6d654000000047404cf01556000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284abaa601004abaa601004abaa601004abaa601004abaa60100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284abaa601004abaa601004abaa601004abaa601004abaa601004abaa601004abaa601004abaa601004abaa601004abaa60100652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404ac51caa00000047404b50673400000047404bddbdfa00000047404c6d654000000047404cf01556000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404811723a0000004740489bfd4c0000004740492636ec000000474049b02e1800000047404a39a90200000047404ac51caa00000047404b50673400000047404bddbdfa00000047404c6d654000000047404cf01556000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646552822.5539732,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_02-47-01/UniTTN_9bfe8_00004_4_tune_init_std=0.1,tune_lr=0.003_2022-03-06_02-47-02\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_max_pending_trials": 17,
    "_metric": "test_accuracy",
    "_total_time": 459.54340744018555,
    "_iteration": 468,
    "_has_errored": false,
    "_fail_fast": false,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_updated_queue": true,
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_02-47-01",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059527000000000000008c107261792e74756e652e73746f70706572948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1646552822.3271978,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2022-03-06_02-47-02",
    "checkpoint_file": "/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_02-47-01/experiment_state-2022-03-06_02-47-02.json",
    "_checkpoint_period": "auto",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1646552822.3271978,
    "timestamp": 1646552914.0309012
  }
}