{
  "checkpoints": [
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"7def9_00007\",\n  \"config\": {\n    \"num_anc\": 1,\n    \"deph_p\": 1,\n    \"tune_lr\": 0.005,\n    \"tune_init_std\": 0.001\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 0.001,\n    \"tune_lr\": 0.005\n  },\n  \"experiment_tag\": \"7_tune_init_std=0.001,tune_lr=0.005\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 10,\n    \"gpu\": 1,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b0a8c03475055944b018c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 49,\n    \"test_accuracy\": 91.85068349106203,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 50,\n    \"experiment_id\": \"ebfe7bcffa4541e995d251fabe303e19\",\n    \"date\": \"2022-03-06_04-25-13\",\n    \"timestamp\": 1646558713,\n    \"time_this_iter_s\": 0.552161455154419,\n    \"time_total_s\": 30.80938959121704,\n    \"pid\": 146038,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"num_anc\": 1,\n      \"deph_p\": 1,\n      \"tune_lr\": 0.005,\n      \"tune_init_std\": 0.001\n    },\n    \"time_since_restore\": 30.80938959121704,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 50,\n    \"trial_id\": \"7def9_00007\",\n    \"experiment_tag\": \"7_tune_init_std=0.001,tune_lr=0.005\"\n  },\n  \"last_update_time\": 1646558713.8149784,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 49,\n      \"min\": 0,\n      \"avg\": 24.499999999999996,\n      \"last\": 49,\n      \"last-5-avg\": 47.0,\n      \"last-10-avg\": 44.5\n    },\n    \"test_accuracy\": {\n      \"max\": 92.06098843322819,\n      \"min\": 53.10199789695058,\n      \"avg\": 88.9116719242902,\n      \"last\": 91.85068349106203,\n      \"last-5-avg\": 91.86119873817033,\n      \"last-10-avg\": 91.91377497371187\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.02,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"timestamp\": {\n      \"max\": 1646558713,\n      \"min\": 1646558686,\n      \"avg\": 1646558699.7399998,\n      \"last\": 1646558713,\n      \"last-5-avg\": 1646558712.2,\n      \"last-10-avg\": 1646558710.8\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3.7938835620880127,\n      \"min\": 0.5431346893310547,\n      \"avg\": 0.6161877918243406,\n      \"last\": 0.552161455154419,\n      \"last-5-avg\": 0.5495646476745606,\n      \"last-10-avg\": 0.5525638580322265\n    },\n    \"time_total_s\": {\n      \"max\": 30.80938959121704,\n      \"min\": 3.7938835620880127,\n      \"avg\": 17.315013427734375,\n      \"last\": 30.80938959121704,\n      \"last-5-avg\": 29.70926547050476,\n      \"last-10-avg\": 28.33339946269989\n    },\n    \"pid\": {\n      \"max\": 146038,\n      \"min\": 146038,\n      \"avg\": 146038.0,\n      \"last\": 146038,\n      \"last-5-avg\": 146038.0,\n      \"last-10-avg\": 146038.0\n    },\n    \"time_since_restore\": {\n      \"max\": 30.80938959121704,\n      \"min\": 3.7938835620880127,\n      \"avg\": 17.315013427734375,\n      \"last\": 30.80938959121704,\n      \"last-5-avg\": 29.70926547050476,\n      \"last-10-avg\": 28.33339946269989\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"config/num_anc\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/deph_p\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.005,\n      \"min\": 0.005,\n      \"avg\": 0.005000000000000001,\n      \"last\": 0.005,\n      \"last-5-avg\": 0.005,\n      \"last-10-avg\": 0.004999999999999999\n    },\n    \"config/tune_init_std\": {\n      \"max\": 0.001,\n      \"min\": 0.001,\n      \"avg\": 0.0010000000000000005,\n      \"last\": 0.001,\n      \"last-5-avg\": 0.001,\n      \"last-10-avg\": 0.0010000000000000002\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2d4b2e4b2f4b304b31652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b31652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474056f671992b56f2474056f9cf01e26399474056f671992b56f2474056f671992b56f2474056f671992b56f2652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740570089d3507ce847405703e73c07898f474056fd2c6a997040474056fd2c6a997040474056f671992b56f2474056f671992b56f2474056f9cf01e26399474056f671992b56f2474056f671992b56f2474056f671992b56f2652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284af77d24624af87d24624af87d24624af97d24624af97d2462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284af47d24624af57d24624af57d24624af67d24624af77d24624af77d24624af87d24624af87d24624af97d24624af97d2462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe18c8f80000000473fe1961500000000473fe19ee180000000473fe1815680000000473fe1ab4e80000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe1fbae00000000473fe2118980000000473fe1b01500000000473fe166c580000000473fe1bfcb00000000473fe18c8f80000000473fe1961500000000473fe19ee180000000473fe1815680000000473fe1ab4e80000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403c9c274c00000047403d28d7f400000047403db5cf0000000047403e41d9b400000047403ecf3428000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039d8815800000047403a690da400000047403af68e4c00000047403b81c47800000047403c0fc2d000000047403c9c274c00000047403d28d7f400000047403db5cf0000000047403e41d9b400000047403ecf3428000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a763a02004a763a02004a763a02004a763a02004a763a0200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a763a02004a763a02004a763a02004a763a02004a763a02004a763a02004a763a02004a763a02004a763a02004a763a0200652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403c9c274c00000047403d28d7f400000047403db5cf0000000047403e41d9b400000047403ecf3428000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039d8815800000047403a690da400000047403af68e4c00000047403b81c47800000047403c0fc2d000000047403c9c274c00000047403d28d7f400000047403db5cf0000000047403e41d9b400000047403ecf3428000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"config/num_anc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/deph_p\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646558679.6908298,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1/UniTTN_7def9_00007_7_tune_init_std=0.001,tune_lr=0.005_2022-03-06_04-24-05\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"7def9_00003\",\n  \"config\": {\n    \"num_anc\": 1,\n    \"deph_p\": 1,\n    \"tune_lr\": 0.001,\n    \"tune_init_std\": 0.001\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 0.001,\n    \"tune_lr\": 0.001\n  },\n  \"experiment_tag\": \"3_tune_init_std=0.001,tune_lr=0.001\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 10,\n    \"gpu\": 1,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b0a8c03475055944b018c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 49,\n    \"test_accuracy\": 92.58675078864354,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 50,\n    \"experiment_id\": \"a188a17ee67043498c61972e537b6ab2\",\n    \"date\": \"2022-03-06_04-22-29\",\n    \"timestamp\": 1646558549,\n    \"time_this_iter_s\": 0.5462634563446045,\n    \"time_total_s\": 30.64315128326416,\n    \"pid\": 146035,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"num_anc\": 1,\n      \"deph_p\": 1,\n      \"tune_lr\": 0.001,\n      \"tune_init_std\": 0.001\n    },\n    \"time_since_restore\": 30.64315128326416,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 50,\n    \"trial_id\": \"7def9_00003\",\n    \"experiment_tag\": \"3_tune_init_std=0.001,tune_lr=0.001\"\n  },\n  \"last_update_time\": 1646558549.0271306,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 49,\n      \"min\": 0,\n      \"avg\": 24.499999999999996,\n      \"last\": 49,\n      \"last-5-avg\": 47.0,\n      \"last-10-avg\": 44.5\n    },\n    \"test_accuracy\": {\n      \"max\": 92.58675078864354,\n      \"min\": 53.10199789695058,\n      \"avg\": 84.98948475289166,\n      \"last\": 92.58675078864354,\n      \"last-5-avg\": 92.57623554153523,\n      \"last-10-avg\": 92.49211356466876\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.02,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"timestamp\": {\n      \"max\": 1646558549,\n      \"min\": 1646558522,\n      \"avg\": 1646558535.08,\n      \"last\": 1646558549,\n      \"last-5-avg\": 1646558547.4,\n      \"last-10-avg\": 1646558546.1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3.78067684173584,\n      \"min\": 0.5373835563659668,\n      \"avg\": 0.6128630256652832,\n      \"last\": 0.5462634563446045,\n      \"last-5-avg\": 0.5441487312316895,\n      \"last-10-avg\": 0.5452491044998169\n    },\n    \"time_total_s\": {\n      \"max\": 30.64315128326416,\n      \"min\": 3.78067684173584,\n      \"avg\": 17.255249319076533,\n      \"last\": 30.64315128326416,\n      \"last-5-avg\": 29.557028436660765,\n      \"last-10-avg\": 28.195422410964966\n    },\n    \"pid\": {\n      \"max\": 146035,\n      \"min\": 146035,\n      \"avg\": 146035.0,\n      \"last\": 146035,\n      \"last-5-avg\": 146035.0,\n      \"last-10-avg\": 146035.0\n    },\n    \"time_since_restore\": {\n      \"max\": 30.64315128326416,\n      \"min\": 3.78067684173584,\n      \"avg\": 17.255249319076533,\n      \"last\": 30.64315128326416,\n      \"last-5-avg\": 29.557028436660765,\n      \"last-10-avg\": 28.195422410964966\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"config/num_anc\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/deph_p\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.001,\n      \"min\": 0.001,\n      \"avg\": 0.0010000000000000005,\n      \"last\": 0.001,\n      \"last-5-avg\": 0.001,\n      \"last-10-avg\": 0.0010000000000000002\n    },\n    \"config/tune_init_std\": {\n      \"max\": 0.001,\n      \"min\": 0.001,\n      \"avg\": 0.0010000000000000005,\n      \"last\": 0.001,\n      \"last-5-avg\": 0.001,\n      \"last-10-avg\": 0.0010000000000000002\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2d4b2e4b2f4b304b31652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b31652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474057222fea76fb6d474057258d532e0814474057258d532e0814474057258d532e0814474057258d532e0814652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405714ba479ac8d147405714ba479ac8d14740571b751908e21f4740571b751908e21f474057222fea76fb6d474057222fea76fb6d474057258d532e0814474057258d532e0814474057258d532e0814474057258d532e0814652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a527d24624a537d24624a537d24624a547d24624a557d2462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a507d24624a507d24624a517d24624a517d24624a527d24624a527d24624a537d24624a537d24624a547d24624a557d2462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe188bd80000000473fe16fd180000000473fe16a8980000000473fe1323f00000000473fe17afd80000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe1b46d80000000473fe15c1c00000000473fe17eea00000000473fe1995580000000473fe141b080000000473fe188bd80000000473fe16fd180000000473fe16a8980000000473fe1323f00000000473fe17afd80000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403c7868d400000047403d03e76000000047403d8f3bac00000047403e18cda400000047403ea4a590000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039be728800000047403a49536800000047403ad54ab800000047403b62156400000047403bec22e800000047403c7868d400000047403d03e76000000047403d8f3bac00000047403e18cda400000047403ea4a590000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a733a02004a733a02004a733a02004a733a02004a733a0200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a733a02004a733a02004a733a02004a733a02004a733a02004a733a02004a733a02004a733a02004a733a02004a733a0200652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403c7868d400000047403d03e76000000047403d8f3bac00000047403e18cda400000047403ea4a590000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039be728800000047403a49536800000047403ad54ab800000047403b62156400000047403bec22e800000047403c7868d400000047403d03e76000000047403d8f3bac00000047403e18cda400000047403ea4a590000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"config/num_anc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/deph_p\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646558515.0430384,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1/UniTTN_7def9_00003_3_tune_init_std=0.001,tune_lr=0.001_2022-03-06_04-21-20\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"7def9_00011\",\n  \"config\": {\n    \"num_anc\": 1,\n    \"deph_p\": 1,\n    \"tune_lr\": 0.025,\n    \"tune_init_std\": 0.001\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 0.001,\n    \"tune_lr\": 0.025\n  },\n  \"experiment_tag\": \"11_tune_init_std=0.001,tune_lr=0.025\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 10,\n    \"gpu\": 1,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b0a8c03475055944b018c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 99,\n    \"test_accuracy\": 94.05888538380653,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 100,\n    \"experiment_id\": \"1782a0ec53b2499fa92c467c4d429456\",\n    \"date\": \"2022-03-06_04-28-26\",\n    \"timestamp\": 1646558906,\n    \"time_this_iter_s\": 0.5593059062957764,\n    \"time_total_s\": 58.51328134536743,\n    \"pid\": 146036,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"num_anc\": 1,\n      \"deph_p\": 1,\n      \"tune_lr\": 0.025,\n      \"tune_init_std\": 0.001\n    },\n    \"time_since_restore\": 58.51328134536743,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 100,\n    \"trial_id\": \"7def9_00011\",\n    \"experiment_tag\": \"11_tune_init_std=0.001,tune_lr=0.025\"\n  },\n  \"last_update_time\": 1646558906.6272335,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 99,\n      \"min\": 0,\n      \"avg\": 49.50000000000002,\n      \"last\": 99,\n      \"last-5-avg\": 97.0,\n      \"last-10-avg\": 94.5\n    },\n    \"test_accuracy\": {\n      \"max\": 94.21661409043112,\n      \"min\": 68.87486855941115,\n      \"avg\": 93.43322818086224,\n      \"last\": 94.05888538380653,\n      \"last-5-avg\": 94.07991587802313,\n      \"last-10-avg\": 94.08517350157732\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.01,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"timestamp\": {\n      \"max\": 1646558906,\n      \"min\": 1646558851,\n      \"avg\": 1646558878.6299996,\n      \"last\": 1646558906,\n      \"last-5-avg\": 1646558905.0,\n      \"last-10-avg\": 1646558903.6\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3.8500452041625977,\n      \"min\": 0.5423188209533691,\n      \"avg\": 0.5851328134536743,\n      \"last\": 0.5593059062957764,\n      \"last-5-avg\": 0.5567298889160156,\n      \"last-10-avg\": 0.5543739557266235\n    },\n    \"time_total_s\": {\n      \"max\": 58.51328134536743,\n      \"min\": 3.8500452041625977,\n      \"avg\": 31.193735809326174,\n      \"last\": 58.51328134536743,\n      \"last-5-avg\": 57.39675941467285,\n      \"last-10-avg\": 56.01226634979248\n    },\n    \"pid\": {\n      \"max\": 146036,\n      \"min\": 146036,\n      \"avg\": 146036.0,\n      \"last\": 146036,\n      \"last-5-avg\": 146036.0,\n      \"last-10-avg\": 146036.0\n    },\n    \"time_since_restore\": {\n      \"max\": 58.51328134536743,\n      \"min\": 3.8500452041625977,\n      \"avg\": 31.193735809326174,\n      \"last\": 58.51328134536743,\n      \"last-5-avg\": 57.39675941467285,\n      \"last-10-avg\": 56.01226634979248\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"config/num_anc\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999993,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/deph_p\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999993,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.025,\n      \"min\": 0.025,\n      \"avg\": 0.024999999999999953,\n      \"last\": 0.025,\n      \"last-5-avg\": 0.025,\n      \"last-10-avg\": 0.024999999999999998\n    },\n    \"config/tune_init_std\": {\n      \"max\": 0.001,\n      \"min\": 0.001,\n      \"avg\": 0.0010000000000000009,\n      \"last\": 0.001,\n      \"last-5-avg\": 0.001,\n      \"last-10-avg\": 0.0010000000000000002\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5f4b604b614b624b63652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5a4b5b4b5c4b5d4b5e4b5f4b604b614b624b63652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740578a7f98a183a347405787222fea76fc47405783c4c7336a5547405780675e7c5dae47405783c4c7336a55652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405787222fea76fc47405787222fea76fc47405780675e7c5dae47405787222fea76fc47405787222fea76fc4740578a7f98a183a347405787222fea76fc47405783c4c7336a5547405780675e7c5dae47405783c4c7336a55652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ab87e24624ab87e24624ab97e24624aba7e24624aba7e2462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ab57e24624ab67e24624ab67e24624ab77e24624ab77e24624ab87e24624ab87e24624ab97e24624aba7e24624aba7e2462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe1b68f80000000473fe1a01d00000000473fe2182800000000473fe1befe00000000473fe1e5d580000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe1a0d800000000473fe1d6cc80000000473fe1bf3980000000473fe1784880000000473fe1a38200000000473fe1b68f80000000473fe1a01d00000000473fe2182800000000473fe1befe00000000473fe1e5d580000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404c243ed200000047404c6abf4600000047404cb31fe600000047404cfa1bde00000047404d41b334000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404ac29d5200000047404b09f88400000047404b50f56a00000047404b96d68c00000047404bdd649400000047404c243ed200000047404c6abf4600000047404cb31fe600000047404cfa1bde00000047404d41b334000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a743a02004a743a02004a743a02004a743a02004a743a0200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a743a02004a743a02004a743a02004a743a02004a743a02004a743a02004a743a02004a743a02004a743a02004a743a0200652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404c243ed200000047404c6abf4600000047404cb31fe600000047404cfa1bde00000047404d41b334000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404ac29d5200000047404b09f88400000047404b50f56a00000047404b96d68c00000047404bdd649400000047404c243ed200000047404c6abf4600000047404cb31fe600000047404cfa1bde00000047404d41b334000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"config/num_anc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/deph_p\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646558844.6138997,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1/UniTTN_7def9_00011_11_tune_init_std=0.001,tune_lr=0.025_2022-03-06_04-26-50\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"7def9_00014\",\n  \"config\": {\n    \"num_anc\": 1,\n    \"deph_p\": 1,\n    \"tune_lr\": 0.125,\n    \"tune_init_std\": 0.01\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 0.01,\n    \"tune_lr\": 0.125\n  },\n  \"experiment_tag\": \"14_tune_init_std=0.01,tune_lr=0.125\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 10,\n    \"gpu\": 1,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b0a8c03475055944b018c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 49,\n    \"test_accuracy\": 92.06098843322819,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 50,\n    \"experiment_id\": \"69acfeb98a96418a862437a35e5c8dc7\",\n    \"date\": \"2022-03-06_04-30-09\",\n    \"timestamp\": 1646559009,\n    \"time_this_iter_s\": 0.5471115112304688,\n    \"time_total_s\": 30.652836561203003,\n    \"pid\": 146031,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"num_anc\": 1,\n      \"deph_p\": 1,\n      \"tune_lr\": 0.125,\n      \"tune_init_std\": 0.01\n    },\n    \"time_since_restore\": 30.652836561203003,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 50,\n    \"trial_id\": \"7def9_00014\",\n    \"experiment_tag\": \"14_tune_init_std=0.01,tune_lr=0.125\"\n  },\n  \"last_update_time\": 1646559009.2588997,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 49,\n      \"min\": 0,\n      \"avg\": 24.499999999999996,\n      \"last\": 49,\n      \"last-5-avg\": 47.0,\n      \"last-10-avg\": 44.5\n    },\n    \"test_accuracy\": {\n      \"max\": 92.534174553102,\n      \"min\": 89.80021030494217,\n      \"avg\": 91.48054679284962,\n      \"last\": 92.06098843322819,\n      \"last-5-avg\": 92.14511041009465,\n      \"last-10-avg\": 92.13985278654049\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.02,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"timestamp\": {\n      \"max\": 1646559009,\n      \"min\": 1646558982,\n      \"avg\": 1646558995.1799994,\n      \"last\": 1646559009,\n      \"last-5-avg\": 1646559007.8,\n      \"last-10-avg\": 1646559006.3\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3.6449663639068604,\n      \"min\": 0.5427255630493164,\n      \"avg\": 0.6130567312240599,\n      \"last\": 0.5471115112304688,\n      \"last-5-avg\": 0.545146894454956,\n      \"last-10-avg\": 0.5474606037139893\n    },\n    \"time_total_s\": {\n      \"max\": 30.652836561203003,\n      \"min\": 3.6449663639068604,\n      \"avg\": 17.16849589347839,\n      \"last\": 30.652836561203003,\n      \"last-5-avg\": 29.561805295944215,\n      \"last-10-avg\": 28.19467329978943\n    },\n    \"pid\": {\n      \"max\": 146031,\n      \"min\": 146031,\n      \"avg\": 146031.0,\n      \"last\": 146031,\n      \"last-5-avg\": 146031.0,\n      \"last-10-avg\": 146031.0\n    },\n    \"time_since_restore\": {\n      \"max\": 30.652836561203003,\n      \"min\": 3.6449663639068604,\n      \"avg\": 17.16849589347839,\n      \"last\": 30.652836561203003,\n      \"last-5-avg\": 29.561805295944215,\n      \"last-10-avg\": 28.19467329978943\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"config/num_anc\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/deph_p\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.125,\n      \"min\": 0.125,\n      \"avg\": 0.12499999999999999,\n      \"last\": 0.125,\n      \"last-5-avg\": 0.125,\n      \"last-10-avg\": 0.125\n    },\n    \"config/tune_init_std\": {\n      \"max\": 0.01,\n      \"min\": 0.01,\n      \"avg\": 0.010000000000000002,\n      \"last\": 0.01,\n      \"last-5-avg\": 0.01,\n      \"last-10-avg\": 0.009999999999999998\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2d4b2e4b2f4b304b31652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b31652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740570dff762caf8347405703e73c07898f4740570744a4be9636474057115cdee3bc2a47405703e73c07898f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740570dff762caf834740570dff762caf8347405714ba479ac8d14740570aa20d75a2dc474056efb6c7bd3da54740570dff762caf8347405703e73c07898f4740570744a4be9636474057115cdee3bc2a47405703e73c07898f652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a1f7f24624a1f7f24624a207f24624a207f24624a217f2462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a1c7f24624a1c7f24624a1d7f24624a1d7f24624a1e7f24624a1f7f24624a1f7f24624a207f24624a207f24624a217f2462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe16a4b80000000473fe1800700000000473fe15e0200000000473fe16ef300000000473fe181f000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe18ea200000000473fe1a4b980000000473fe1a3c780000000473fe17cc000000000473fe1a2de80000000473fe16a4b80000000473fe1800700000000473fe15e0200000000473fe16ef300000000473fe181f000000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403c78a8ec00000047403d04a92400000047403d8f993400000047403e1b10cc00000047403ea7204c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039ba159400000047403a473b6000000047403ad4599c00000047403b603f9c00000047403bed569000000047403c78a8ec00000047403d04a92400000047403d8f993400000047403e1b10cc00000047403ea7204c000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a6f3a02004a6f3a02004a6f3a02004a6f3a02004a6f3a0200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a6f3a02004a6f3a02004a6f3a02004a6f3a02004a6f3a02004a6f3a02004a6f3a02004a6f3a02004a6f3a02004a6f3a0200652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403c78a8ec00000047403d04a92400000047403d8f993400000047403e1b10cc00000047403ea7204c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039ba159400000047403a473b6000000047403ad4599c00000047403b603f9c00000047403bed569000000047403c78a8ec00000047403d04a92400000047403d8f993400000047403e1b10cc00000047403ea7204c000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"config/num_anc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/deph_p\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646558975.2510996,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1/UniTTN_7def9_00014_14_tune_init_std=0.01,tune_lr=0.125_2022-03-06_04-29-00\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"7def9_00008\",\n  \"config\": {\n    \"num_anc\": 1,\n    \"deph_p\": 1,\n    \"tune_lr\": 0.025,\n    \"tune_init_std\": 1\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 1,\n    \"tune_lr\": 0.025\n  },\n  \"experiment_tag\": \"8_tune_init_std=1,tune_lr=0.025\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 10,\n    \"gpu\": 1,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b0a8c03475055944b018c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 49,\n    \"test_accuracy\": 90.95688748685595,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 50,\n    \"experiment_id\": \"1daeb24af7c249698c97340769638041\",\n    \"date\": \"2022-03-06_04-25-48\",\n    \"timestamp\": 1646558748,\n    \"time_this_iter_s\": 0.553502082824707,\n    \"time_total_s\": 31.075834274291992,\n    \"pid\": 146028,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"num_anc\": 1,\n      \"deph_p\": 1,\n      \"tune_lr\": 0.025,\n      \"tune_init_std\": 1\n    },\n    \"time_since_restore\": 31.075834274291992,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 50,\n    \"trial_id\": \"7def9_00008\",\n    \"experiment_tag\": \"8_tune_init_std=1,tune_lr=0.025\"\n  },\n  \"last_update_time\": 1646558748.1629508,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 49,\n      \"min\": 0,\n      \"avg\": 24.499999999999996,\n      \"last\": 49,\n      \"last-5-avg\": 47.0,\n      \"last-10-avg\": 44.5\n    },\n    \"test_accuracy\": {\n      \"max\": 91.58780231335436,\n      \"min\": 79.91587802313354,\n      \"avg\": 89.44689800210303,\n      \"last\": 90.95688748685595,\n      \"last-5-avg\": 91.09358569926394,\n      \"last-10-avg\": 91.23028391167193\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.02,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"timestamp\": {\n      \"max\": 1646558748,\n      \"min\": 1646558720,\n      \"avg\": 1646558733.939999,\n      \"last\": 1646558748,\n      \"last-5-avg\": 1646558746.6,\n      \"last-10-avg\": 1646558745.2\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3.7887425422668457,\n      \"min\": 0.5467562675476074,\n      \"avg\": 0.6215166854858396,\n      \"last\": 0.553502082824707,\n      \"last-5-avg\": 0.5547651767730712,\n      \"last-10-avg\": 0.5562549114227295\n    },\n    \"time_total_s\": {\n      \"max\": 31.075834274291992,\n      \"min\": 3.7887425422668457,\n      \"avg\": 17.43045644760132,\n      \"last\": 31.075834274291992,\n      \"last-5-avg\": 29.96656403541565,\n      \"last-10-avg\": 28.57519886493683\n    },\n    \"pid\": {\n      \"max\": 146028,\n      \"min\": 146028,\n      \"avg\": 146028.0,\n      \"last\": 146028,\n      \"last-5-avg\": 146028.0,\n      \"last-10-avg\": 146028.0\n    },\n    \"time_since_restore\": {\n      \"max\": 31.075834274291992,\n      \"min\": 3.7887425422668457,\n      \"avg\": 17.43045644760132,\n      \"last\": 31.075834274291992,\n      \"last-5-avg\": 29.96656403541565,\n      \"last-10-avg\": 28.57519886493683\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"config/num_anc\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/deph_p\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.025,\n      \"min\": 0.025,\n      \"avg\": 0.02499999999999999,\n      \"last\": 0.025,\n      \"last-5-avg\": 0.025,\n      \"last-10-avg\": 0.024999999999999998\n    },\n    \"config/tune_init_std\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2d4b2e4b2f4b304b31652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b31652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474056d4cb8204d86e474056e24124e10b09474056bd3da5037fde474056ac6a9970409b474056bd3da5037fde652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474056b3256ade59e9474056dee3bc29fe62474056dee3bc29fe62474056e59e8d9817b0474056dee3bc29fe62474056d4cb8204d86e474056e24124e10b09474056bd3da5037fde474056ac6a9970409b474056bd3da5037fde652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a197e24624a1a7e24624a1b7e24624a1b7e24624a1c7e2462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a177e24624a177e24624a187e24624a187e24624a197e24624a197e24624a1a7e24624a1b7e24624a1b7e24624a1c7e2462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe1a8d600000000473fe1db7480000000473fe1d2b500000000473fe1b5e500000000473fe1b64a00000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe1c04e00000000473fe1bf8b80000000473fe1ece700000000473fe1f2ca00000000473fe1ddae00000000473fe1a8d600000000473fe1db7480000000473fe1d2b500000000473fe1b5e500000000473fe1b64a00000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403cda971c00000047403d6972c000000047403df8086800000047403e85b79000000047403f1369e0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403a11691800000047403a9f657400000047403b2eccac00000047403bbe62fc00000047403c4d506c00000047403cda971c00000047403d6972c000000047403df8086800000047403e85b79000000047403f1369e0000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a6c3a02004a6c3a02004a6c3a02004a6c3a02004a6c3a0200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a6c3a02004a6c3a02004a6c3a02004a6c3a02004a6c3a02004a6c3a02004a6c3a02004a6c3a02004a6c3a02004a6c3a0200652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403cda971c00000047403d6972c000000047403df8086800000047403e85b79000000047403f1369e0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403a11691800000047403a9f657400000047403b2eccac00000047403bbe62fc00000047403c4d506c00000047403cda971c00000047403d6972c000000047403df8086800000047403e85b79000000047403f1369e0000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"config/num_anc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/deph_p\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646558713.8197794,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1/UniTTN_7def9_00008_8_tune_init_std=1,tune_lr=0.025_2022-03-06_04-24-39\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"7def9_00012\",\n  \"config\": {\n    \"num_anc\": 1,\n    \"deph_p\": 1,\n    \"tune_lr\": 0.125,\n    \"tune_init_std\": 1\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 1,\n    \"tune_lr\": 0.125\n  },\n  \"experiment_tag\": \"12_tune_init_std=1,tune_lr=0.125\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 10,\n    \"gpu\": 1,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b0a8c03475055944b018c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 49,\n    \"test_accuracy\": 89.37960042060989,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 50,\n    \"experiment_id\": \"fbd46f0d33b04e1a97fbcb7fb55eb354\",\n    \"date\": \"2022-03-06_04-29-00\",\n    \"timestamp\": 1646558940,\n    \"time_this_iter_s\": 0.5519821643829346,\n    \"time_total_s\": 30.877601385116577,\n    \"pid\": 146027,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"num_anc\": 1,\n      \"deph_p\": 1,\n      \"tune_lr\": 0.125,\n      \"tune_init_std\": 1\n    },\n    \"time_since_restore\": 30.877601385116577,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 50,\n    \"trial_id\": \"7def9_00012\",\n    \"experiment_tag\": \"12_tune_init_std=1,tune_lr=0.125\"\n  },\n  \"last_update_time\": 1646558940.8567798,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 49,\n      \"min\": 0,\n      \"avg\": 24.499999999999996,\n      \"last\": 49,\n      \"last-5-avg\": 47.0,\n      \"last-10-avg\": 44.5\n    },\n    \"test_accuracy\": {\n      \"max\": 89.90536277602523,\n      \"min\": 84.9106203995794,\n      \"avg\": 89.05993690851734,\n      \"last\": 89.37960042060989,\n      \"last-5-avg\": 89.31650893796005,\n      \"last-10-avg\": 89.2429022082019\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.02,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"timestamp\": {\n      \"max\": 1646558940,\n      \"min\": 1646558913,\n      \"avg\": 1646558926.7199998,\n      \"last\": 1646558940,\n      \"last-5-avg\": 1646558939.2,\n      \"last-10-avg\": 1646558937.8\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3.8397390842437744,\n      \"min\": 0.5436573028564453,\n      \"avg\": 0.6175520277023313,\n      \"last\": 0.5519821643829346,\n      \"last-5-avg\": 0.5525200366973877,\n      \"last-10-avg\": 0.5554113388061523\n    },\n    \"time_total_s\": {\n      \"max\": 30.877601385116577,\n      \"min\": 3.8397390842437744,\n      \"avg\": 17.351102662086483,\n      \"last\": 30.877601385116577,\n      \"last-5-avg\": 29.77134041786194,\n      \"last-10-avg\": 28.389646458625794\n    },\n    \"pid\": {\n      \"max\": 146027,\n      \"min\": 146027,\n      \"avg\": 146027.0,\n      \"last\": 146027,\n      \"last-5-avg\": 146027.0,\n      \"last-10-avg\": 146027.0\n    },\n    \"time_since_restore\": {\n      \"max\": 30.877601385116577,\n      \"min\": 3.8397390842437744,\n      \"avg\": 17.351102662086483,\n      \"last\": 30.877601385116577,\n      \"last-5-avg\": 29.77134041786194,\n      \"last-10-avg\": 28.389646458625794\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"config/num_anc\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/deph_p\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.125,\n      \"min\": 0.125,\n      \"avg\": 0.12499999999999999,\n      \"last\": 0.125,\n      \"last-5-avg\": 0.125,\n      \"last-10-avg\": 0.125\n    },\n    \"config/tune_init_std\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2d4b2e4b2f4b304b31652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b31652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740564ad5bcb3d1b3474056584b5f90044f47405651908e21eb01474056584b5f90044f474056584b5f90044f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405640bd828eabbe4740564e33256ade5a474056441aeb45b86547405654edf6d8f7a84740564e33256ade5a4740564ad5bcb3d1b3474056584b5f90044f47405651908e21eb01474056584b5f90044f474056584b5f90044f652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ada7e24624adb7e24624adb7e24624adc7e24624adc7e2462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ad77e24624ad87e24624ad87e24624ad97e24624ada7e24624ada7e24624adb7e24624adb7e24624adc7e24624adc7e2462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe1aeeb80000000473fe1809400000000473fe1d12280000000473fe1bcc000000000473fe1a9d680000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe2196b00000000473fe2313980000000473fe1c54980000000473fe1abab80000000473fe1987a00000000473fe1aeeb80000000473fe1809400000000473fe1d12280000000473fe1bcc000000000473fe1a9d680000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403caae81400000047403d36ecb400000047403dc575c800000047403e535bc800000047403ee0aa7c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039e39b7400000047403a75254000000047403b034f8c00000047403b90ace800000047403c1d70b800000047403caae81400000047403d36ecb400000047403dc575c800000047403e535bc800000047403ee0aa7c000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a6b3a02004a6b3a02004a6b3a02004a6b3a02004a6b3a0200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a6b3a02004a6b3a02004a6b3a02004a6b3a02004a6b3a02004a6b3a02004a6b3a02004a6b3a02004a6b3a02004a6b3a0200652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403caae81400000047403d36ecb400000047403dc575c800000047403e535bc800000047403ee0aa7c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039e39b7400000047403a75254000000047403b034f8c00000047403b90ace800000047403c1d70b800000047403caae81400000047403d36ecb400000047403dc575c800000047403e535bc800000047403ee0aa7c000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"config/num_anc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/deph_p\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646558906.6317823,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1/UniTTN_7def9_00012_12_tune_init_std=1,tune_lr=0.125_2022-03-06_04-27-24\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"7def9_00015\",\n  \"config\": {\n    \"num_anc\": 1,\n    \"deph_p\": 1,\n    \"tune_lr\": 0.125,\n    \"tune_init_std\": 0.001\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 0.001,\n    \"tune_lr\": 0.125\n  },\n  \"experiment_tag\": \"15_tune_init_std=0.001,tune_lr=0.125\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 10,\n    \"gpu\": 1,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b0a8c03475055944b018c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 49,\n    \"test_accuracy\": 91.58780231335436,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 50,\n    \"experiment_id\": \"61996750f2364ce486eb6e54c4740d23\",\n    \"date\": \"2022-03-06_04-30-43\",\n    \"timestamp\": 1646559043,\n    \"time_this_iter_s\": 0.548741340637207,\n    \"time_total_s\": 30.628461360931396,\n    \"pid\": 146030,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"num_anc\": 1,\n      \"deph_p\": 1,\n      \"tune_lr\": 0.125,\n      \"tune_init_std\": 0.001\n    },\n    \"time_since_restore\": 30.628461360931396,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 50,\n    \"trial_id\": \"7def9_00015\",\n    \"experiment_tag\": \"15_tune_init_std=0.001,tune_lr=0.125\"\n  },\n  \"last_update_time\": 1646559043.2241745,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 49,\n      \"min\": 0,\n      \"avg\": 24.499999999999996,\n      \"last\": 49,\n      \"last-5-avg\": 47.0,\n      \"last-10-avg\": 44.5\n    },\n    \"test_accuracy\": {\n      \"max\": 92.42902208201893,\n      \"min\": 87.85488958990535,\n      \"avg\": 90.54679284963197,\n      \"last\": 91.58780231335436,\n      \"last-5-avg\": 91.64037854889591,\n      \"last-10-avg\": 91.70347003154575\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.02,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"timestamp\": {\n      \"max\": 1646559043,\n      \"min\": 1646559016,\n      \"avg\": 1646559029.1599998,\n      \"last\": 1646559043,\n      \"last-5-avg\": 1646559041.6,\n      \"last-10-avg\": 1646559040.2\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3.6507062911987305,\n      \"min\": 0.5423843860626221,\n      \"avg\": 0.6125692272186276,\n      \"last\": 0.548741340637207,\n      \"last-5-avg\": 0.5572686672210694,\n      \"last-10-avg\": 0.5516142129898072\n    },\n    \"time_total_s\": {\n      \"max\": 30.628461360931396,\n      \"min\": 3.6507062911987305,\n      \"avg\": 17.13734924316406,\n      \"last\": 30.628461360931396,\n      \"last-5-avg\": 29.517771816253664,\n      \"last-10-avg\": 28.13411455154419\n    },\n    \"pid\": {\n      \"max\": 146030,\n      \"min\": 146030,\n      \"avg\": 146030.0,\n      \"last\": 146030,\n      \"last-5-avg\": 146030.0,\n      \"last-10-avg\": 146030.0\n    },\n    \"time_since_restore\": {\n      \"max\": 30.628461360931396,\n      \"min\": 3.6507062911987305,\n      \"avg\": 17.13734924316406,\n      \"last\": 30.628461360931396,\n      \"last-5-avg\": 29.517771816253664,\n      \"last-10-avg\": 28.13411455154419\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"config/num_anc\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/deph_p\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.125,\n      \"min\": 0.125,\n      \"avg\": 0.12499999999999999,\n      \"last\": 0.125,\n      \"last-5-avg\": 0.125,\n      \"last-10-avg\": 0.125\n    },\n    \"config/tune_init_std\": {\n      \"max\": 0.001,\n      \"min\": 0.001,\n      \"avg\": 0.0010000000000000005,\n      \"last\": 0.001,\n      \"last-5-avg\": 0.001,\n      \"last-10-avg\": 0.0010000000000000002\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2d4b2e4b2f4b304b31652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b31652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474056e8fbf64f24574740570089d3507ce8474056e8fbf64f2457474056d4cb8204d86e474056e59e8d9817b0652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740570089d3507ce8474056ec595f0630fe474056e24124e10b09474056f31430744a4c474056f31430744a4c474056e8fbf64f24574740570089d3507ce8474056e8fbf64f2457474056d4cb8204d86e474056e59e8d9817b0652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a407f24624a417f24624a427f24624a427f24624a437f2462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a3e7f24624a3e7f24624a3f7f24624a3f7f24624a407f24624a407f24624a417f24624a427f24624a427f24624a437f2462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe1c8cb00000000473fe1f94900000000473fe209ab80000000473fe1ceb000000000473fe18f4a00000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe164cf00000000473fe18a9080000000473fe18e4b80000000473fe1701b00000000473fe16cbd00000000473fe1c8cb00000000473fe1f94900000000473fe209ab80000000473fe1ceb000000000473fe18f4a00000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403c65db6400000047403cf5a5ac00000047403d85f30800000047403e14688800000047403ea0e2d8000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039a7e76c00000047403a343bf000000047403ac0ae4c00000047403b4c2f2400000047403bd7950c00000047403c65db6400000047403cf5a5ac00000047403d85f30800000047403e14688800000047403ea0e2d8000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a6e3a02004a6e3a02004a6e3a02004a6e3a02004a6e3a0200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a6e3a02004a6e3a02004a6e3a02004a6e3a02004a6e3a02004a6e3a02004a6e3a02004a6e3a02004a6e3a02004a6e3a0200652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403c65db6400000047403cf5a5ac00000047403d85f30800000047403e14688800000047403ea0e2d8000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039a7e76c00000047403a343bf000000047403ac0ae4c00000047403b4c2f2400000047403bd7950c00000047403c65db6400000047403cf5a5ac00000047403d85f30800000047403e14688800000047403ea0e2d8000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"config/num_anc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/deph_p\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646559009.2680087,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1/UniTTN_7def9_00015_15_tune_init_std=0.001,tune_lr=0.125_2022-03-06_04-29-35\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"7def9_00009\",\n  \"config\": {\n    \"num_anc\": 1,\n    \"deph_p\": 1,\n    \"tune_lr\": 0.025,\n    \"tune_init_std\": 0.1\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 0.1,\n    \"tune_lr\": 0.025\n  },\n  \"experiment_tag\": \"9_tune_init_std=0.1,tune_lr=0.025\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 10,\n    \"gpu\": 1,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b0a8c03475055944b018c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 99,\n    \"test_accuracy\": 92.74447949526814,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 100,\n    \"experiment_id\": \"b18090ccd0874f01b30a8deff210f764\",\n    \"date\": \"2022-03-06_04-26-50\",\n    \"timestamp\": 1646558810,\n    \"time_this_iter_s\": 0.5565409660339355,\n    \"time_total_s\": 59.104477405548096,\n    \"pid\": 146033,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"num_anc\": 1,\n      \"deph_p\": 1,\n      \"tune_lr\": 0.025,\n      \"tune_init_std\": 0.1\n    },\n    \"time_since_restore\": 59.104477405548096,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 100,\n    \"trial_id\": \"7def9_00009\",\n    \"experiment_tag\": \"9_tune_init_std=0.1,tune_lr=0.025\"\n  },\n  \"last_update_time\": 1646558810.7636173,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 99,\n      \"min\": 0,\n      \"avg\": 49.50000000000002,\n      \"last\": 99,\n      \"last-5-avg\": 97.0,\n      \"last-10-avg\": 94.5\n    },\n    \"test_accuracy\": {\n      \"max\": 93.37539432176656,\n      \"min\": 87.27655099894848,\n      \"avg\": 92.5078864353312,\n      \"last\": 92.74447949526814,\n      \"last-5-avg\": 92.56572029442694,\n      \"last-10-avg\": 92.56572029442692\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.01,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"timestamp\": {\n      \"max\": 1646558810,\n      \"min\": 1646558755,\n      \"avg\": 1646558782.4800003,\n      \"last\": 1646558810,\n      \"last-5-avg\": 1646558809.2,\n      \"last-10-avg\": 1646558807.7\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3.844508409500122,\n      \"min\": 0.5496077537536621,\n      \"avg\": 0.5910447740554807,\n      \"last\": 0.5565409660339355,\n      \"last-5-avg\": 0.5553489208221436,\n      \"last-10-avg\": 0.5558481216430664\n    },\n    \"time_total_s\": {\n      \"max\": 59.104477405548096,\n      \"min\": 3.844508409500122,\n      \"avg\": 31.496658377647393,\n      \"last\": 59.104477405548096,\n      \"last-5-avg\": 57.99302000999451,\n      \"last-10-avg\": 56.60612549781799\n    },\n    \"pid\": {\n      \"max\": 146033,\n      \"min\": 146033,\n      \"avg\": 146033.0,\n      \"last\": 146033,\n      \"last-5-avg\": 146033.0,\n      \"last-10-avg\": 146033.0\n    },\n    \"time_since_restore\": {\n      \"max\": 59.104477405548096,\n      \"min\": 3.844508409500122,\n      \"avg\": 31.496658377647393,\n      \"last\": 59.104477405548096,\n      \"last-5-avg\": 57.99302000999451,\n      \"last-10-avg\": 56.60612549781799\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"config/num_anc\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999993,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/deph_p\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999993,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.025,\n      \"min\": 0.025,\n      \"avg\": 0.024999999999999953,\n      \"last\": 0.025,\n      \"last-5-avg\": 0.025,\n      \"last-10-avg\": 0.024999999999999998\n    },\n    \"config/tune_init_std\": {\n      \"max\": 0.1,\n      \"min\": 0.1,\n      \"avg\": 0.09999999999999981,\n      \"last\": 0.1,\n      \"last-5-avg\": 0.1,\n      \"last-10-avg\": 0.09999999999999999\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5f4b604b614b624b63652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5a4b5b4b5c4b5d4b5e4b5f4b604b614b624b63652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847405728eabbe514ba474057258d532e08144740571817b051d5784740571ed281bfeec64740572fa58d532e08652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740572c48249c216147405728eabbe514ba4740571817b051d5784740571b751908e21f4740572c48249c216147405728eabbe514ba474057258d532e08144740571817b051d5784740571ed281bfeec64740572fa58d532e08652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a587e24624a597e24624a597e24624a5a7e24624a5a7e2462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a557e24624a567e24624a567e24624a577e24624a577e24624a587e24624a597e24624a597e24624a5a7e24624a5a7e2462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe1d35500000000473fe1a5f280000000473fe1c54600000000473fe1cd5b00000000473fe1cf2f00000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe1f84a00000000473fe1d8e300000000473fe1ce3880000000473fe1ab7400000000473fe1b92300000000473fe1d35500000000473fe1a5f280000000473fe1c54600000000473fe1cd5b00000000473fe1cf2f00000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404c71407a00000047404cb7d84400000047404cfeed5c00000047404d4622c800000047404d8d5f84000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404b0dc45c00000047404b5527e800000047404b9c60ca00000047404be30e9a00000047404c29f32600000047404c71407a00000047404cb7d84400000047404cfeed5c00000047404d4622c800000047404d8d5f84000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a713a02004a713a02004a713a02004a713a02004a713a0200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a713a02004a713a02004a713a02004a713a02004a713a02004a713a02004a713a02004a713a02004a713a02004a713a0200652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404c71407a00000047404cb7d84400000047404cfeed5c00000047404d4622c800000047404d8d5f84000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404b0dc45c00000047404b5527e800000047404b9c60ca00000047404be30e9a00000047404c29f32600000047404c71407a00000047404cb7d84400000047404cfeed5c00000047404d4622c800000047404d8d5f84000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"config/num_anc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/deph_p\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646558748.1672575,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1/UniTTN_7def9_00009_9_tune_init_std=0.1,tune_lr=0.025_2022-03-06_04-25-13\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"7def9_00002\",\n  \"config\": {\n    \"num_anc\": 1,\n    \"deph_p\": 1,\n    \"tune_lr\": 0.001,\n    \"tune_init_std\": 0.01\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 0.01,\n    \"tune_lr\": 0.001\n  },\n  \"experiment_tag\": \"2_tune_init_std=0.01,tune_lr=0.001\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 10,\n    \"gpu\": 1,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b0a8c03475055944b018c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 49,\n    \"test_accuracy\": 92.11356466876973,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 50,\n    \"experiment_id\": \"d812e047b8a14ab3b93dddf6eaf45048\",\n    \"date\": \"2022-03-06_04-21-55\",\n    \"timestamp\": 1646558515,\n    \"time_this_iter_s\": 0.5473666191101074,\n    \"time_total_s\": 30.891988039016724,\n    \"pid\": 146040,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"num_anc\": 1,\n      \"deph_p\": 1,\n      \"tune_lr\": 0.001,\n      \"tune_init_std\": 0.01\n    },\n    \"time_since_restore\": 30.891988039016724,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 50,\n    \"trial_id\": \"7def9_00002\",\n    \"experiment_tag\": \"2_tune_init_std=0.01,tune_lr=0.001\"\n  },\n  \"last_update_time\": 1646558515.038352,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 49,\n      \"min\": 0,\n      \"avg\": 24.499999999999996,\n      \"last\": 49,\n      \"last-5-avg\": 47.0,\n      \"last-10-avg\": 44.5\n    },\n    \"test_accuracy\": {\n      \"max\": 92.11356466876973,\n      \"min\": 53.10199789695058,\n      \"avg\": 85.15772870662465,\n      \"last\": 92.11356466876973,\n      \"last-5-avg\": 91.99789695057834,\n      \"last-10-avg\": 91.86119873817034\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.02,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"timestamp\": {\n      \"max\": 1646558515,\n      \"min\": 1646558487,\n      \"avg\": 1646558500.939999,\n      \"last\": 1646558515,\n      \"last-5-avg\": 1646558513.4,\n      \"last-10-avg\": 1646558512.1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3.7963757514953613,\n      \"min\": 0.5417335033416748,\n      \"avg\": 0.6178397607803342,\n      \"last\": 0.5473666191101074,\n      \"last-5-avg\": 0.5554717063903809,\n      \"last-10-avg\": 0.5542213678359985\n    },\n    \"time_total_s\": {\n      \"max\": 30.891988039016724,\n      \"min\": 3.7963757514953613,\n      \"avg\": 17.370042428970333,\n      \"last\": 30.891988039016724,\n      \"last-5-avg\": 29.79221796989441,\n      \"last-10-avg\": 28.39750952720642\n    },\n    \"pid\": {\n      \"max\": 146040,\n      \"min\": 146040,\n      \"avg\": 146040.0,\n      \"last\": 146040,\n      \"last-5-avg\": 146040.0,\n      \"last-10-avg\": 146040.0\n    },\n    \"time_since_restore\": {\n      \"max\": 30.891988039016724,\n      \"min\": 3.7963757514953613,\n      \"avg\": 17.370042428970333,\n      \"last\": 30.891988039016724,\n      \"last-5-avg\": 29.79221796989441,\n      \"last-10-avg\": 28.39750952720642\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"config/num_anc\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/deph_p\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.001,\n      \"min\": 0.001,\n      \"avg\": 0.0010000000000000005,\n      \"last\": 0.001,\n      \"last-5-avg\": 0.001,\n      \"last-10-avg\": 0.0010000000000000002\n    },\n    \"config/tune_init_std\": {\n      \"max\": 0.01,\n      \"min\": 0.01,\n      \"avg\": 0.010000000000000002,\n      \"last\": 0.01,\n      \"last-5-avg\": 0.01,\n      \"last-10-avg\": 0.009999999999999998\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2d4b2e4b2f4b304b31652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b31652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474056f671992b56f24740570089d3507ce8474056fd2c6a99704047405703e73c07898f4740570744a4be9636652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474056e8fbf64f2457474056ec595f0630fe474056ec595f0630fe474056efb6c7bd3da5474056f671992b56f2474056f671992b56f24740570089d3507ce8474056fd2c6a99704047405703e73c07898f4740570744a4be9636652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a307d24624a317d24624a317d24624a327d24624a337d2462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a2e7d24624a2e7d24624a2f7d24624a2f7d24624a307d24624a307d24624a317d24624a317d24624a327d24624a337d2462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe2224200000000473fe216d080000000473fe1996800000000473fe1899d80000000473fe1840700000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe1989d00000000473fe19f6f80000000473fe1881a00000000473fe1b15180000000473fe2083980000000473fe2224200000000473fe216d080000000473fe1996800000000473fe1899d80000000473fe1840700000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403cae6a6c00000047403d3f20f000000047403dcbec3000000047403e58391c00000047403ee45954000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039e64fb800000047403a734b3400000047403aff8c0400000047403b8d169000000047403c1d585c00000047403cae6a6c00000047403d3f20f000000047403dcbec3000000047403e58391c00000047403ee45954000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a783a02004a783a02004a783a02004a783a02004a783a0200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a783a02004a783a02004a783a02004a783a02004a783a02004a783a02004a783a02004a783a02004a783a02004a783a0200652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403cae6a6c00000047403d3f20f000000047403dcbec3000000047403e58391c00000047403ee45954000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039e64fb800000047403a734b3400000047403aff8c0400000047403b8d169000000047403c1d585c00000047403cae6a6c00000047403d3f20f000000047403dcbec3000000047403e58391c00000047403ee45954000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"config/num_anc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/deph_p\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646558480.6790118,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1/UniTTN_7def9_00002_2_tune_init_std=0.01,tune_lr=0.001_2022-03-06_04-20-18\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"7def9_00005\",\n  \"config\": {\n    \"num_anc\": 1,\n    \"deph_p\": 1,\n    \"tune_lr\": 0.005,\n    \"tune_init_std\": 0.1\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 0.1,\n    \"tune_lr\": 0.005\n  },\n  \"experiment_tag\": \"5_tune_init_std=0.1,tune_lr=0.005\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 10,\n    \"gpu\": 1,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b0a8c03475055944b018c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 99,\n    \"test_accuracy\": 93.7434279705573,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 100,\n    \"experiment_id\": \"bf30f0e812f448ba851650becff6960b\",\n    \"date\": \"2022-03-06_04-24-05\",\n    \"timestamp\": 1646558645,\n    \"time_this_iter_s\": 0.5464699268341064,\n    \"time_total_s\": 58.32206583023071,\n    \"pid\": 146042,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"num_anc\": 1,\n      \"deph_p\": 1,\n      \"tune_lr\": 0.005,\n      \"tune_init_std\": 0.1\n    },\n    \"time_since_restore\": 58.32206583023071,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 100,\n    \"trial_id\": \"7def9_00005\",\n    \"experiment_tag\": \"5_tune_init_std=0.1,tune_lr=0.005\"\n  },\n  \"last_update_time\": 1646558645.450734,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 99,\n      \"min\": 0,\n      \"avg\": 49.50000000000002,\n      \"last\": 99,\n      \"last-5-avg\": 97.0,\n      \"last-10-avg\": 94.5\n    },\n    \"test_accuracy\": {\n      \"max\": 93.7434279705573,\n      \"min\": 75.23659305993691,\n      \"avg\": 92.61093585699267,\n      \"last\": 93.7434279705573,\n      \"last-5-avg\": 93.70136698212409,\n      \"last-10-avg\": 93.6855941114616\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.01,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"timestamp\": {\n      \"max\": 1646558645,\n      \"min\": 1646558590,\n      \"avg\": 1646558617.5299997,\n      \"last\": 1646558645,\n      \"last-5-avg\": 1646558643.8,\n      \"last-10-avg\": 1646558642.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3.7790727615356445,\n      \"min\": 0.5396525859832764,\n      \"avg\": 0.5832206583023067,\n      \"last\": 0.5464699268341064,\n      \"last-5-avg\": 0.5461556434631347,\n      \"last-10-avg\": 0.5471362352371216\n    },\n    \"time_total_s\": {\n      \"max\": 58.32206583023071,\n      \"min\": 3.7790727615356445,\n      \"avg\": 31.06333119630813,\n      \"last\": 58.32206583023071,\n      \"last-5-avg\": 57.22809519767761,\n      \"last-10-avg\": 55.86201651096344\n    },\n    \"pid\": {\n      \"max\": 146042,\n      \"min\": 146042,\n      \"avg\": 146042.0,\n      \"last\": 146042,\n      \"last-5-avg\": 146042.0,\n      \"last-10-avg\": 146042.0\n    },\n    \"time_since_restore\": {\n      \"max\": 58.32206583023071,\n      \"min\": 3.7790727615356445,\n      \"avg\": 31.06333119630813,\n      \"last\": 58.32206583023071,\n      \"last-5-avg\": 57.22809519767761,\n      \"last-10-avg\": 55.86201651096344\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"config/num_anc\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999993,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/deph_p\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999993,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.005,\n      \"min\": 0.005,\n      \"avg\": 0.0050000000000000044,\n      \"last\": 0.005,\n      \"last-5-avg\": 0.005,\n      \"last-10-avg\": 0.004999999999999999\n    },\n    \"config/tune_init_std\": {\n      \"max\": 0.1,\n      \"min\": 0.1,\n      \"avg\": 0.09999999999999981,\n      \"last\": 0.1,\n      \"last-5-avg\": 0.1,\n      \"last-10-avg\": 0.09999999999999999\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5f4b604b614b624b63652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5a4b5b4b5c4b5d4b5e4b5f4b604b614b624b63652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740576c36ea3211c44740576c36ea3211c44740576c36ea3211c44740576c36ea3211c44740576f9452e91e6b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740576c36ea3211c4474057657c18c3f8764740576c36ea3211c44740576c36ea3211c44740576c36ea3211c44740576c36ea3211c44740576c36ea3211c44740576c36ea3211c44740576c36ea3211c44740576f9452e91e6b652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ab37d24624ab37d24624ab47d24624ab47d24624ab57d2462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ab07d24624ab17d24624ab17d24624ab27d24624ab27d24624ab37d24624ab37d24624ab47d24624ab47d24624ab57d2462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe144d580000000473fe1ab4d00000000473fe1762580000000473fe17f9280000000473fe17cae80000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe17f7a80000000473fe18d0080000000473fe1ba3380000000473fe1709c80000000473fe17b9280000000473fe144d580000000473fe1ab4d00000000473fe1762580000000473fe17f9280000000473fe17cae80000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404c10c2a600000047404c576fda00000047404c9d487000000047404ce346ba00000047404d293974000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404ab2e1c400000047404af915c600000047404b3ffe9400000047404b85c10600000047404bcbaf5000000047404c10c2a600000047404c576fda00000047404c9d487000000047404ce346ba00000047404d293974000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a7a3a02004a7a3a02004a7a3a02004a7a3a02004a7a3a0200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a7a3a02004a7a3a02004a7a3a02004a7a3a02004a7a3a02004a7a3a02004a7a3a02004a7a3a02004a7a3a02004a7a3a0200652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404c10c2a600000047404c576fda00000047404c9d487000000047404ce346ba00000047404d293974000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404ab2e1c400000047404af915c600000047404b3ffe9400000047404b85c10600000047404bcbaf5000000047404c10c2a600000047404c576fda00000047404c9d487000000047404ce346ba00000047404d293974000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"config/num_anc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/deph_p\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646558583.5893414,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1/UniTTN_7def9_00005_5_tune_init_std=0.1,tune_lr=0.005_2022-03-06_04-22-29\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"7def9_00013\",\n  \"config\": {\n    \"num_anc\": 1,\n    \"deph_p\": 1,\n    \"tune_lr\": 0.125,\n    \"tune_init_std\": 0.1\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 0.1,\n    \"tune_lr\": 0.125\n  },\n  \"experiment_tag\": \"13_tune_init_std=0.1,tune_lr=0.125\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 10,\n    \"gpu\": 1,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b0a8c03475055944b018c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 49,\n    \"test_accuracy\": 91.9558359621451,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 50,\n    \"experiment_id\": \"dcfc15c363164106860db84e08ae73c1\",\n    \"date\": \"2022-03-06_04-29-35\",\n    \"timestamp\": 1646558975,\n    \"time_this_iter_s\": 0.5563123226165771,\n    \"time_total_s\": 31.086183309555054,\n    \"pid\": 146034,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"num_anc\": 1,\n      \"deph_p\": 1,\n      \"tune_lr\": 0.125,\n      \"tune_init_std\": 0.1\n    },\n    \"time_since_restore\": 31.086183309555054,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 50,\n    \"trial_id\": \"7def9_00013\",\n    \"experiment_tag\": \"13_tune_init_std=0.1,tune_lr=0.125\"\n  },\n  \"last_update_time\": 1646558975.2465758,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 49,\n      \"min\": 0,\n      \"avg\": 24.499999999999996,\n      \"last\": 49,\n      \"last-5-avg\": 47.0,\n      \"last-10-avg\": 44.5\n    },\n    \"test_accuracy\": {\n      \"max\": 92.21871713985279,\n      \"min\": 89.37960042060989,\n      \"avg\": 91.7781282860147,\n      \"last\": 91.9558359621451,\n      \"last-5-avg\": 92.06098843322818,\n      \"last-10-avg\": 92.01366982124081\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.02,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"timestamp\": {\n      \"max\": 1646558975,\n      \"min\": 1646558947,\n      \"avg\": 1646558961.08,\n      \"last\": 1646558975,\n      \"last-5-avg\": 1646558973.8,\n      \"last-10-avg\": 1646558972.3\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3.8364670276641846,\n      \"min\": 0.5440938472747803,\n      \"avg\": 0.6217236661911011,\n      \"last\": 0.5563123226165771,\n      \"last-5-avg\": 0.5528616905212402,\n      \"last-10-avg\": 0.5526381015777588\n    },\n    \"time_total_s\": {\n      \"max\": 31.086183309555054,\n      \"min\": 3.8364670276641846,\n      \"avg\": 17.508317298889157,\n      \"last\": 31.086183309555054,\n      \"last-5-avg\": 29.97825140953064,\n      \"last-10-avg\": 28.59779760837555\n    },\n    \"pid\": {\n      \"max\": 146034,\n      \"min\": 146034,\n      \"avg\": 146034.0,\n      \"last\": 146034,\n      \"last-5-avg\": 146034.0,\n      \"last-10-avg\": 146034.0\n    },\n    \"time_since_restore\": {\n      \"max\": 31.086183309555054,\n      \"min\": 3.8364670276641846,\n      \"avg\": 17.508317298889157,\n      \"last\": 31.086183309555054,\n      \"last-5-avg\": 29.97825140953064,\n      \"last-10-avg\": 28.59779760837555\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"config/num_anc\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/deph_p\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.125,\n      \"min\": 0.125,\n      \"avg\": 0.12499999999999999,\n      \"last\": 0.125,\n      \"last-5-avg\": 0.125,\n      \"last-10-avg\": 0.125\n    },\n    \"config/tune_init_std\": {\n      \"max\": 0.1,\n      \"min\": 0.1,\n      \"avg\": 0.09999999999999996,\n      \"last\": 0.1,\n      \"last-5-avg\": 0.1,\n      \"last-10-avg\": 0.09999999999999999\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2d4b2e4b2f4b304b31652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b31652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740570089d3507ce84740570aa20d75a2dc4740570744a4be963647405703e73c07898f474056fd2c6a997040652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740570744a4be9636474056f31430744a4c474056fd2c6a997040474056f9cf01e2639947405703e73c07898f4740570089d3507ce84740570aa20d75a2dc4740570744a4be963647405703e73c07898f474056fd2c6a997040652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284afd7e24624afd7e24624afe7e24624afe7e24624aff7e2462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284afa7e24624afa7e24624afb7e24624afb7e24624afc7e24624afd7e24624afd7e24624afe7e24624afe7e24624aff7e2462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe1b34680000000473fe1880180000000473fe1be3a00000000473fe1ae6580000000473fe1cd4f80000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe1a36000000000473fe1d04980000000473fe1a02980000000473fe1935100000000473fe1bbc200000000473fe1b34680000000473fe1880180000000473fe1be3a00000000473fe1ae6580000000473fe1cd4f80000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403ce0009800000047403d6c40a400000047403dfa327400000047403e87a5a000000047403f16101c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403a1c6a3400000047403aaaec8000000047403b37edcc00000047403bc4885400000047403c52666400000047403ce0009800000047403d6c40a400000047403dfa327400000047403e87a5a000000047403f16101c000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a723a02004a723a02004a723a02004a723a02004a723a0200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a723a02004a723a02004a723a02004a723a02004a723a02004a723a02004a723a02004a723a02004a723a02004a723a0200652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403ce0009800000047403d6c40a400000047403dfa327400000047403e87a5a000000047403f16101c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403a1c6a3400000047403aaaec8000000047403b37edcc00000047403bc4885400000047403c52666400000047403ce0009800000047403d6c40a400000047403dfa327400000047403e87a5a000000047403f16101c000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"config/num_anc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/deph_p\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000473fc0000000000000652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646558940.8650208,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1/UniTTN_7def9_00013_13_tune_init_std=0.1,tune_lr=0.125_2022-03-06_04-28-26\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"7def9_00006\",\n  \"config\": {\n    \"num_anc\": 1,\n    \"deph_p\": 1,\n    \"tune_lr\": 0.005,\n    \"tune_init_std\": 0.01\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 0.01,\n    \"tune_lr\": 0.005\n  },\n  \"experiment_tag\": \"6_tune_init_std=0.01,tune_lr=0.005\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 10,\n    \"gpu\": 1,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b0a8c03475055944b018c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 49,\n    \"test_accuracy\": 92.32386961093586,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 50,\n    \"experiment_id\": \"69a8f1329f124efb97bfdfece46678c0\",\n    \"date\": \"2022-03-06_04-24-39\",\n    \"timestamp\": 1646558679,\n    \"time_this_iter_s\": 0.5651693344116211,\n    \"time_total_s\": 30.818089962005615,\n    \"pid\": 146041,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"num_anc\": 1,\n      \"deph_p\": 1,\n      \"tune_lr\": 0.005,\n      \"tune_init_std\": 0.01\n    },\n    \"time_since_restore\": 30.818089962005615,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 50,\n    \"trial_id\": \"7def9_00006\",\n    \"experiment_tag\": \"6_tune_init_std=0.01,tune_lr=0.005\"\n  },\n  \"last_update_time\": 1646558679.6860764,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 49,\n      \"min\": 0,\n      \"avg\": 24.499999999999996,\n      \"last\": 49,\n      \"last-5-avg\": 47.0,\n      \"last-10-avg\": 44.5\n    },\n    \"test_accuracy\": {\n      \"max\": 92.58675078864354,\n      \"min\": 46.89800210304942,\n      \"avg\": 88.7718191377497,\n      \"last\": 92.32386961093586,\n      \"last-5-avg\": 92.42902208201893,\n      \"last-10-avg\": 92.48159831756047\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.02,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"timestamp\": {\n      \"max\": 1646558679,\n      \"min\": 1646558652,\n      \"avg\": 1646558665.6199994,\n      \"last\": 1646558679,\n      \"last-5-avg\": 1646558678.0,\n      \"last-10-avg\": 1646558676.6\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3.9190056324005127,\n      \"min\": 0.5386359691619873,\n      \"avg\": 0.6163617992401124,\n      \"last\": 0.5651693344116211,\n      \"last-5-avg\": 0.5556534767150879,\n      \"last-10-avg\": 0.5522198438644409\n    },\n    \"time_total_s\": {\n      \"max\": 30.818089962005615,\n      \"min\": 3.9190056324005127,\n      \"avg\": 17.351660962104788,\n      \"last\": 30.818089962005615,\n      \"last-5-avg\": 29.6962290763855,\n      \"last-10-avg\": 28.320791029930113\n    },\n    \"pid\": {\n      \"max\": 146041,\n      \"min\": 146041,\n      \"avg\": 146041.0,\n      \"last\": 146041,\n      \"last-5-avg\": 146041.0,\n      \"last-10-avg\": 146041.0\n    },\n    \"time_since_restore\": {\n      \"max\": 30.818089962005615,\n      \"min\": 3.9190056324005127,\n      \"avg\": 17.351660962104788,\n      \"last\": 30.818089962005615,\n      \"last-5-avg\": 29.6962290763855,\n      \"last-10-avg\": 28.320791029930113\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"config/num_anc\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/deph_p\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.005,\n      \"min\": 0.005,\n      \"avg\": 0.005000000000000001,\n      \"last\": 0.005,\n      \"last-5-avg\": 0.005,\n      \"last-10-avg\": 0.004999999999999999\n    },\n    \"config/tune_init_std\": {\n      \"max\": 0.01,\n      \"min\": 0.01,\n      \"avg\": 0.010000000000000002,\n      \"last\": 0.01,\n      \"last-5-avg\": 0.01,\n      \"last-10-avg\": 0.009999999999999998\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2d4b2e4b2f4b304b31652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b31652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740571ed281bfeec647405714ba479ac8d14740571ed281bfeec6474057222fea76fb6d47405714ba479ac8d1652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474057222fea76fb6d474057222fea76fb6d474057222fea76fb6d474057222fea76fb6d474057222fea76fb6d4740571ed281bfeec647405714ba479ac8d14740571ed281bfeec6474057222fea76fb6d47405714ba479ac8d1652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ad57d24624ad57d24624ad67d24624ad77d24624ad77d2462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ad27d24624ad37d24624ad37d24624ad47d24624ad47d24624ad57d24624ad57d24624ad67d24624ad77d24624ad77d2462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe1730200000000473fe19a7280000000473fe1bf3a00000000473fe2050480000000473fe215de00000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe1974a80000000473fe1b2fd80000000473fe18b4c80000000473fe18eed00000000473fe169c700000000473fe1730200000000473fe19a7280000000473fe1bf3a00000000473fe2050480000000473fe215de00000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403c95c9e000000047403d229d7400000047403db0974400000047403e40bf6800000047403ed16e58000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039d879e000000047403a6611cc00000047403af26c3000000047403b7ee39800000047403c0a31d000000047403c95c9e000000047403d229d7400000047403db0974400000047403e40bf6800000047403ed16e58000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a793a02004a793a02004a793a02004a793a02004a793a0200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a793a02004a793a02004a793a02004a793a02004a793a02004a793a02004a793a02004a793a02004a793a02004a793a0200652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403c95c9e000000047403d229d7400000047403db0974400000047403e40bf6800000047403ed16e58000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039d879e000000047403a6611cc00000047403af26c3000000047403b7ee39800000047403c0a31d000000047403c95c9e000000047403d229d7400000047403db0974400000047403e40bf6800000047403ed16e58000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"config/num_anc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/deph_p\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646558645.4560685,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1/UniTTN_7def9_00006_6_tune_init_std=0.01,tune_lr=0.005_2022-03-06_04-23-03\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"7def9_00004\",\n  \"config\": {\n    \"num_anc\": 1,\n    \"deph_p\": 1,\n    \"tune_lr\": 0.005,\n    \"tune_init_std\": 1\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 1,\n    \"tune_lr\": 0.005\n  },\n  \"experiment_tag\": \"4_tune_init_std=1,tune_lr=0.005\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 10,\n    \"gpu\": 1,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b0a8c03475055944b018c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 49,\n    \"test_accuracy\": 91.21976866456362,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 50,\n    \"experiment_id\": \"c301b4581de04b33b7438f00b3e08a16\",\n    \"date\": \"2022-03-06_04-23-03\",\n    \"timestamp\": 1646558583,\n    \"time_this_iter_s\": 0.558605432510376,\n    \"time_total_s\": 31.14654278755188,\n    \"pid\": 146032,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"num_anc\": 1,\n      \"deph_p\": 1,\n      \"tune_lr\": 0.005,\n      \"tune_init_std\": 1\n    },\n    \"time_since_restore\": 31.14654278755188,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 50,\n    \"trial_id\": \"7def9_00004\",\n    \"experiment_tag\": \"4_tune_init_std=1,tune_lr=0.005\"\n  },\n  \"last_update_time\": 1646558583.584431,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 49,\n      \"min\": 0,\n      \"avg\": 24.499999999999996,\n      \"last\": 49,\n      \"last-5-avg\": 47.0,\n      \"last-10-avg\": 44.5\n    },\n    \"test_accuracy\": {\n      \"max\": 91.27234490010515,\n      \"min\": 53.20715036803365,\n      \"avg\": 88.97055730809669,\n      \"last\": 91.21976866456362,\n      \"last-5-avg\": 91.21976866456362,\n      \"last-10-avg\": 91.17245005257624\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.02,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"timestamp\": {\n      \"max\": 1646558583,\n      \"min\": 1646558556,\n      \"avg\": 1646558569.3399994,\n      \"last\": 1646558583,\n      \"last-5-avg\": 1646558582.0,\n      \"last-10-avg\": 1646558580.6\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3.8119237422943115,\n      \"min\": 0.5494863986968994,\n      \"avg\": 0.6229308557510372,\n      \"last\": 0.558605432510376,\n      \"last-5-avg\": 0.5551135540008545,\n      \"last-10-avg\": 0.5556880235671997\n    },\n    \"time_total_s\": {\n      \"max\": 31.14654278755188,\n      \"min\": 3.8119237422943115,\n      \"avg\": 17.495812516212464,\n      \"last\": 31.14654278755188,\n      \"last-5-avg\": 30.035782670974733,\n      \"last-10-avg\": 28.646394848823547\n    },\n    \"pid\": {\n      \"max\": 146032,\n      \"min\": 146032,\n      \"avg\": 146032.0,\n      \"last\": 146032,\n      \"last-5-avg\": 146032.0,\n      \"last-10-avg\": 146032.0\n    },\n    \"time_since_restore\": {\n      \"max\": 31.14654278755188,\n      \"min\": 3.8119237422943115,\n      \"avg\": 17.495812516212464,\n      \"last\": 31.14654278755188,\n      \"last-5-avg\": 30.035782670974733,\n      \"last-10-avg\": 28.646394848823547\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"config/num_anc\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/deph_p\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.005,\n      \"min\": 0.005,\n      \"avg\": 0.005000000000000001,\n      \"last\": 0.005,\n      \"last-5-avg\": 0.005,\n      \"last-10-avg\": 0.004999999999999999\n    },\n    \"config/tune_init_std\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2d4b2e4b2f4b304b31652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b31652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474056ce10b096bf20474056ce10b096bf20474056ce10b096bf20474056ce10b096bf20474056ce10b096bf20652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474056c3f87671992b474056c3f87671992b474056cab347dfb279474056d16e194dcbc7474056c3f87671992b474056ce10b096bf20474056ce10b096bf20474056ce10b096bf20474056ce10b096bf20474056ce10b096bf20652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a757d24624a757d24624a767d24624a777d24624a777d2462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a727d24624a737d24624a737d24624a747d24624a747d24624a757d24624a757d24624a767d24624a777d24624a777d2462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe1c29680000000473fe1cd4c80000000473fe1b95a80000000473fe1a81d80000000473fe1e01880000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe1b4b480000000473fe1d1fb80000000473fe1c0fe00000000473fe1fb2a80000000473fe1bdaa80000000473fe1c29680000000473fe1cd4c80000000473fe1b95a80000000473fe1a81d80000000473fe1e01880000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403ced0cec00000047403d7b775000000047403e09422400000047403e96831000000047403f2583d4000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403a2499c400000047403ab329a000000047403b41319000000047403bd10ae400000047403c5ef83800000047403ced0cec00000047403d7b775000000047403e09422400000047403e96831000000047403f2583d4000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a703a02004a703a02004a703a02004a703a02004a703a0200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a703a02004a703a02004a703a02004a703a02004a703a02004a703a02004a703a02004a703a02004a703a02004a703a0200652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403ced0cec00000047403d7b775000000047403e09422400000047403e96831000000047403f2583d4000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403a2499c400000047403ab329a000000047403b41319000000047403bd10ae400000047403c5ef83800000047403ced0cec00000047403d7b775000000047403e09422400000047403e96831000000047403f2583d4000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"config/num_anc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/deph_p\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b473f747ae147ae147b652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646558549.0328877,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1/UniTTN_7def9_00004_4_tune_init_std=1,tune_lr=0.005_2022-03-06_04-21-55\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"7def9_00010\",\n  \"config\": {\n    \"num_anc\": 1,\n    \"deph_p\": 1,\n    \"tune_lr\": 0.025,\n    \"tune_init_std\": 0.01\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 0.01,\n    \"tune_lr\": 0.025\n  },\n  \"experiment_tag\": \"10_tune_init_std=0.01,tune_lr=0.025\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 10,\n    \"gpu\": 1,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b0a8c03475055944b018c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 49,\n    \"test_accuracy\": 92.534174553102,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 50,\n    \"experiment_id\": \"78a53948962e425b8c9a5cbdb31946d9\",\n    \"date\": \"2022-03-06_04-27-24\",\n    \"timestamp\": 1646558844,\n    \"time_this_iter_s\": 0.5436971187591553,\n    \"time_total_s\": 30.552963256835938,\n    \"pid\": 146029,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"num_anc\": 1,\n      \"deph_p\": 1,\n      \"tune_lr\": 0.025,\n      \"tune_init_std\": 0.01\n    },\n    \"time_since_restore\": 30.552963256835938,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 50,\n    \"trial_id\": \"7def9_00010\",\n    \"experiment_tag\": \"10_tune_init_std=0.01,tune_lr=0.025\"\n  },\n  \"last_update_time\": 1646558844.6086733,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 49,\n      \"min\": 0,\n      \"avg\": 24.499999999999996,\n      \"last\": 49,\n      \"last-5-avg\": 47.0,\n      \"last-10-avg\": 44.5\n    },\n    \"test_accuracy\": {\n      \"max\": 93.05993690851734,\n      \"min\": 83.01787592008412,\n      \"avg\": 92.2092534174553,\n      \"last\": 92.534174553102,\n      \"last-5-avg\": 92.46056782334384,\n      \"last-10-avg\": 92.48159831756047\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.02,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"timestamp\": {\n      \"max\": 1646558844,\n      \"min\": 1646558817,\n      \"avg\": 1646558830.6799998,\n      \"last\": 1646558844,\n      \"last-5-avg\": 1646558843.0,\n      \"last-10-avg\": 1646558841.6\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3.865434169769287,\n      \"min\": 0.5356452465057373,\n      \"avg\": 0.6110592651367187,\n      \"last\": 0.5436971187591553,\n      \"last-5-avg\": 0.5431362628936768,\n      \"last-10-avg\": 0.5449719667434693\n    },\n    \"time_total_s\": {\n      \"max\": 30.552963256835938,\n      \"min\": 3.865434169769287,\n      \"avg\": 17.20434077262878,\n      \"last\": 30.552963256835938,\n      \"last-5-avg\": 29.463948488235474,\n      \"last-10-avg\": 28.1023916721344\n    },\n    \"pid\": {\n      \"max\": 146029,\n      \"min\": 146029,\n      \"avg\": 146029.0,\n      \"last\": 146029,\n      \"last-5-avg\": 146029.0,\n      \"last-10-avg\": 146029.0\n    },\n    \"time_since_restore\": {\n      \"max\": 30.552963256835938,\n      \"min\": 3.865434169769287,\n      \"avg\": 17.20434077262878,\n      \"last\": 30.552963256835938,\n      \"last-5-avg\": 29.463948488235474,\n      \"last-10-avg\": 28.1023916721344\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 50,\n      \"min\": 1,\n      \"avg\": 25.499999999999996,\n      \"last\": 50,\n      \"last-5-avg\": 48.0,\n      \"last-10-avg\": 45.5\n    },\n    \"config/num_anc\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/deph_p\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999999,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.025,\n      \"min\": 0.025,\n      \"avg\": 0.02499999999999999,\n      \"last\": 0.025,\n      \"last-5-avg\": 0.025,\n      \"last-10-avg\": 0.024999999999999998\n    },\n    \"config/tune_init_std\": {\n      \"max\": 0.01,\n      \"min\": 0.01,\n      \"avg\": 0.010000000000000002,\n      \"last\": 0.01,\n      \"last-5-avg\": 0.01,\n      \"last-10-avg\": 0.009999999999999998\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2d4b2e4b2f4b304b31652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b31652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474057115cdee3bc2a47405714ba479ac8d14740571ed281bfeec64740572c48249c2161474057222fea76fb6d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740571b751908e21f4740571b751908e21f474057258d532e08144740571817b051d5784740572c48249c2161474057115cdee3bc2a47405714ba479ac8d14740571ed281bfeec64740572c48249c2161474057222fea76fb6d652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a7a7e24624a7a7e24624a7b7e24624a7c7e24624a7c7e2462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a777e24624a787e24624a787e24624a797e24624a797e24624a7a7e24624a7a7e24624a7b7e24624a7c7e24624a7c7e2462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe1515800000000473fe1491d80000000473fe1563e80000000473fe1903100000000473fe165f780000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe16cc700000000473fe1785e00000000473fe18b4780000000473fe153ba00000000473fe1b91780000000473fe1515800000000473fe1491d80000000473fe1563e80000000473fe1903100000000473fe165f780000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403c60e2dc00000047403ceb2bc800000047403d75ddbc00000047403e025f4400000047403e8d8f00000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039a5d46400000047403a31975400000047403abdf19000000047403b488f6000000047403bd6581c00000047403c60e2dc00000047403ceb2bc800000047403d75ddbc00000047403e025f4400000047403e8d8f00000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a6d3a02004a6d3a02004a6d3a02004a6d3a02004a6d3a0200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a6d3a02004a6d3a02004a6d3a02004a6d3a02004a6d3a02004a6d3a02004a6d3a02004a6d3a02004a6d3a02004a6d3a0200652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403c60e2dc00000047403ceb2bc800000047403d75ddbc00000047403e025f4400000047403e8d8f00000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039a5d46400000047403a31975400000047403abdf19000000047403b488f6000000047403bd6581c00000047403c60e2dc00000047403ceb2bc800000047403d75ddbc00000047403e025f4400000047403e8d8f00000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b2e4b2f4b304b314b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b294b2a4b2b4b2c4b2d4b2e4b2f4b304b314b32652e\"\n      }\n    },\n    \"config/num_anc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/deph_p\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a473f9999999999999a652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646558810.7717004,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1/UniTTN_7def9_00010_10_tune_init_std=0.01,tune_lr=0.025_2022-03-06_04-25-48\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"7def9_00001\",\n  \"config\": {\n    \"num_anc\": 1,\n    \"deph_p\": 1,\n    \"tune_lr\": 0.001,\n    \"tune_init_std\": 0.1\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 0.1,\n    \"tune_lr\": 0.001\n  },\n  \"experiment_tag\": \"1_tune_init_std=0.1,tune_lr=0.001\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 10,\n    \"gpu\": 1,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b0a8c03475055944b018c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 99,\n    \"test_accuracy\": 93.53312302839116,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 100,\n    \"experiment_id\": \"cee4da05b6b042adafb9193aaef472dd\",\n    \"date\": \"2022-03-06_04-21-20\",\n    \"timestamp\": 1646558480,\n    \"time_this_iter_s\": 0.5574431419372559,\n    \"time_total_s\": 59.11304521560669,\n    \"pid\": 146039,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"num_anc\": 1,\n      \"deph_p\": 1,\n      \"tune_lr\": 0.001,\n      \"tune_init_std\": 0.1\n    },\n    \"time_since_restore\": 59.11304521560669,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 100,\n    \"trial_id\": \"7def9_00001\",\n    \"experiment_tag\": \"1_tune_init_std=0.1,tune_lr=0.001\"\n  },\n  \"last_update_time\": 1646558480.6702957,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 99,\n      \"min\": 0,\n      \"avg\": 49.50000000000002,\n      \"last\": 99,\n      \"last-5-avg\": 97.0,\n      \"last-10-avg\": 94.5\n    },\n    \"test_accuracy\": {\n      \"max\": 93.7434279705573,\n      \"min\": 53.10199789695058,\n      \"avg\": 91.34910620399576,\n      \"last\": 93.53312302839116,\n      \"last-5-avg\": 93.53312302839116,\n      \"last-10-avg\": 93.55415352260778\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.01,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"timestamp\": {\n      \"max\": 1646558480,\n      \"min\": 1646558425,\n      \"avg\": 1646558452.400001,\n      \"last\": 1646558480,\n      \"last-5-avg\": 1646558479.0,\n      \"last-10-avg\": 1646558477.6\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3.828720808029175,\n      \"min\": 0.5489068031311035,\n      \"avg\": 0.591130452156067,\n      \"last\": 0.5574431419372559,\n      \"last-5-avg\": 0.5567272186279297,\n      \"last-10-avg\": 0.5561533451080323\n    },\n    \"time_total_s\": {\n      \"max\": 59.11304521560669,\n      \"min\": 3.828720808029175,\n      \"avg\": 31.49780974626541,\n      \"last\": 59.11304521560669,\n      \"last-5-avg\": 57.997697257995604,\n      \"last-10-avg\": 56.608575916290285\n    },\n    \"pid\": {\n      \"max\": 146039,\n      \"min\": 146039,\n      \"avg\": 146039.0,\n      \"last\": 146039,\n      \"last-5-avg\": 146039.0,\n      \"last-10-avg\": 146039.0\n    },\n    \"time_since_restore\": {\n      \"max\": 59.11304521560669,\n      \"min\": 3.828720808029175,\n      \"avg\": 31.49780974626541,\n      \"last\": 59.11304521560669,\n      \"last-5-avg\": 57.997697257995604,\n      \"last-10-avg\": 56.608575916290285\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"config/num_anc\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999993,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/deph_p\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999993,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.001,\n      \"min\": 0.001,\n      \"avg\": 0.0010000000000000009,\n      \"last\": 0.001,\n      \"last-5-avg\": 0.001,\n      \"last-10-avg\": 0.0010000000000000002\n    },\n    \"config/tune_init_std\": {\n      \"max\": 0.1,\n      \"min\": 0.1,\n      \"avg\": 0.09999999999999981,\n      \"last\": 0.1,\n      \"last-5-avg\": 0.1,\n      \"last-10-avg\": 0.09999999999999999\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5f4b604b614b624b63652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5a4b5b4b5c4b5d4b5e4b5f4b604b614b624b63652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474057621eb00cebcf474057621eb00cebcf474057621eb00cebcf474057621eb00cebcf474057621eb00cebcf652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405768d9817b051d474057657c18c3f876474057657c18c3f876474057621eb00cebcf474057621eb00cebcf474057621eb00cebcf474057621eb00cebcf474057621eb00cebcf474057621eb00cebcf474057621eb00cebcf652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a0e7d24624a0e7d24624a0f7d24624a107d24624a107d2462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a0b7d24624a0c7d24624a0c7d24624a0d7d24624a0d7d24624a0e7d24624a0e7d24624a0f7d24624a107d24624a107d2462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe1c26700000000473fe1c43b00000000473fe1cce500000000473fe1e97200000000473fe1d69300000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe1d34f80000000473fe1c61e80000000473fe1c6ba80000000473fe1cd5880000000473fe1b70800000000473fe1c26700000000473fe1c43b00000000473fe1cce500000000473fe1e97200000000473fe1d69300000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404c7133b000000047404cb8449c00000047404cff783000000047404d471df800000047404d8e7844000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404b0de52e00000047404b54fda800000047404b9c189200000047404be34df400000047404c2a2a1400000047404c7133b000000047404cb8449c00000047404cff783000000047404d471df800000047404d8e7844000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a773a02004a773a02004a773a02004a773a02004a773a0200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a773a02004a773a02004a773a02004a773a02004a773a02004a773a02004a773a02004a773a02004a773a02004a773a0200652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404c7133b000000047404cb8449c00000047404cff783000000047404d471df800000047404d8e7844000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404b0de52e00000047404b54fda800000047404b9c189200000047404be34df400000047404c2a2a1400000047404c7133b000000047404cb8449c00000047404cff783000000047404d471df800000047404d8e7844000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"config/num_anc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/deph_p\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a473fb999999999999a652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646558418.0830214,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1/UniTTN_7def9_00001_1_tune_init_std=0.1,tune_lr=0.001_2022-03-06_04-19-15\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"7def9_00000\",\n  \"config\": {\n    \"num_anc\": 1,\n    \"deph_p\": 1,\n    \"tune_lr\": 0.001,\n    \"tune_init_std\": 1\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 1,\n    \"tune_lr\": 0.001\n  },\n  \"experiment_tag\": \"0_tune_init_std=1,tune_lr=0.001\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 10,\n    \"gpu\": 1,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b0a8c03475055944b018c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 99,\n    \"test_accuracy\": 90.27339642481599,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 100,\n    \"experiment_id\": \"4f935a718cb24afaa136e3826fc6e511\",\n    \"date\": \"2022-03-06_04-20-18\",\n    \"timestamp\": 1646558418,\n    \"time_this_iter_s\": 0.5491695404052734,\n    \"time_total_s\": 59.02869129180908,\n    \"pid\": 146037,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"num_anc\": 1,\n      \"deph_p\": 1,\n      \"tune_lr\": 0.001,\n      \"tune_init_std\": 1\n    },\n    \"time_since_restore\": 59.02869129180908,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 100,\n    \"trial_id\": \"7def9_00000\",\n    \"experiment_tag\": \"0_tune_init_std=1,tune_lr=0.001\"\n  },\n  \"last_update_time\": 1646558418.0782819,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 99,\n      \"min\": 0,\n      \"avg\": 49.50000000000002,\n      \"last\": 99,\n      \"last-5-avg\": 97.0,\n      \"last-10-avg\": 94.5\n    },\n    \"test_accuracy\": {\n      \"max\": 91.58780231335436,\n      \"min\": 53.10199789695058,\n      \"avg\": 87.07570977917977,\n      \"last\": 90.27339642481599,\n      \"last-5-avg\": 90.25236593059938,\n      \"last-10-avg\": 90.19978969505783\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.01,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"timestamp\": {\n      \"max\": 1646558418,\n      \"min\": 1646558362,\n      \"avg\": 1646558389.8300004,\n      \"last\": 1646558418,\n      \"last-5-avg\": 1646558416.4,\n      \"last-10-avg\": 1646558415.1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3.866366386413574,\n      \"min\": 0.5484645366668701,\n      \"avg\": 0.5902869129180909,\n      \"last\": 0.5491695404052734,\n      \"last-5-avg\": 0.5552211761474609,\n      \"last-10-avg\": 0.5566158294677734\n    },\n    \"time_total_s\": {\n      \"max\": 59.02869129180908,\n      \"min\": 3.866366386413574,\n      \"avg\": 31.456115388870245,\n      \"last\": 59.02869129180908,\n      \"last-5-avg\": 57.92007660865784,\n      \"last-10-avg\": 56.528879284858704\n    },\n    \"pid\": {\n      \"max\": 146037,\n      \"min\": 146037,\n      \"avg\": 146037.0,\n      \"last\": 146037,\n      \"last-5-avg\": 146037.0,\n      \"last-10-avg\": 146037.0\n    },\n    \"time_since_restore\": {\n      \"max\": 59.02869129180908,\n      \"min\": 3.866366386413574,\n      \"avg\": 31.456115388870245,\n      \"last\": 59.02869129180908,\n      \"last-5-avg\": 57.92007660865784,\n      \"last-10-avg\": 56.528879284858704\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 100,\n      \"min\": 1,\n      \"avg\": 50.50000000000002,\n      \"last\": 100,\n      \"last-5-avg\": 98.0,\n      \"last-10-avg\": 95.5\n    },\n    \"config/num_anc\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999993,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/deph_p\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999993,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.001,\n      \"min\": 0.001,\n      \"avg\": 0.0010000000000000009,\n      \"last\": 0.001,\n      \"last-5-avg\": 0.001,\n      \"last-10-avg\": 0.0010000000000000002\n    },\n    \"config/tune_init_std\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 0.9999999999999993,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5f4b604b614b624b63652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5a4b5b4b5c4b5d4b5e4b5f4b604b614b624b63652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740568e21eb00cebd4740568e21eb00cebd474056917f53b7db64474056917f53b7db64474056917f53b7db64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740568409b0dba8c84740568409b0dba8c84740568ac48249c2164740568e21eb00cebd4740568e21eb00cebd4740568e21eb00cebd4740568e21eb00cebd474056917f53b7db64474056917f53b7db64474056917f53b7db64652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284acf7c24624ad07c24624ad07c24624ad17c24624ad27c2462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284acd7c24624acd7c24624ace7c24624ace7c24624acf7c24624acf7c24624ad07c24624ad07c24624ad17c24624ad27c2462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe1cc2880000000473fe1ca1b00000000473fe1bad500000000473fe1f1f780000000473fe192cc00000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe1d89400000000473fe2060d80000000473fe19acd80000000473fe213ea80000000473fe1bac280000000473fe1cc2880000000473fe1ca1b00000000473fe1bad500000000473fe1f1f780000000473fe192cc00000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404c67855a00000047404caeadc600000047404cf5991a00000047404d3d60f800000047404d83ac28000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404b02969800000047404b4aaece00000047404b911a0400000047404bd969ae00000047404c2054b800000047404c67855a00000047404caeadc600000047404cf5991a00000047404d3d60f800000047404d83ac28000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a753a02004a753a02004a753a02004a753a02004a753a0200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a753a02004a753a02004a753a02004a753a02004a753a02004a753a02004a753a02004a753a02004a753a02004a753a0200652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404c67855a00000047404caeadc600000047404cf5991a00000047404d3d60f800000047404d83ac28000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404b02969800000047404b4aaece00000047404b911a0400000047404bd969ae00000047404c2054b800000047404c67855a00000047404caeadc600000047404cf5991a00000047404d3d60f800000047404d83ac28000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b604b614b624b634b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b5b4b5c4b5d4b5e4b5f4b604b614b624b634b64652e\"\n      }\n    },\n    \"config/num_anc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/deph_p\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b014b014b014b014b01652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1646558355.5510042,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1/UniTTN_7def9_00000_0_tune_init_std=1,tune_lr=0.001_2022-03-06_04-19-15\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_max_pending_trials": 17,
    "_metric": "test_accuracy",
    "_total_time": 633.2646028995514,
    "_iteration": 1162,
    "_has_errored": false,
    "_fail_fast": false,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_updated_queue": true,
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059527000000000000008c107261792e74756e652e73746f70706572948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1646558355.3292313,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2022-03-06_04-19-15",
    "checkpoint_file": "/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/anc1_deph1/experiment_state-2022-03-06_04-19-15.json",
    "_checkpoint_period": "auto",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1646558355.3292313,
    "timestamp": 1646559037.1245086
  }
}