{
  "checkpoints": [
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"94438_00005\",\n  \"config\": {\n    \"num_anc\": 0,\n    \"deph_p\": 1.0,\n    \"tune_lr\": 0.003,\n    \"tune_init_std\": 0.01\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_03-01-07\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 0.01,\n    \"tune_lr\": 0.003\n  },\n  \"experiment_tag\": \"5_tune_init_std=0.01,tune_lr=0.003\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 2,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b028c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 3,\n    \"test_accuracy\": 53.10199789695058,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 4,\n    \"experiment_id\": \"13e6d84e96284bb083e7d2bc9b61d5f5\",\n    \"date\": \"2022-03-06_03-01-18\",\n    \"timestamp\": 1646553678,\n    \"time_this_iter_s\": 1.1601333618164062,\n    \"time_total_s\": 7.1760573387146,\n    \"pid\": 114466,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"num_anc\": 0,\n      \"deph_p\": 1.0,\n      \"tune_lr\": 0.003,\n      \"tune_init_std\": 0.01\n    },\n    \"time_since_restore\": 7.1760573387146,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 4,\n    \"trial_id\": \"94438_00005\",\n    \"experiment_tag\": \"5_tune_init_std=0.01,tune_lr=0.003\"\n  },\n  \"last_update_time\": 1646553678.2815387,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 3,\n      \"min\": 0,\n      \"avg\": 1.5,\n      \"last\": 3,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"test_accuracy\": {\n      \"max\": 53.10199789695058,\n      \"min\": 53.10199789695058,\n      \"avg\": 53.10199789695058,\n      \"last\": 53.10199789695058,\n      \"last-5-avg\": 53.10199789695058,\n      \"last-10-avg\": 53.10199789695058\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 4,\n      \"min\": 1,\n      \"avg\": 2.5,\n      \"last\": 4,\n      \"last-5-avg\": 2.5,\n      \"last-10-avg\": 2.5\n    },\n    \"timestamp\": {\n      \"max\": 1646553678,\n      \"min\": 1646553674,\n      \"avg\": 1646553676.0,\n      \"last\": 1646553678,\n      \"last-5-avg\": 1646553676.0,\n      \"last-10-avg\": 1646553676.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3.893951177597046,\n      \"min\": 0.9839386940002441,\n      \"avg\": 1.7940143346786497,\n      \"last\": 1.1601333618164062,\n      \"last-5-avg\": 1.79401433467865,\n      \"last-10-avg\": 1.79401433467865\n    },\n    \"time_total_s\": {\n      \"max\": 7.1760573387146,\n      \"min\": 3.893951177597046,\n      \"avg\": 5.490955591201782,\n      \"last\": 7.1760573387146,\n      \"last-5-avg\": 5.490955591201782,\n      \"last-10-avg\": 5.490955591201782\n    },\n    \"pid\": {\n      \"max\": 114466,\n      \"min\": 114466,\n      \"avg\": 114466.0,\n      \"last\": 114466,\n      \"last-5-avg\": 114466.0,\n      \"last-10-avg\": 114466.0\n    },\n    \"time_since_restore\": {\n      \"max\": 7.1760573387146,\n      \"min\": 3.893951177597046,\n      \"avg\": 5.490955591201782,\n      \"last\": 7.1760573387146,\n      \"last-5-avg\": 5.490955591201782,\n      \"last-10-avg\": 5.490955591201782\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 4,\n      \"min\": 1,\n      \"avg\": 2.5,\n      \"last\": 4,\n      \"last-5-avg\": 2.5,\n      \"last-10-avg\": 2.5\n    },\n    \"config/num_anc\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"config/deph_p\": {\n      \"max\": 1.0,\n      \"min\": 1.0,\n      \"avg\": 1.0,\n      \"last\": 1.0,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.003,\n      \"min\": 0.003,\n      \"avg\": 0.003,\n      \"last\": 0.003,\n      \"last-5-avg\": 0.003,\n      \"last-10-avg\": 0.003\n    },\n    \"config/tune_init_std\": {\n      \"max\": 0.01,\n      \"min\": 0.01,\n      \"avg\": 0.009999999999999998,\n      \"last\": 0.01,\n      \"last-5-avg\": 0.01,\n      \"last-10-avg\": 0.01\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b014b024b03652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404a8d0e445fd4ee47404a8d0e445fd4ee47404a8d0e445fd4ee47404a8d0e445fd4ee652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404a8d0e445fd4ee47404a8d0e445fd4ee47404a8d0e445fd4ee47404a8d0e445fd4ee652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942889898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b04652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b04652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a4a6a24624a4b6a24624a4d6a24624a4e6a2462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a4a6a24624a4b6a24624a4d6a24624a4e6a2462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847400f26cfe0000000473fef7c6d00000000473ff2356340000000473ff28fe800000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847400f26cfe0000000473fef7c6d00000000473ff2356340000000473ff28fe800000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847400f26cfe000000047401382f590000000474018104e6000000047401cb44860000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847400f26cfe000000047401382f590000000474018104e6000000047401cb44860000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a22bf01004a22bf01004a22bf01004a22bf0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a22bf01004a22bf01004a22bf01004a22bf0100652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847400f26cfe000000047401382f590000000474018104e6000000047401cb44860000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847400f26cfe000000047401382f590000000474018104e6000000047401cb44860000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b04652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b04652e\"\n      }\n    },\n    \"config/num_anc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b00652e\"\n      }\n    },\n    \"config/deph_p\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b473f847ae147ae147b652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1646553668.5792537,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_03-01-07/UniTTN_94438_00005_5_tune_init_std=0.01,tune_lr=0.003_2022-03-06_03-01-08\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"94438_00002\",\n  \"config\": {\n    \"num_anc\": 0,\n    \"deph_p\": 1.0,\n    \"tune_lr\": 0.001,\n    \"tune_init_std\": 0.01\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_03-01-07\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 0.01,\n    \"tune_lr\": 0.001\n  },\n  \"experiment_tag\": \"2_tune_init_std=0.01,tune_lr=0.001\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 2,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b028c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 0,\n    \"test_accuracy\": 53.10199789695058,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"experiment_id\": \"22c5e0ebbf9f47d6bcb6b7a9d361ed62\",\n    \"date\": \"2022-03-06_03-01-17\",\n    \"timestamp\": 1646553677,\n    \"time_this_iter_s\": 4.6072447299957275,\n    \"time_total_s\": 4.6072447299957275,\n    \"pid\": 114467,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"num_anc\": 0,\n      \"deph_p\": 1.0,\n      \"tune_lr\": 0.001,\n      \"tune_init_std\": 0.01\n    },\n    \"time_since_restore\": 4.6072447299957275,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"trial_id\": \"94438_00002\",\n    \"experiment_tag\": \"2_tune_init_std=0.01,tune_lr=0.001\"\n  },\n  \"last_update_time\": 1646553677.805605,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"test_accuracy\": {\n      \"max\": 53.10199789695058,\n      \"min\": 53.10199789695058,\n      \"avg\": 53.10199789695058,\n      \"last\": 53.10199789695058,\n      \"last-5-avg\": 53.10199789695058,\n      \"last-10-avg\": 53.10199789695058\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"timestamp\": {\n      \"max\": 1646553677,\n      \"min\": 1646553677,\n      \"avg\": 1646553677,\n      \"last\": 1646553677,\n      \"last-5-avg\": 1646553677,\n      \"last-10-avg\": 1646553677\n    },\n    \"time_this_iter_s\": {\n      \"max\": 4.6072447299957275,\n      \"min\": 4.6072447299957275,\n      \"avg\": 4.6072447299957275,\n      \"last\": 4.6072447299957275,\n      \"last-5-avg\": 4.6072447299957275,\n      \"last-10-avg\": 4.6072447299957275\n    },\n    \"time_total_s\": {\n      \"max\": 4.6072447299957275,\n      \"min\": 4.6072447299957275,\n      \"avg\": 4.6072447299957275,\n      \"last\": 4.6072447299957275,\n      \"last-5-avg\": 4.6072447299957275,\n      \"last-10-avg\": 4.6072447299957275\n    },\n    \"pid\": {\n      \"max\": 114467,\n      \"min\": 114467,\n      \"avg\": 114467,\n      \"last\": 114467,\n      \"last-5-avg\": 114467,\n      \"last-10-avg\": 114467\n    },\n    \"time_since_restore\": {\n      \"max\": 4.6072447299957275,\n      \"min\": 4.6072447299957275,\n      \"avg\": 4.6072447299957275,\n      \"last\": 4.6072447299957275,\n      \"last-5-avg\": 4.6072447299957275,\n      \"last-10-avg\": 4.6072447299957275\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"config/num_anc\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"config/deph_p\": {\n      \"max\": 1.0,\n      \"min\": 1.0,\n      \"avg\": 1.0,\n      \"last\": 1.0,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.001,\n      \"min\": 0.001,\n      \"avg\": 0.001,\n      \"last\": 0.001,\n      \"last-5-avg\": 0.001,\n      \"last-10-avg\": 0.001\n    },\n    \"config/tune_init_std\": {\n      \"max\": 0.01,\n      \"min\": 0.01,\n      \"avg\": 0.01,\n      \"last\": 0.01,\n      \"last-5-avg\": 0.01,\n      \"last-10-avg\": 0.01\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447404a8d0e445fd4ee612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447404a8d0e445fd4ee612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944a4d6a2462612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944a4d6a2462612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740126dd190000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740126dd190000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740126dd190000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740126dd190000000612e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944a23bf0100612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944a23bf0100612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740126dd190000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740126dd190000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"config/num_anc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"config/deph_p\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473ff0000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473ff0000000000000612e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f50624dd2f1a9fc612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f50624dd2f1a9fc612e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f847ae147ae147b612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f847ae147ae147b612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1646553668.5448308,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_03-01-07/UniTTN_94438_00002_2_tune_init_std=0.01,tune_lr=0.001_2022-03-06_03-01-08\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"94438_00003\",\n  \"config\": {\n    \"num_anc\": 0,\n    \"deph_p\": 1.0,\n    \"tune_lr\": 0.003,\n    \"tune_init_std\": 1\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_03-01-07\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 1,\n    \"tune_lr\": 0.003\n  },\n  \"experiment_tag\": \"3_tune_init_std=1,tune_lr=0.003\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 2,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b028c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 2,\n    \"test_accuracy\": 57.09779179810725,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 3,\n    \"experiment_id\": \"fb0b9bc0c272466fb4888fa3928eba80\",\n    \"date\": \"2022-03-06_03-01-18\",\n    \"timestamp\": 1646553678,\n    \"time_this_iter_s\": 1.140099048614502,\n    \"time_total_s\": 6.3186023235321045,\n    \"pid\": 114459,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"num_anc\": 0,\n      \"deph_p\": 1.0,\n      \"tune_lr\": 0.003,\n      \"tune_init_std\": 1\n    },\n    \"time_since_restore\": 6.3186023235321045,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 3,\n    \"trial_id\": \"94438_00003\",\n    \"experiment_tag\": \"3_tune_init_std=1,tune_lr=0.003\"\n  },\n  \"last_update_time\": 1646553678.2660253,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 2,\n      \"min\": 0,\n      \"avg\": 1.0,\n      \"last\": 2,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"test_accuracy\": {\n      \"max\": 57.09779179810725,\n      \"min\": 53.20715036803365,\n      \"avg\": 54.539081668419215,\n      \"last\": 57.09779179810725,\n      \"last-5-avg\": 54.539081668419215,\n      \"last-10-avg\": 54.539081668419215\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"timestamp\": {\n      \"max\": 1646553678,\n      \"min\": 1646553675,\n      \"avg\": 1646553676.6666665,\n      \"last\": 1646553678,\n      \"last-5-avg\": 1646553676.6666667,\n      \"last-10-avg\": 1646553676.6666667\n    },\n    \"time_this_iter_s\": {\n      \"max\": 4.066783666610718,\n      \"min\": 1.1117196083068848,\n      \"avg\": 2.106200774510701,\n      \"last\": 1.140099048614502,\n      \"last-5-avg\": 2.1062007745107016,\n      \"last-10-avg\": 2.1062007745107016\n    },\n    \"time_total_s\": {\n      \"max\": 6.3186023235321045,\n      \"min\": 4.066783666610718,\n      \"avg\": 5.187963088353475,\n      \"last\": 6.3186023235321045,\n      \"last-5-avg\": 5.187963088353475,\n      \"last-10-avg\": 5.187963088353475\n    },\n    \"pid\": {\n      \"max\": 114459,\n      \"min\": 114459,\n      \"avg\": 114459.0,\n      \"last\": 114459,\n      \"last-5-avg\": 114459.0,\n      \"last-10-avg\": 114459.0\n    },\n    \"time_since_restore\": {\n      \"max\": 6.3186023235321045,\n      \"min\": 4.066783666610718,\n      \"avg\": 5.187963088353475,\n      \"last\": 6.3186023235321045,\n      \"last-5-avg\": 5.187963088353475,\n      \"last-10-avg\": 5.187963088353475\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"config/num_anc\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"config/deph_p\": {\n      \"max\": 1.0,\n      \"min\": 1.0,\n      \"avg\": 1.0,\n      \"last\": 1.0,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.003,\n      \"min\": 0.003,\n      \"avg\": 0.003,\n      \"last\": 0.003,\n      \"last-5-avg\": 0.0030000000000000005,\n      \"last-10-avg\": 0.0030000000000000005\n    },\n    \"config/tune_init_std\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1.0,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b014b02652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404a9a83e73c078a47404aa7f98a183a2547404c8c84710f5806652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404a9a83e73c078a47404aa7f98a183a2547404c8c84710f5806652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a4b6a24624a4d6a24624a4e6a2462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a4b6a24624a4d6a24624a4e6a2462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740104462f0000000473ff1c99a80000000473ff23dd880000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740104462f0000000473ff1c99a80000000473ff23dd880000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740104462f0000000474014b6c990000000474019463fb0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740104462f0000000474014b6c990000000474019463fb0000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a1bbf01004a1bbf01004a1bbf0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a1bbf01004a1bbf01004a1bbf0100652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740104462f0000000474014b6c990000000474019463fb0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740104462f0000000474014b6c990000000474019463fb0000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"config/num_anc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"config/deph_p\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ff0000000000000473ff0000000000000473ff0000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000473ff0000000000000473ff0000000000000652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b01652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1646553668.5508122,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_03-01-07/UniTTN_94438_00003_3_tune_init_std=1,tune_lr=0.003_2022-03-06_03-01-08\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"94438_00004\",\n  \"config\": {\n    \"num_anc\": 0,\n    \"deph_p\": 1.0,\n    \"tune_lr\": 0.003,\n    \"tune_init_std\": 0.1\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_03-01-07\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 0.1,\n    \"tune_lr\": 0.003\n  },\n  \"experiment_tag\": \"4_tune_init_std=0.1,tune_lr=0.003\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 2,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b028c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 2,\n    \"test_accuracy\": 53.10199789695058,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 3,\n    \"experiment_id\": \"7709ed5d6d894270a643cfac37ac22c7\",\n    \"date\": \"2022-03-06_03-01-18\",\n    \"timestamp\": 1646553678,\n    \"time_this_iter_s\": 1.1423189640045166,\n    \"time_total_s\": 6.480957269668579,\n    \"pid\": 114460,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"num_anc\": 0,\n      \"deph_p\": 1.0,\n      \"tune_lr\": 0.003,\n      \"tune_init_std\": 0.1\n    },\n    \"time_since_restore\": 6.480957269668579,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 3,\n    \"trial_id\": \"94438_00004\",\n    \"experiment_tag\": \"4_tune_init_std=0.1,tune_lr=0.003\"\n  },\n  \"last_update_time\": 1646553678.0312064,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 2,\n      \"min\": 0,\n      \"avg\": 1.0,\n      \"last\": 2,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"test_accuracy\": {\n      \"max\": 53.10199789695058,\n      \"min\": 53.10199789695058,\n      \"avg\": 53.10199789695057,\n      \"last\": 53.10199789695058,\n      \"last-5-avg\": 53.10199789695057,\n      \"last-10-avg\": 53.10199789695057\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"timestamp\": {\n      \"max\": 1646553678,\n      \"min\": 1646553675,\n      \"avg\": 1646553676.3333333,\n      \"last\": 1646553678,\n      \"last-5-avg\": 1646553676.3333333,\n      \"last-10-avg\": 1646553676.3333333\n    },\n    \"time_this_iter_s\": {\n      \"max\": 4.192044019699097,\n      \"min\": 1.1423189640045166,\n      \"avg\": 2.1603190898895264,\n      \"last\": 1.1423189640045166,\n      \"last-5-avg\": 2.1603190898895264,\n      \"last-10-avg\": 2.1603190898895264\n    },\n    \"time_total_s\": {\n      \"max\": 6.480957269668579,\n      \"min\": 4.192044019699097,\n      \"avg\": 5.337213198343912,\n      \"last\": 6.480957269668579,\n      \"last-5-avg\": 5.337213198343913,\n      \"last-10-avg\": 5.337213198343913\n    },\n    \"pid\": {\n      \"max\": 114460,\n      \"min\": 114460,\n      \"avg\": 114460.0,\n      \"last\": 114460,\n      \"last-5-avg\": 114460.0,\n      \"last-10-avg\": 114460.0\n    },\n    \"time_since_restore\": {\n      \"max\": 6.480957269668579,\n      \"min\": 4.192044019699097,\n      \"avg\": 5.337213198343912,\n      \"last\": 6.480957269668579,\n      \"last-5-avg\": 5.337213198343913,\n      \"last-10-avg\": 5.337213198343913\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"config/num_anc\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"config/deph_p\": {\n      \"max\": 1.0,\n      \"min\": 1.0,\n      \"avg\": 1.0,\n      \"last\": 1.0,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.003,\n      \"min\": 0.003,\n      \"avg\": 0.003,\n      \"last\": 0.003,\n      \"last-5-avg\": 0.0030000000000000005,\n      \"last-10-avg\": 0.0030000000000000005\n    },\n    \"config/tune_init_std\": {\n      \"max\": 0.1,\n      \"min\": 0.1,\n      \"avg\": 0.1,\n      \"last\": 0.1,\n      \"last-5-avg\": 0.10000000000000002,\n      \"last-10-avg\": 0.10000000000000002\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b014b02652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404a8d0e445fd4ee47404a8d0e445fd4ee47404a8d0e445fd4ee652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404a8d0e445fd4ee47404a8d0e445fd4ee47404a8d0e445fd4ee652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a4b6a24624a4c6a24624a4e6a2462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a4b6a24624a4c6a24624a4e6a2462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474010c4a730000000473ff2587340000000473ff246f040000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474010c4a730000000473ff2587340000000473ff246f040000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474010c4a7300000004740155ac400000000474019ec8010000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474010c4a7300000004740155ac400000000474019ec8010000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a1cbf01004a1cbf01004a1cbf0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a1cbf01004a1cbf01004a1cbf0100652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474010c4a7300000004740155ac400000000474019ec8010000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474010c4a7300000004740155ac400000000474019ec8010000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"config/num_anc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"config/deph_p\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ff0000000000000473ff0000000000000473ff0000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000473ff0000000000000473ff0000000000000652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f689374bc6a7efa473f689374bc6a7efa473f689374bc6a7efa652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fb999999999999a473fb999999999999a473fb999999999999a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fb999999999999a473fb999999999999a473fb999999999999a652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1646553668.5593245,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_03-01-07/UniTTN_94438_00004_4_tune_init_std=0.1,tune_lr=0.003_2022-03-06_03-01-08\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"94438_00001\",\n  \"config\": {\n    \"num_anc\": 0,\n    \"deph_p\": 1.0,\n    \"tune_lr\": 0.001,\n    \"tune_init_std\": 0.1\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_03-01-07\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 0.1,\n    \"tune_lr\": 0.001\n  },\n  \"experiment_tag\": \"1_tune_init_std=0.1,tune_lr=0.001\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 2,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b028c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 1,\n    \"test_accuracy\": 53.10199789695058,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 2,\n    \"experiment_id\": \"4adc4aa27840442a972ee38904d450c9\",\n    \"date\": \"2022-03-06_03-01-17\",\n    \"timestamp\": 1646553677,\n    \"time_this_iter_s\": 1.1065304279327393,\n    \"time_total_s\": 5.375749111175537,\n    \"pid\": 114458,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"num_anc\": 0,\n      \"deph_p\": 1.0,\n      \"tune_lr\": 0.001,\n      \"tune_init_std\": 0.1\n    },\n    \"time_since_restore\": 5.375749111175537,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 2,\n    \"trial_id\": \"94438_00001\",\n    \"experiment_tag\": \"1_tune_init_std=0.1,tune_lr=0.001\"\n  },\n  \"last_update_time\": 1646553677.727393,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 1,\n      \"min\": 0,\n      \"avg\": 0.5,\n      \"last\": 1,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"test_accuracy\": {\n      \"max\": 53.10199789695058,\n      \"min\": 53.10199789695058,\n      \"avg\": 53.10199789695058,\n      \"last\": 53.10199789695058,\n      \"last-5-avg\": 53.10199789695058,\n      \"last-10-avg\": 53.10199789695058\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"timestamp\": {\n      \"max\": 1646553677,\n      \"min\": 1646553676,\n      \"avg\": 1646553676.5,\n      \"last\": 1646553677,\n      \"last-5-avg\": 1646553676.5,\n      \"last-10-avg\": 1646553676.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 4.269218683242798,\n      \"min\": 1.1065304279327393,\n      \"avg\": 2.6878745555877686,\n      \"last\": 1.1065304279327393,\n      \"last-5-avg\": 2.6878745555877686,\n      \"last-10-avg\": 2.6878745555877686\n    },\n    \"time_total_s\": {\n      \"max\": 5.375749111175537,\n      \"min\": 4.269218683242798,\n      \"avg\": 4.8224838972091675,\n      \"last\": 5.375749111175537,\n      \"last-5-avg\": 4.8224838972091675,\n      \"last-10-avg\": 4.8224838972091675\n    },\n    \"pid\": {\n      \"max\": 114458,\n      \"min\": 114458,\n      \"avg\": 114458.0,\n      \"last\": 114458,\n      \"last-5-avg\": 114458.0,\n      \"last-10-avg\": 114458.0\n    },\n    \"time_since_restore\": {\n      \"max\": 5.375749111175537,\n      \"min\": 4.269218683242798,\n      \"avg\": 4.8224838972091675,\n      \"last\": 5.375749111175537,\n      \"last-5-avg\": 4.8224838972091675,\n      \"last-10-avg\": 4.8224838972091675\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"config/num_anc\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"config/deph_p\": {\n      \"max\": 1.0,\n      \"min\": 1.0,\n      \"avg\": 1.0,\n      \"last\": 1.0,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.001,\n      \"min\": 0.001,\n      \"avg\": 0.001,\n      \"last\": 0.001,\n      \"last-5-avg\": 0.001,\n      \"last-10-avg\": 0.001\n    },\n    \"config/tune_init_std\": {\n      \"max\": 0.1,\n      \"min\": 0.1,\n      \"avg\": 0.1,\n      \"last\": 0.1,\n      \"last-5-avg\": 0.1,\n      \"last-10-avg\": 0.1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b01652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404a8d0e445fd4ee47404a8d0e445fd4ee652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404a8d0e445fd4ee47404a8d0e445fd4ee652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a4c6a24624a4d6a2462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a4c6a24624a4d6a2462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847401113ae10000000473ff1b45940000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847401113ae10000000473ff1b45940000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847401113ae1000000047401580c460000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847401113ae1000000047401580c460000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a1abf01004a1abf0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a1abf01004a1abf0100652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847401113ae1000000047401580c460000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847401113ae1000000047401580c460000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"config/num_anc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b00652e\"\n      }\n    },\n    \"config/deph_p\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ff0000000000000473ff0000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000473ff0000000000000652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fb999999999999a473fb999999999999a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fb999999999999a473fb999999999999a652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1646553668.5395024,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_03-01-07/UniTTN_94438_00001_1_tune_init_std=0.1,tune_lr=0.001_2022-03-06_03-01-08\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"UniTTN\",\n  \"trial_id\": \"94438_00000\",\n  \"config\": {\n    \"num_anc\": 0,\n    \"deph_p\": 1.0,\n    \"tune_lr\": 0.001,\n    \"tune_init_std\": 1\n  },\n  \"local_dir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_03-01-07\",\n  \"evaluated_params\": {\n    \"tune_init_std\": 1,\n    \"tune_lr\": 0.001\n  },\n  \"experiment_tag\": \"0_tune_init_std=1,tune_lr=0.001\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 2,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b028c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"training_iteration\": 100\n  },\n  \"log_to_file\": [\n    \"stdout\",\n    \"stderr\"\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"epoch\": 1,\n    \"test_accuracy\": 60.88328075709779,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 2,\n    \"experiment_id\": \"2d10379c66364b49973840a9b2fd213d\",\n    \"date\": \"2022-03-06_03-01-18\",\n    \"timestamp\": 1646553678,\n    \"time_this_iter_s\": 1.2300546169281006,\n    \"time_total_s\": 6.023321866989136,\n    \"pid\": 114462,\n    \"hostname\": \"bigboy2.cchem.berkeley.edu\",\n    \"node_ip\": \"128.32.17.9\",\n    \"config\": {\n      \"num_anc\": 0,\n      \"deph_p\": 1.0,\n      \"tune_lr\": 0.001,\n      \"tune_init_std\": 1\n    },\n    \"time_since_restore\": 6.023321866989136,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 2,\n    \"trial_id\": \"94438_00000\",\n    \"experiment_tag\": \"0_tune_init_std=1,tune_lr=0.001\"\n  },\n  \"last_update_time\": 1646553678.82349,\n  \"metric_analysis\": {\n    \"epoch\": {\n      \"max\": 1,\n      \"min\": 0,\n      \"avg\": 0.5,\n      \"last\": 1,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"test_accuracy\": {\n      \"max\": 61.88222923238696,\n      \"min\": 60.88328075709779,\n      \"avg\": 61.38275499474238,\n      \"last\": 60.88328075709779,\n      \"last-5-avg\": 61.38275499474238,\n      \"last-10-avg\": 61.38275499474238\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"timestamp\": {\n      \"max\": 1646553678,\n      \"min\": 1646553677,\n      \"avg\": 1646553677.5,\n      \"last\": 1646553678,\n      \"last-5-avg\": 1646553677.5,\n      \"last-10-avg\": 1646553677.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 4.793267250061035,\n      \"min\": 1.2300546169281006,\n      \"avg\": 3.011660933494568,\n      \"last\": 1.2300546169281006,\n      \"last-5-avg\": 3.011660933494568,\n      \"last-10-avg\": 3.011660933494568\n    },\n    \"time_total_s\": {\n      \"max\": 6.023321866989136,\n      \"min\": 4.793267250061035,\n      \"avg\": 5.4082945585250854,\n      \"last\": 6.023321866989136,\n      \"last-5-avg\": 5.4082945585250854,\n      \"last-10-avg\": 5.4082945585250854\n    },\n    \"pid\": {\n      \"max\": 114462,\n      \"min\": 114462,\n      \"avg\": 114462.0,\n      \"last\": 114462,\n      \"last-5-avg\": 114462.0,\n      \"last-10-avg\": 114462.0\n    },\n    \"time_since_restore\": {\n      \"max\": 6.023321866989136,\n      \"min\": 4.793267250061035,\n      \"avg\": 5.4082945585250854,\n      \"last\": 6.023321866989136,\n      \"last-5-avg\": 5.4082945585250854,\n      \"last-10-avg\": 5.4082945585250854\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"config/num_anc\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"config/deph_p\": {\n      \"max\": 1.0,\n      \"min\": 1.0,\n      \"avg\": 1.0,\n      \"last\": 1.0,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"config/tune_lr\": {\n      \"max\": 0.001,\n      \"min\": 0.001,\n      \"avg\": 0.001,\n      \"last\": 0.001,\n      \"last-5-avg\": 0.001,\n      \"last-10-avg\": 0.001\n    },\n    \"config/tune_init_std\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1.0,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"epoch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b01652e\"\n      }\n    },\n    \"test_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404ef0ece33256ae47404e710f580675e8652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404ef0ece33256ae47404e710f580675e8652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a4d6a24624a4e6a2462652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a4d6a24624a4e6a2462652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740132c4e40000000473ff3ae4dc0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740132c4e40000000473ff3ae4dc0000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740132c4e4000000047401817e1b0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740132c4e4000000047401817e1b0000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a1ebf01004a1ebf0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a1ebf01004a1ebf0100652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740132c4e4000000047401817e1b0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740132c4e4000000047401817e1b0000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"config/num_anc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b00652e\"\n      }\n    },\n    \"config/deph_p\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ff0000000000000473ff0000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000473ff0000000000000652e\"\n      }\n    },\n    \"config/tune_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f50624dd2f1a9fc473f50624dd2f1a9fc652e\"\n      }\n    },\n    \"config/tune_init_std\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b01652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1646553668.53156,\n  \"logdir\": \"/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_03-01-07/UniTTN_94438_00000_0_tune_init_std=1,tune_lr=0.001_2022-03-06_03-01-08\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_max_pending_trials": 17,
    "_metric": "test_accuracy",
    "_total_time": 279.1181619167328,
    "_iteration": 227,
    "_has_errored": false,
    "_fail_fast": false,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_updated_queue": true,
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_03-01-07",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059527000000000000008c107261792e74756e652e73746f70706572948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1646553668.3278697,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2022-03-06_03-01-08",
    "checkpoint_file": "/home/haoranliao/dephased_ttn_project/uni_ttn/ray_results/UniTTN_2022-03-06_03-01-07/experiment_state-2022-03-06_03-01-08.json",
    "_checkpoint_period": "auto",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1646553668.3278697,
    "timestamp": 1646553709.4795887
  }
}